<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ye Zheng&#39;s Blog</title>
    <link>http://csyezheng.github.io/</link>
    <description>Recent content on Ye Zheng&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 09 Aug 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="http://csyezheng.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>http://csyezheng.github.io/about/</link>
      <pubDate>Mon, 25 Sep 2017 21:38:52 +0800</pubDate>
      
      <guid>http://csyezheng.github.io/about/</guid>
      
        <description>&lt;p&gt;I&amp;rsquo;m graduated from the Hebei GEO University with a degree in marketing, because I thought computers were cool from an early age, so I chose programmers as my future employment direction in my third year of college. In the third year of college, I learned some front-end knowledge, and in the fourth year of college I learned some C ++ related knowledge. After graduating, I naturally found a job related to programming.&lt;/p&gt;
&lt;p&gt;In the first company, I was mainly engaged in web crawling. I was responsible for scraping various financial data including stock exchanges, performing data cleaning, and completing an announcement classification system during the period. I worked as a data development engineer in the second company, and solved development problems such as real-time data forwarding, reception, and storage. I worked as a back-end development engineer at a third company and built the entire edx-based online learning system.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Mybatis Spring Boot</title>
      <link>http://csyezheng.github.io/post/back-end/mybatis-spring-boot/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/back-end/mybatis-spring-boot/</guid>
      
        <description>&lt;h2 id=&#34;creating-a-project&#34;&gt;Creating a project&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;spring init -d=web --build=maven mysite
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;declare-dependencies&#34;&gt;Declare Dependencies&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;cd mysite
vim pom.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.liquibase&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;liquibase-core&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;3.10.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.mybatis.spring.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;mybatis-spring-boot-starter&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.1.3&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;8.0.20&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MyBatis-Spring-Boot-Starter will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Autodetect an existing &lt;code&gt;DataSource&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Will create and register an instance of a &lt;code&gt;SqlSessionFactory&lt;/code&gt; passing that &lt;code&gt;DataSource&lt;/code&gt; as an input using the &lt;code&gt;SqlSessionFactoryBean&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Will create and register an instance of a &lt;code&gt;SqlSessionTemplate&lt;/code&gt; got out of the &lt;code&gt;SqlSessionFactory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Auto-scan your mappers, link them to the &lt;code&gt;SqlSessionTemplate&lt;/code&gt; and register them to Spring context so they can be injected into your beans&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;applicationproperties&#34;&gt;application.properties&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/discovery?characterEncoding=utf8&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;useSSL=false&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=GMT%2B8&amp;amp;nullCatalogMeansCurrent=true&amp;amp;allowPublicKeyRetrieval=true
spring.datasource.driver=com.mysql.cj.jdbc.Driver

# https://docs.spring.io/spring-boot/docs/2.1.1.RELEASE/reference/html/howto-database-initialization.html#howto-execute-liquibase-database-migrations-on-startup
spring.liquibase.change-log=classpath:/db/changelog/db.changelog-master.xml
spring.liquibase.enabled=true
spring.liquibase.contexts=dev, faker
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;dbchangelog&#34;&gt;dbchangelog&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/resources/db/changelog/db.changelog-master.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;databaseChangeLog
        xmlns=&amp;quot;http://www.liquibase.org/xml/ns/dbchangelog&amp;quot;
        xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
        xsi:schemaLocation=&amp;quot;http://www.liquibase.org/xml/ns/dbchangelog
	  http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.8.xsd&amp;quot;&amp;gt;
    &amp;lt;include file=&amp;quot;db/changelog/db.changelog-1.0.xml&amp;quot; relativeToChangelogFile=&amp;quot;false&amp;quot;/&amp;gt;
&amp;lt;/databaseChangeLog&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/resources/db/changelog/db.changelog-1.0.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;databaseChangeLog
        xmlns=&amp;quot;http://www.liquibase.org/xml/ns/dbchangelog&amp;quot;
        xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
        xsi:schemaLocation=&amp;quot;http://www.liquibase.org/xml/ns/dbchangelog
         http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&amp;quot;&amp;gt;
&amp;lt;/databaseChangeLog&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;run-a-spring-boot-application&#34;&gt;Run a spring boot application&lt;/h3&gt;
&lt;p&gt;Hot Swapping&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-devtools&amp;lt;/artifactId&amp;gt;
        &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt;
        &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
    &amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
        &amp;lt;plugin&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;!-- enable forking --&amp;gt;
            &amp;lt;configuration&amp;gt;
                &amp;lt;fork&amp;gt;true&amp;lt;/fork&amp;gt;
            &amp;lt;/configuration&amp;gt;
        &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Run a created application using the Spring Boot Maven Plugin.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim pom.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;properties&amp;gt;
  &amp;lt;maven.compiler.target&amp;gt;1.8&amp;lt;/maven.compiler.target&amp;gt;
  &amp;lt;maven.compiler.source&amp;gt;1.8&amp;lt;/maven.compiler.source&amp;gt;
&amp;lt;/properties&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;build&amp;gt;
  &amp;lt;plugins&amp;gt;
    &amp;lt;plugin&amp;gt;
      &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
      &amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;
      &amp;lt;version&amp;gt;3.6.1&amp;lt;/version&amp;gt;
      &amp;lt;configuration&amp;gt;
        &amp;lt;source&amp;gt;1.8&amp;lt;/source&amp;gt;
        &amp;lt;target&amp;gt;1.8&amp;lt;/target&amp;gt;
      &amp;lt;/configuration&amp;gt;
    &amp;lt;/plugin&amp;gt;
  &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;./mvnw spring-boot:run
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Database generate two table:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DATABASECHANGELOG&lt;/li&gt;
&lt;li&gt;DATABASECHANGELOGLOCK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;atabasechangelog ：用于 Liquibase 操作记录，以行的形式跟踪每个&lt;/strong&gt;*&lt;strong&gt;变更集*****，并由“ id”，“ author”和“ filename”列的组合标识。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;databasechangeloglock ：来确保一次仅运行一个&lt;/strong&gt; &lt;strong&gt;Liquibase&lt;/strong&gt; &lt;strong&gt;实例。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;create-table&#34;&gt;Create table&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/resources/db/changelog/db.changelog-1.0.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;databaseChangeLog
        xmlns=&amp;quot;http://www.liquibase.org/xml/ns/dbchangelog&amp;quot;
        xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
        xsi:schemaLocation=&amp;quot;http://www.liquibase.org/xml/ns/dbchangelog
         http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&amp;quot;&amp;gt;

    &amp;lt;changeSet author=&amp;quot;liquibase-docs&amp;quot; id=&amp;quot;create-city&amp;quot;&amp;gt;
        &amp;lt;preConditions onFail=&amp;quot;MARK_RAN&amp;quot;&amp;gt;
            &amp;lt;not&amp;gt;
                &amp;lt;tableExists tableName=&amp;quot;city&amp;quot;/&amp;gt;
            &amp;lt;/not&amp;gt;
        &amp;lt;/preConditions&amp;gt;
        &amp;lt;createTable remarks=&amp;quot;城市&amp;quot; tableName=&amp;quot;city&amp;quot;&amp;gt;
            &amp;lt;column name=&amp;quot;id&amp;quot; type=&amp;quot;BIGINT&amp;quot; autoIncrement=&amp;quot;true&amp;quot;&amp;gt;
                &amp;lt;constraints primaryKey=&amp;quot;true&amp;quot;/&amp;gt;
            &amp;lt;/column&amp;gt;
            &amp;lt;column name=&amp;quot;name&amp;quot; remarks=&amp;quot;名称&amp;quot; type=&amp;quot;VARCHAR(255)&amp;quot;/&amp;gt;
            &amp;lt;column name=&amp;quot;state&amp;quot; remarks=&amp;quot;州&amp;quot; type=&amp;quot;VARCHAR(255)&amp;quot;/&amp;gt;
            &amp;lt;column name=&amp;quot;country&amp;quot; remarks=&amp;quot;国家&amp;quot; type=&amp;quot;VARCHAR(255)&amp;quot;/&amp;gt;
        &amp;lt;/createTable&amp;gt;
    &amp;lt;/changeSet&amp;gt;

    &amp;lt;changeSet author=&amp;quot;liquibase-docs&amp;quot; id=&amp;quot;create-hotel&amp;quot;&amp;gt;
        &amp;lt;preConditions onFail=&amp;quot;MARK_RAN&amp;quot;&amp;gt;
            &amp;lt;not&amp;gt;
                &amp;lt;tableExists tableName=&amp;quot;hotel&amp;quot;/&amp;gt;
            &amp;lt;/not&amp;gt;
        &amp;lt;/preConditions&amp;gt;
        &amp;lt;createTable remarks=&amp;quot;酒店&amp;quot; tableName=&amp;quot;hotel&amp;quot;&amp;gt;
            &amp;lt;column name=&amp;quot;id&amp;quot; type=&amp;quot;BIGINT&amp;quot;/&amp;gt;
            &amp;lt;column name=&amp;quot;city&amp;quot; remarks=&amp;quot;城市&amp;quot; type=&amp;quot;VARCHAR(255)&amp;quot;/&amp;gt;
            &amp;lt;column name=&amp;quot;name&amp;quot; remarks=&amp;quot;名称&amp;quot; type=&amp;quot;VARCHAR(255)&amp;quot;/&amp;gt;
            &amp;lt;column name=&amp;quot;address&amp;quot; remarks=&amp;quot;地址&amp;quot; type=&amp;quot;VARCHAR(255)&amp;quot;/&amp;gt;
            &amp;lt;column name=&amp;quot;zip&amp;quot; remarks=&amp;quot;邮编&amp;quot; type=&amp;quot;VARCHAR(255)&amp;quot;/&amp;gt;
        &amp;lt;/createTable&amp;gt;
    &amp;lt;/changeSet&amp;gt;

&amp;lt;/databaseChangeLog&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;create-a-domain-class&#34;&gt;Create a domain class&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;mkdir src/main/java/com/example/mysite/domain
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite/City.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.mysite.domain;

import java.io.Serializable;

public class City implements Serializable {

  private static final long serialVersionUID = 1L;

  private Long id;

  private String name;

  private String state;

  private String country;

  public Long getId() {
    return this.id;
  }

  public void setId(Long id) {
    this.id = id;
  }

  public String getName() {
    return this.name;
  }

  public void setName(String name) {
    this.name = name;
  }

  public String getState() {
    return this.state;
  }

  public void setState(String state) {
    this.state = state;
  }

  public String getCountry() {
    return this.country;
  }

  public void setCountry(String country) {
    this.country = country;
  }

  @Override
  public String toString() {
    return getId() + &amp;quot;,&amp;quot; + getName() + &amp;quot;,&amp;quot; + getState() + &amp;quot;,&amp;quot; + getCountry();
  }

}
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite/domain/Hotel.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.mysite.domain;

import java.io.Serializable;

public class Hotel implements Serializable {

  private static final long serialVersionUID = 1L;

  private Long city;

  private String name;

  private String address;

  private String zip;

  public Long getCity() {
    return city;
  }

  public void setCity(Long city) {
    this.city = city;
  }

  public String getName() {
    return name;
  }

  public void setName(String name) {
    this.name = name;
  }

  public String getAddress() {
    return address;
  }

  public void setAddress(String address) {
    this.address = address;
  }

  public String getZip() {
    return zip;
  }

  public void setZip(String zip) {
    this.zip = zip;
  }

  @Override
  public String toString() {
    return getCity() + &amp;quot;,&amp;quot; + getName() + &amp;quot;,&amp;quot; + getAddress() + &amp;quot;,&amp;quot; + getZip();
  }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;create-a-dao&#34;&gt;Create a DAO&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;mkdir src/main/java/com/example/mysite/dao
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite/dao/CityDao.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.mysite.dao;

import org.apache.ibatis.session.SqlSession;
import org.springframework.stereotype.Component;

import com.example.mysite.domain.City;

@Component
public class CityDao {

    private final SqlSession sqlSession;

    public CityDao(SqlSession sqlSession) {
        this.sqlSession = sqlSession;
    }

    public City selectCityById(long id) {
      return this.sqlSession.selectOne(&amp;quot;selectCityById&amp;quot;, id);
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;create-a-mapper-interface&#34;&gt;Create a mapper interface&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;mkdir src/main/java/com/example/mysite/mapper
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite/mapper/HotelMapper.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.mysite.mapper;

import org.apache.ibatis.annotations.Mapper;

import com.example.mysite.domain.Hotel;

@Mapper
public interface HotelMapper {
  Hotel selectByCityId(int cityId);
}
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;writer-mapper-file&#34;&gt;Writer mapper file&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p src/main/resources/com/example/mysite/mapper
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/resources/com/example/mysite/mapper/CityMapper.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot; ?&amp;gt;
&amp;lt;!DOCTYPE mapper
        PUBLIC &amp;quot;-//mybatis.org//DTD Mapper 3.0//EN&amp;quot;
        &amp;quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&amp;quot;&amp;gt;
&amp;lt;mapper namespace=&amp;quot;com.example.mysite.mapper.CityMapper&amp;quot;&amp;gt;
    &amp;lt;select id=&amp;quot;selectCityById&amp;quot; resultType=&amp;quot;City&amp;quot;&amp;gt;
        select id, name, state, country from city where id = #{id}
    &amp;lt;/select&amp;gt;
&amp;lt;/mapper&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/resources/com/example/mysite/mapper/HotelMapper.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot; ?&amp;gt;
&amp;lt;!DOCTYPE mapper
        PUBLIC &amp;quot;-//mybatis.org//DTD Mapper 3.0//EN&amp;quot;
        &amp;quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&amp;quot;&amp;gt;
&amp;lt;mapper namespace=&amp;quot;com.example.mysite.mapper.HotelMapper&amp;quot;&amp;gt;
    &amp;lt;select id=&amp;quot;selectByCityId&amp;quot; resultType=&amp;quot;Hotel&amp;quot;&amp;gt;
        select city, name, address, zip from hotel where city = #{id}
    &amp;lt;/select&amp;gt;
&amp;lt;/mapper&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;modify-a-spring-boot-application-class&#34;&gt;Modify a spring boot application class&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite/DemoApplication.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.mysite;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.autoconfigure.SpringBootApplication;

import com.example.mysite.dao.CityDao;
import com.example.mysite.mapper.HotelMapper;

@SpringBootApplication
public class DemoApplication implements CommandLineRunner {

    public static void main(String[] args) {
        SpringApplication.run(DemoApplication.class, args);
    }

    private final CityDao cityDao;
    private final HotelMapper hotelMapper;

    public DemoApplication(CityDao cityDao, HotelMapper hotelMapper) {
        this.cityDao = cityDao;
        this.hotelMapper = hotelMapper;
    }

    @Override
    @SuppressWarnings(&amp;quot;squid:S106&amp;quot;)
    public void run(String... args) {
        System.out.println(this.cityDao.selectCityById(1));
        System.out.println(this.hotelMapper.selectByCityId(1));
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;mybatis-configuration&#34;&gt;Mybatis Configuration&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/resources/application.properties
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;mybatis.config-location=classpath:mybatis-config.xml
logging.level.root=WARN
logging.level.com.example.mysite.mapper=TRACE
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/resources/mybatis-config.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE configuration
        PUBLIC &amp;quot;-//mybatis.org//DTD Config 3.0//EN&amp;quot;
        &amp;quot;http://mybatis.org/dtd/mybatis-3-config.dtd&amp;quot;&amp;gt;
&amp;lt;configuration&amp;gt;
    &amp;lt;typeAliases&amp;gt;
        &amp;lt;package name=&amp;quot;com.example.mysite.domain&amp;quot;/&amp;gt;
    &amp;lt;/typeAliases&amp;gt;
    &amp;lt;mappers&amp;gt;
        &amp;lt;mapper resource=&amp;quot;com/example/mysite/mapper/CityMapper.xml&amp;quot;/&amp;gt;
        &amp;lt;mapper resource=&amp;quot;com/example/mysite/mapper/HotelMapper.xml&amp;quot;/&amp;gt;
    &amp;lt;/mappers&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>Spring</title>
      <link>http://csyezheng.github.io/post/back-end/spring/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/back-end/spring/</guid>
      
        <description>&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;h3 id=&#34;install-jdk&#34;&gt;Install JDK&lt;/h3&gt;
&lt;p&gt;Download &lt;code&gt;jdk-8u261-linux-x64.tar.gz&lt;/code&gt; from Oracle&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -S jdk8-openjdk
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim ~/.bashrc 
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;export JAVA_HOME=/usr/lib/jvm/java-8-openjdk
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;install-maven&#34;&gt;Install maven&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -S maven
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;cp /opt/maven/conf/settings.xml ~/.m2/
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim ~/.m2/settings.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;mirror&amp;gt;
  &amp;lt;id&amp;gt;alimaven&amp;lt;/id&amp;gt;
  &amp;lt;mirrorOf&amp;gt;central&amp;lt;/mirrorOf&amp;gt;
  &amp;lt;name&amp;gt;aliyun maven&amp;lt;/name&amp;gt;
  &amp;lt;url&amp;gt;http://maven.aliyun.com/nexus/content/groups/public&amp;lt;/url&amp;gt;
&amp;lt;/mirror&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;installing-the-spring-boot-cli&#34;&gt;Installing the Spring Boot CLI&lt;/h3&gt;
&lt;p&gt;Download  the Spring Boot CLI&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget https://repo.spring.io/snapshot/org/springframework/boot/spring-boot-cli/2.3.3.BUILD-SNAPSHOT/spring-boot-cli-2.3.3.BUILD-SNAPSHOT-bin.zip
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Extract  to a directory that supports file execution.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo unzip spring-boot-cli-2.3.3.BUILD-SNAPSHOT-bin.zip -d /opt/
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim ~/.bashrc 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Add the following line to the file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export PATH=/opt/spring-2.3.3.BUILD-SNAPSHOT/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Use the source command to force Linux to reload the &lt;code&gt;.bashrc&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;spring-at-a-glance&#34;&gt;Spring at a glance&lt;/h2&gt;
&lt;h3 id=&#34;creating-a-project&#34;&gt;Creating a project&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;spring help init
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;spring init --list
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;spring init -d=web,mybatis,mysql --build=maven mysite
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;add-your-code&#34;&gt;Add your code&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite/DemoApplication.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.demo;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

@SpringBootApplication
@RestController
public class DemoApplication {
	
    public static void main(String[] args) {
    	SpringApplication.run(DemoApplication.class, args);
    }

    @GetMapping(&amp;quot;/hello&amp;quot;)
    public String hello(@RequestParam(value = &amp;quot;name&amp;quot;, defaultValue = &amp;quot;World&amp;quot;) String name) {
        return String.format(&amp;quot;Hello %s!&amp;quot;, name);
    }
}            
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;use-the-compiler-plugin&#34;&gt;Use the Compiler Plugin&lt;/h3&gt;
&lt;h6 id=&#34;maven-java-compiler-properties&#34;&gt;Maven Java Compiler Properties&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;vim pom.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;properties&amp;gt;
  &amp;lt;maven.compiler.target&amp;gt;1.8&amp;lt;/maven.compiler.target&amp;gt;
  &amp;lt;maven.compiler.source&amp;gt;1.8&amp;lt;/maven.compiler.source&amp;gt;
&amp;lt;/properties&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;maven-java-compiler-plugin&#34;&gt;Maven Java Compiler Plugin&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;vim pom.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;build&amp;gt;
  &amp;lt;plugins&amp;gt;
    &amp;lt;plugin&amp;gt;
      &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
      &amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;
      &amp;lt;version&amp;gt;3.6.1&amp;lt;/version&amp;gt;
      &amp;lt;configuration&amp;gt;
        &amp;lt;source&amp;gt;1.8&amp;lt;/source&amp;gt;
        &amp;lt;target&amp;gt;1.8&amp;lt;/target&amp;gt;
      &amp;lt;/configuration&amp;gt;
    &amp;lt;/plugin&amp;gt;
  &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;hot-swapping&#34;&gt;Hot Swapping&lt;/h3&gt;
&lt;h4 id=&#34;developer-tools&#34;&gt;Developer Tools&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;dependencies&amp;gt;
    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-devtools&amp;lt;/artifactId&amp;gt;
        &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt;
        &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
    &amp;lt;/dependency&amp;gt;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
        &amp;lt;plugin&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;!-- enable forking --&amp;gt;
            &amp;lt;configuration&amp;gt;
                &amp;lt;fork&amp;gt;true&amp;lt;/fork&amp;gt;
            &amp;lt;/configuration&amp;gt;
        &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;automatic-restart&#34;&gt;Automatic Restart&lt;/h4&gt;
&lt;p&gt;Triggering a restart&lt;/p&gt;
&lt;p&gt;As DevTools monitors classpath resources, the only way to trigger a restart is to update the classpath. The way in which you cause the classpath to be updated depends on the IDE that you are using. In Eclipse, saving a modified file causes the classpath to be updated and triggers a restart. In IntelliJ IDEA, &lt;strong&gt;building the project&lt;/strong&gt; (&lt;code&gt;Build +→+ Build Project&lt;/code&gt;) has the same effect.&lt;/p&gt;
&lt;p&gt;As long as forking is enabled, you can also start your application by using the supported build plugins (Maven and Gradle), since DevTools needs an isolated application classloader to operate properly. By default, the Gradle and Maven plugins fork the application process.&lt;/p&gt;
&lt;p&gt;If start application by command line, manually execute command &lt;strong&gt;compilation&lt;/strong&gt; after code change:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./mvnw compile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;run-the-server&#34;&gt;Run the server&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;./mvnw spring-boot:run
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now that the server’s running, visit http://localhost:8080/hello with your Web browser.&lt;/p&gt;
&lt;p&gt;Then, depending on the development environment you use, after a change to Java code is made, you might need to &lt;strong&gt;build your project.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you start your Spring Boot app with &lt;strong&gt;java -jar&lt;/strong&gt;, the How Swap will not work even if you add the &lt;strong&gt;spring-boot-devtools&lt;/strong&gt; dependency.&lt;/p&gt;
&lt;h2 id=&#34;structuring-your-code&#34;&gt;Structuring Your Code&lt;/h2&gt;
&lt;p&gt;The following listing shows a typical layout:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;com
 +- example
     +- myapplication
         +- Application.java
         |
         +- customer
         |   +- Customer.java
         |   +- CustomerController.java
         |   +- CustomerService.java
         |   +- CustomerRepository.java
         |
         +- order
             +- Order.java
             +- OrderController.java
             +- OrderService.java
             +- OrderRepository.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;com
 +- example
     +- myapplication
         +- Application.java
         |
         +- config - class which will read from property files
         +- cache - caching mechanism class files
         +- controller - controller clwass
         +- dao - Data Access Object
         +- domain - @Entity 
         +- dto - Data Transfer Object
         +- exception - exception class  
         +- model - pojos classes will be present
         +- repository - @Repository
         +- security - security classes
         +- service - Impl classes
         +- utils - utility classes
         +- validation - validators classes
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h2&gt;
&lt;h3 id=&#34;building-java-projects-with-maven&#34;&gt;Building Java Projects with Maven&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;mkdir mysite
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;mkdir -p src/main/java/hello
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/java/hello/HelloWorld.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package hello;

public class HelloWorld {
  public static void main(String[] args) {
    Greeter greeter = new Greeter();
    System.out.println(greeter.sayHello());
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/java/hello/Greeter.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package hello;

public class Greeter {
  public String sayHello() {
    return &amp;quot;Hello world!&amp;quot;;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;define-a-simple-maven-build&#34;&gt;Define a simple Maven build&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;vim pom.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;project xmlns=&amp;quot;http://maven.apache.org/POM/4.0.0&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
    xsi:schemaLocation=&amp;quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&amp;quot;&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;

    &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;gs-maven&amp;lt;/artifactId&amp;gt;
    &amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt;
    &amp;lt;version&amp;gt;0.1.0&amp;lt;/version&amp;gt;

    &amp;lt;properties&amp;gt;
        &amp;lt;maven.compiler.source&amp;gt;1.8&amp;lt;/maven.compiler.source&amp;gt;
        &amp;lt;maven.compiler.target&amp;gt;1.8&amp;lt;/maven.compiler.target&amp;gt;
    &amp;lt;/properties&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;maven-shade-plugin&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;2.1&amp;lt;/version&amp;gt;
                &amp;lt;executions&amp;gt;
                    &amp;lt;execution&amp;gt;
                        &amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;
                        &amp;lt;goals&amp;gt;
                            &amp;lt;goal&amp;gt;shade&amp;lt;/goal&amp;gt;
                        &amp;lt;/goals&amp;gt;
                        &amp;lt;configuration&amp;gt;
                            &amp;lt;transformers&amp;gt;
                                &amp;lt;transformer
                                    implementation=&amp;quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&amp;quot;&amp;gt;
                                    &amp;lt;mainClass&amp;gt;hello.HelloWorld&amp;lt;/mainClass&amp;gt;
                                &amp;lt;/transformer&amp;gt;
                            &amp;lt;/transformers&amp;gt;
                        &amp;lt;/configuration&amp;gt;
                    &amp;lt;/execution&amp;gt;
                &amp;lt;/executions&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;build-java-code&#34;&gt;Build Java code&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;mvn compile
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;mvn package
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;java -jar target/mysite-0.1.0.jar
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;declare-dependencies&#34;&gt;Declare Dependencies&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;vim pom.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;dependencies&amp;gt;
		&amp;lt;dependency&amp;gt;
			&amp;lt;groupId&amp;gt;joda-time&amp;lt;/groupId&amp;gt;
			&amp;lt;artifactId&amp;gt;joda-time&amp;lt;/artifactId&amp;gt;
			&amp;lt;version&amp;gt;2.9.2&amp;lt;/version&amp;gt;
		&amp;lt;/dependency&amp;gt;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/main/java/hello/HelloWorld.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package hello;

import org.joda.time.LocalTime;

public class HelloWorld {
  public static void main(String[] args) {
    LocalTime currentTime = new LocalTime();
    System.out.println(&amp;quot;The current local time is: &amp;quot; + currentTime);
    Greeter greeter = new Greeter();
    System.out.println(greeter.sayHello());
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;write-a-test&#34;&gt;Write a Test&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;vim pom.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
	&amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;4.12&amp;lt;/version&amp;gt;
	&amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;mkdir -p src/test/java/hello
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim src/test/java/hello/GreeterTest.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package hello;

import static org.hamcrest.CoreMatchers.containsString;
import static org.junit.Assert.*;

import org.junit.Test;

public class GreeterTest {

  private Greeter greeter = new Greeter();

  @Test
  public void greeterSaysHello() {
    assertThat(greeter.sayHello(), containsString(&amp;quot;Hello&amp;quot;));
  }

}
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;mvn test
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;building-an-application-with-spring-boot&#34;&gt;Building an Application with Spring Boot&lt;/h3&gt;
&lt;h3 id=&#34;mybatis-integration-with-spring-boot&#34;&gt;MyBatis integration with Spring Boot&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;spring init -d=web,mybatis,h2 --build=maven mysite_mybatis
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;create-sql-files&#34;&gt;Create sql files&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/resources/schema.sql
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;CREATE TABLE city
(
  id      INT PRIMARY KEY auto_increment,
  name    VARCHAR,
  state   VARCHAR,
  country VARCHAR
);
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;create-a-domain-class&#34;&gt;Create a domain class&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite_mybatis/City.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.mysite_mybatis;

public class City {

  private Long id;
  private String name;
  private String state;
  private String country;

  public Long getId() {
    return this.id;
  }

  public void setId(Long id) {
    this.id = id;
  }

  public String getName() {
    return this.name;
  }

  public void setName(String name) {
    this.name = name;
  }

  public String getState() {
    return this.state;
  }

  public void setState(String state) {
    this.state = state;
  }

  public String getCountry() {
    return this.country;
  }

  public void setCountry(String country) {
    this.country = country;
  }

  @Override
  public String toString() {
    return getId() + &amp;quot;,&amp;quot; + getName() + &amp;quot;,&amp;quot; + getState() + &amp;quot;,&amp;quot; + getCountry();
  }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;create-a-mapper-interface&#34;&gt;Create a mapper interface&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite_mybatis/CityMapper.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.mysite_mybatis;

import org.apache.ibatis.annotations.Insert;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Options;
import org.apache.ibatis.annotations.Select;

@Mapper
public interface CityMapper {

  @Insert(&amp;quot;INSERT INTO city (name, state, country) VALUES(#{name}, #{state}, #{country})&amp;quot;)
  @Options(useGeneratedKeys = true, keyProperty = &amp;quot;id&amp;quot;)
  void insert(City city);

  @Select(&amp;quot;SELECT id, name, state, country FROM city WHERE id = #{id}&amp;quot;)
  City findById(long id);

}
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;modify-a-spring-boot-application-class&#34;&gt;Modify a spring boot application class&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;vim src/main/java/com/example/mysite_mybatis/DemoApplication.java
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;package com.example.mysite_mybatis;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;

@SpringBootApplication
public class DemoApplication {

    public static void main(String[] args) {
        SpringApplication.run(DemoApplication.class, args);
    }

    public DemoApplication(CityMapper cityMapper) {
        this.cityMapper = cityMapper;
    }

    @Bean
    CommandLineRunner sampleCommandLineRunner() {
        return args -&amp;gt; {
            City city = new City();
            city.setName(&amp;quot;San Francisco&amp;quot;);
            city.setState(&amp;quot;CA&amp;quot;);
            city.setCountry(&amp;quot;US&amp;quot;);
            cityMapper.insert(city);
            System.out.println(this.cityMapper.findById(city.getId()));
        };
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;run-a-spring-boot-application&#34;&gt;Run a spring boot application&lt;/h6&gt;
&lt;p&gt;Run a created application using the Spring Boot Maven Plugin.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim pom.xml
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;properties&amp;gt;
  &amp;lt;maven.compiler.target&amp;gt;1.8&amp;lt;/maven.compiler.target&amp;gt;
  &amp;lt;maven.compiler.source&amp;gt;1.8&amp;lt;/maven.compiler.source&amp;gt;
&amp;lt;/properties&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;build&amp;gt;
  &amp;lt;plugins&amp;gt;
    &amp;lt;plugin&amp;gt;
      &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
      &amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;
      &amp;lt;version&amp;gt;3.6.1&amp;lt;/version&amp;gt;
      &amp;lt;configuration&amp;gt;
        &amp;lt;source&amp;gt;1.8&amp;lt;/source&amp;gt;
        &amp;lt;target&amp;gt;1.8&amp;lt;/target&amp;gt;
      &amp;lt;/configuration&amp;gt;
    &amp;lt;/plugin&amp;gt;
  &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/current/reference/html/using-spring-boot.html&#34;&gt;Using Spring Boot&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>欣宸Blog</title>
      <link>http://csyezheng.github.io/post/devops/</link>
      <pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/devops/</guid>
      
        <description>&lt;p&gt;&lt;a href=&#34;https://cloud.tencent.com/developer/column/1662&#34;&gt;https://cloud.tencent.com/developer/column/1662&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>circumvent Internet censorship</title>
      <link>http://csyezheng.github.io/post/any-path/circumvent-internet-censorship/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/any-path/circumvent-internet-censorship/</guid>
      
        <description>&lt;h2 id=&#34;shadowsocks&#34;&gt;Shadowsocks&lt;/h2&gt;
&lt;h2 id=&#34;shadowsocksr&#34;&gt;ShadowsocksR&lt;/h2&gt;
&lt;h3 id=&#34;subscription-address&#34;&gt;subscription address&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ssrsub/ssr/master/ssrsub&#34;&gt;https://raw.githubusercontent.com/ssrsub/ssr/master/ssrsub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://yzzz.ml/freessr/&#34;&gt;https://yzzz.ml/freessr/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AmazingDM/sub/master/ssrshare.com&#34;&gt;https://raw.githubusercontent.com/AmazingDM/sub/master/ssrshare.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://haobang.yangwang.workers.dev/&#34;&gt;https://haobang.yangwang.workers.dev/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.yangwang.tk/&#34;&gt;http://www.yangwang.tk/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://shadow-socks-share.herokuapp.com/subscribe&#34;&gt;https://shadow-socks-share.herokuapp.com/subscribe&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.liesauer.net/yogurt/subscribe?ACCESS_TOKEN=DAYxR3mMaZAsaqUb&#34;&gt;https://www.liesauer.net/yogurt/subscribe?ACCESS_TOKEN=DAYxR3mMaZAsaqUb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://qiaomenzhuanfx.netlify.com/&#34;&gt;https://qiaomenzhuanfx.netlify.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://muma16fx.netlify.com/&#34;&gt;https://muma16fx.netlify.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/voken100g/AutoSSR/master/online&#34;&gt;https://raw.githubusercontent.com/voken100g/AutoSSR/master/online&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/voken100g/AutoSSR/master/recent&#34;&gt;https://raw.githubusercontent.com/voken100g/AutoSSR/master/recent&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://youlianboshi.netlify.com/&#34;&gt;https://youlianboshi.netlify.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://ss.pythonic.life/full/subscribe&#34;&gt;http://ss.pythonic.life/full/subscribe&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nutgeek.cn/newsubscribe/&#34;&gt;https://www.nutgeek.cn/newsubscribe/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://prom-php.herokuapp.com/cloudfra_ssr.txt&#34;&gt;https://prom-php.herokuapp.com/cloudfra_ssr.txt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://share-shadowsocks.herokuapp.com/full/subscribe&#34;&gt;http://share-shadowsocks.herokuapp.com/full/subscribe&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://share-shadowsocksr.herokuapp.com/subscribe?valid=1&#34;&gt;http://share-shadowsocksr.herokuapp.com/subscribe?valid=1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AmazingDM/sub/master/ssrshare.com&#34;&gt;https://raw.githubusercontent.com/AmazingDM/sub/master/ssrshare.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/liesauer/Free-SS-SSR&#34;&gt;https://github.com/liesauer/Free-SS-SSR&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://yzzz.ml/freessr&#34;&gt;https://yzzz.ml/freessr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.liesauer.net/yogurt/subscribe?ACCESS_TOKEN=DAYxR3mMaZAsaqUb&#34;&gt;https://www.liesauer.net/yogurt/subscribe?ACCESS_TOKEN=DAYxR3mMaZAsaqUb&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;free-account&#34;&gt;Free account&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youneed.win/free-ssr&#34;&gt;https://www.youneed.win/free-ssr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://nulastudio.org/Freedom/&#34;&gt;http://nulastudio.org/Freedom/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lncn.org/&#34;&gt;https://lncn.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jichangdaquan.com/node/429.html&#34;&gt;https://jichangdaquan.com/node/429.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.freess.best/&#34;&gt;https://www.freess.best/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://fanqiang.network/&#34;&gt;https://fanqiang.network/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jichangdaquan.com/node/429.html&#34;&gt;https://jichangdaquan.com/node/429.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;v2ray&#34;&gt;V2ray&lt;/h2&gt;
&lt;h3 id=&#34;subscription-address-1&#34;&gt;subscription address&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AmazingDM/sub/master/v2ray_ssrshare.com&#34;&gt;https://raw.githubusercontent.com/AmazingDM/sub/master/v2ray_ssrshare.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jiang.netlify.com/&#34;&gt;https://jiang.netlify.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://youlianboshi.netlify.com/&#34;&gt;https://youlianboshi.netlify.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/eycorsican/rule-sets/master/kitsunebi_sub&#34;&gt;https://raw.githubusercontent.com/eycorsican/rule-sets/master/kitsunebi_sub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ssrsub/ssr/master/v2ray&#34;&gt;https://raw.githubusercontent.com/ssrsub/ssr/master/v2ray&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bhqt.ltd/?p=236&#34;&gt;https://bhqt.ltd/?p=236&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;free-account-1&#34;&gt;Free account&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://free-ss.site/&#34;&gt;https://free-ss.site/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.freess.best/v2ray.html&#34;&gt;https://www.freess.best/v2ray.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.freevpnnet.com/&#34;&gt;https://www.freevpnnet.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jichangdaquan.com/node/429.html&#34;&gt;https://jichangdaquan.com/node/429.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://view.freev2ray.org/&#34;&gt;https://view.freev2ray.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://v2ray.cat/&#34;&gt;https://v2ray.cat/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://v2ray.party/&#34;&gt;https://v2ray.party/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://my.freev2ray.org/&#34;&gt;https://my.freev2ray.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://v2fire.tk/&#34;&gt;https://v2fire.tk/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://get.freev2ray.com/&#34;&gt;https://get.freev2ray.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://freev2.org&#34;&gt;https://freev2.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jichangdaquan.com/node/429.html&#34;&gt;https://jichangdaquan.com/node/429.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/hoochanlon/w3-goto-world/blob/master/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E3%80%81%E6%9A%97%E7%BD%91%E3%80%81%E9%9B%B6%E7%BD%91/%E5%85%8D%E8%B4%B9ss%E3%80%81ssr%E3%80%81vmess%E5%88%86%E4%BA%AB/readme.md&#34;&gt;https://github.com/hoochanlon/w3-goto-world/blob/master/科学上网、暗网、零网/免费ss、ssr、vmess分享/readme.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://fanqiang.network/shadowsocks-servers&#34;&gt;SHADOWSOCKS服务器信息&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.similarsites.com/&#34;&gt;https://www.similarsites.com&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Question answering</title>
      <link>http://csyezheng.github.io/post/natural-language-processing/question-answering/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/natural-language-processing/question-answering/</guid>
      
        <description>&lt;p&gt;Reference&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/deepmipt/DeepPavlov&#34;&gt;https://github.com/deepmipt/DeepPavlov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/deepset-ai/FARM&#34;&gt;https://github.com/deepset-ai/FARM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;https://github.com/huggingface/transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/deepset-ai/haystack&#34;&gt;https://github.com/deepset-ai/haystack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/deepset-ai/COVID-QA&#34;&gt;https://github.com/deepset-ai/COVID-QA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://demo.allennlp.org/reading-comprehension&#34;&gt;https://demo.allennlp.org/reading-comprehension&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/baidu/AnyQ&#34;&gt;https://github.com/baidu/AnyQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/allenai/bi-att-flow&#34;&gt;https://github.com/allenai/bi-att-flow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/google-research/language/tree/master/language/question_answering&#34;&gt;https://github.com/google-research/language/tree/master/language/question_answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aihub.cloud.google.com/p/products%2Ffb38fa2f-f246-43c8-b611-c82948fc6d85&#34;&gt;BERT Question Answering Inference with Mixed Precision in TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/c/tensorflow2-question-answering/&#34;&gt;https://www.kaggle.com/c/tensorflow2-question-answering/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/chrischute/squad&#34;&gt;https://github.com/chrischute/squad&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ColasGael/QA-squad&#34;&gt;https://github.com/ColasGael/QA-squad&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/IBM/MAX-Question-Answering&#34;&gt;https://github.com/IBM/MAX-Question-Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/cs224n/project/default-final-project-handout.pdf&#34;&gt;http://web.stanford.edu/class/cs224n/project/default-final-project-handout.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/baidu/DuReader&#34;&gt;https://github.com/baidu/DuReader&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>tencent nlp interview</title>
      <link>http://csyezheng.github.io/post/interview/tencent-nlp-interview/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/interview/tencent-nlp-interview/</guid>
      
        <description>&lt;h2 id=&#34;一面技术面&#34;&gt;一面（技术面）&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;面试形式：电话面试&lt;/strong&gt;。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;简要的自我介绍。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;研究生阶段最有挑战的项目是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于这个项目，传统的方法是怎么样的？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;列举下这个任务在传统用法的一些典型特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;看你简历里有QA相关的论文，大概介绍下里面用的方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你在这篇论文里用到的是GloVe，为何不用word2vec，或者说word2vec与GloVe有什么区别？&lt;/p&gt;
&lt;p&gt;我大致说了下他们的区别：word2vec是NNLM的一个较为典型的代表，其利用了DNN的方法来训练获取到词向量，而且词向量是中间产物，这个思路最早是Bengio提出，Google Brain提出的word2vec让词向量火了起来。而GloVe是采用词频统计信息，利用一些数学方法逐步优化得来，它没有神经网络的结构，所以词向量训练的速度相对更快。（这里当时不记得具体的公式推导了，原论文我倒是看过，但是当时记得不清了，实际上GloVe是词共现矩阵+类SVD的方法）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你清楚word2vec吗，大致描述下word2vec的结构以及训练方法。&lt;/p&gt;
&lt;p&gt;从宏观上描述了DNN的一个结构，从输入（大致带过分词，词表构建，one-hot等过程），到隐层，到输出层。然后详细讲了两种训练结构，即CBoW和Skip-Gram。讲完两种训练方法后，大致介绍了下训练时候词表大小过大，输出层过大的优化方法，即：&lt;strong&gt;hierarchical softmax&lt;/strong&gt;和&lt;strong&gt;negative sampling&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现阶段NLP的研究相对CV发展还是很缓慢，你认为是什么原因？&lt;/p&gt;
&lt;p&gt;自然语言存在变化性，和不确定性，即语义的抽取对神经网络来说是很难的，在英文，人脑可以通过词形来建立词与词之间的关系，但是语义不确定性很强，比如歧义，一词多义，词序等等都会影响语义。而CV的特征相对固定，如图像处理，filter提取的特征一般是某种轮廓或边缘特征，这些特征对于特定的物体都是固定的，所以效果会更好。（其实总结就是&lt;strong&gt;感知智能&lt;/strong&gt;和&lt;strong&gt;认知智能&lt;/strong&gt;，&lt;strong&gt;感知智能&lt;/strong&gt;很容易实现，即CV，而&lt;strong&gt;认知智能&lt;/strong&gt;有很多挑战，即NLP）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你知道隐马尔可夫模型吗，大概介绍下。&lt;/p&gt;
&lt;p&gt;问了HMM的几个要素，即：初始概率，状态转移矩阵，发射矩阵，这三个要素&lt;/p&gt;
&lt;p&gt;这三个要素的运算过程，提及了一下维特比算法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;维特比算法其实是一种动态规划算法，动态规划算法通常用来解决什么问题，在HMM里是怎么使用的？
大致描述了下动态规划的最优解问题，然后结合HMM的迭代过程说了一些。（面试官应该还是想听到HMM的理论，因为HMM推导会用到它里面的假设，然后得到递推关系，就可以分解为子问题，利用维特比算法求解）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;算法题吧：在一个敏感词过滤的场景下，要怎么在一个字符串里找出敏感词的位置？算法复杂度是多少？
面试官应该是想听到KMP一类的算法&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你还有什么问题要问我的吗？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;咱们部门对实习生的预期目标是啥？培养方式和考核方式？&lt;/li&gt;
&lt;li&gt;工作期间的考核情况如何，比如周报、月报、日报这些频繁吗？&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;二面技术面&#34;&gt;二面（技术面）&lt;/h2&gt;
&lt;p&gt;二面也是技术，但是和初面不同的是，二面没有那么关注项目了（但是也是从项目开始问），比较注重理论层面。自初面结束之后，有一周时间的空档，我恶补了基础理论知识，首先是对初面的知识查漏补缺，再刷了剑指offer，捡起了李航《统计学习方法》，基本的机器学习算法以及推导。&lt;strong&gt;面试形式：电话面试&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;个人发现，NLP岗位，很多面试官喜欢问：HMM、CRF、LDA这些知识。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;看你的简历上，在做一个相似性评估的项目，大致介绍下。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;了解，那么获取的词向量你是怎么获取的？&lt;/p&gt;
&lt;p&gt;从word2vec中获取，然后作为模型的输入（讲了一些实验操作）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你的词向量自己训练过吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你知道几种词向量的方法？&lt;/p&gt;
&lt;p&gt;这里说的很详细，我带了一下传统的，如IDF、词袋、LDA，GloVe等偏统计方法，然后具体描述了NNLM下的模型：word2vec（和一面一样，介绍的比较详细），character level CNN Model（英文适用，中文不太适用）；转向RNN结构：传统RNN将序列压缩至向量的过程，LSTM解决RNN长依赖模型，双向语言模型（BiLSTM）；根据双向语言模型，导出了ELMo以及内部细节；主流热门的Transformer系列：Transformer内部细节详细讲了一下，然后转向GPT（Transformer Decoder，单向模型，和之前的双向模型做了个区分），详细说了一下，然后是BERT（Transformer Encoder，双向语言模型，和GPT的对比和ELMo的相同点，以及区别）详解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;安利本人译的一篇综述：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/109564205&#34;&gt;邹智鹏：综述：神经网络语言模型（译）zhuanlan.zhihu.com&lt;img src=&#34;https://pic4.zhimg.com/v2-51ab1d559571ce449cd4580b5a47e697_ipico.jpg&#34; alt=&#34;图标&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果觉得翻译不好的话，建议论文阅读原文[ ]。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;n元模型了解吗，如果共现频率为零怎么解决？&lt;/p&gt;
&lt;p&gt;大致讲了下ngram与n阶马尔可夫。共现为0的解决方案有点忘记了，但是提了一下在GloVe中有提及这个情况的解决方案，但是我也忘记了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;你认为为什么BERT能达到这么好的效果？&lt;/p&gt;
&lt;p&gt;我认为BERT的效果很大程度上取决于Transformer的一个Attention机制，即Self-Attention，正如原文标题《Attention is all you need》，注意力机制很好地找出了文本序列的语义相关度，在语义层面上，能够提取到更关键的特征，比如理解序列中的指示代词。其次是Transformer的结构优势，没有RNN的梯度消失问题，理论上支持任意长度的文本，用了position embedding（区别说明了下Transformer的三角函数和BERT的position embedding的不同）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;注意力机制你了解多少，或者说你了解哪几种？&lt;/p&gt;
&lt;p&gt;注意力机制最初是在CV领域用的比较多，其次被应用到了NLP领域，并且取得了较好的效果。我主要研究NLP比较多，CV了解不深，所以只了解NLP的两种attention。最早的Attention是在seq2seq中提出（或者说Encoder-Decoder模型），讲了下这个模型注意力机制的细节，以及注意力获取的方式，文献名我忘记了，原始的论文应该是NMT相关场景。然后讲了BERT的Self-Attention细节，比如Q、K、V这些。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里到BERT想要继续向后拓展的时候，被面试官打断了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LSTM你了解吗，它的大致结构是怎么样的？&lt;/p&gt;
&lt;p&gt;大概描述了下它的三个门。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;假设输入是$x$维，LSTM的参数量为多少？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;正则化你用过吗，有哪些正则化方法？&lt;/p&gt;
&lt;p&gt;有L1、L2正则化，其他的比如Dropout、Batch Normalization不知道算不算，但是它能达到正则化的效果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文本相似性一般有那几种度量方法？&lt;/p&gt;
&lt;p&gt;&lt;em&gt;之前项目里有过这个相似性的问题，我不知道面试官具体想要的点在哪，就先说了下VSM的基础知识，他又再次深入地问了下，可以用什么模型。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;然后我大致说了下常用的方法，比如最简单的word2vec加权，然后用VSM，RNN得到固定维度的向量后，用VSM，以及这一系列的方法。然后补充说了，利用深度学习转化为二分类的问题的思路和方法，以及BERT中的使用，因为BERT是有做文本相似性任务的。 深度学习之外，还有很多方法，比如主题模型、LDA之类的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;序列标注做过吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HMM和CRF有什么区别？&lt;/p&gt;
&lt;p&gt;&lt;em&gt;之前恶补了HMM的理论，详细讲了HMM，但是CRF只有大概了解，就没仔细说。&lt;/em&gt; HMM的2个假设，正向反向算法（递推式推导），EM算法，维特比算法。CRF打破了两个假设，所以效果更好。（说的比较大概，也和面试官说了这部分不是很了解，只知道个大概）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;传统机器学习算法了解吗，比如XGBoost和SVM这些？&lt;/p&gt;
&lt;p&gt;了解。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;那你讲一下SVM吧。&lt;/p&gt;
&lt;p&gt;讲了下SVM的推导：hard margin, soft margin, 几何距离、函数距离，最优化，拉格朗日乘子法，对偶问题，KKT条件，损失函数，惩罚系数等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为什么SVM求解要求解他的对偶问题？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其实，是因为对偶问题可以降低原问题的计算复杂度。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;三面hr面&#34;&gt;三面（HR面）&lt;/h2&gt;
&lt;p&gt;HR面就不涉及技术了，主要是和HR各种聊，在这之前，看网上很多面经，都说HR面还是很多坑的，即&lt;strong&gt;有套路&lt;/strong&gt;，但是好在面我的HR小哥哥比较真实，没有过分的套路我。&lt;strong&gt;面试形式：视频面试（腾讯会议）&lt;/strong&gt;。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;学校的基本情况，导师是谁，组里的研究方向是啥？&lt;/li&gt;
&lt;li&gt;根据我的研究方向，问了下我们的工作。&lt;/li&gt;
&lt;li&gt;有没有了解行业内你这个领域的一些工作，即你们组的研究方向的落地情况如何？&lt;/li&gt;
&lt;li&gt;聊基本情况，实习时间，毕业要求。&lt;/li&gt;
&lt;li&gt;家庭情况，籍贯、家里成员、父母工作。&lt;/li&gt;
&lt;li&gt;实习地点有没有什么规划？&lt;/li&gt;
&lt;li&gt;HR小哥哥开始介绍他们部门的业务情况，业务方向等等。&lt;/li&gt;
&lt;li&gt;你有没有什么问题？&lt;/li&gt;
&lt;li&gt;那么我这边也没有问题了，整个面试就算通过了，大概一周左右会有通知。（大概意思，算是口头offer）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;小建议&#34;&gt;小建议&lt;/h2&gt;
&lt;p&gt;技术岗，&lt;strong&gt;刷算法题&lt;/strong&gt;！时间来不及就先剑指offer 66道，相对简单，多刷几遍，然后做leetcode。&lt;/p&gt;
&lt;p&gt;算法岗，&lt;strong&gt;基础机器学习算法：SVM、Bayes、DT、Clustering、boosting（Adaboost、GBDT）、bagging（RF）、LR。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;项目，&lt;strong&gt;一定要熟悉，不熟悉的就别往简历上写&lt;/strong&gt;。说不清楚的会被喷的很惨，一定会被diss，甚至会质疑简历真实性。简历上写了的就要再次复盘，要了然于胸，不要忘记了然后讲不明白。&lt;/p&gt;
&lt;p&gt;论文，要熟悉所在领域的一些经典论文模型，里面的细节也要清楚，&lt;strong&gt;最好读原文&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NLP的经典：HMM、CRF、LDA&lt;/strong&gt;，我在很多次面试都碰到这些，重点圈出，个人遭遇，视情况准备吧。&lt;/p&gt;
&lt;p&gt;HR套路，虽然面我的HR没怎么套路我，但是HR毕竟还是要尽量选择稳定的人，所以HR面还是要长心眼，对某些敏感问题的态度要坚决，宗旨：&lt;strong&gt;我爱XX公司，我一定去，工作地点不挑，实习时间能满足&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/117450353&#34;&gt;https://zhuanlan.zhihu.com/p/117450353&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Top 20 Python Libraries for Data Science</title>
      <link>http://csyezheng.github.io/post/machine-learning/top-20-python-libraries/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/machine-learning/top-20-python-libraries/</guid>
      
        <description>&lt;h2 id=&#34;core-libraries--statistics&#34;&gt;Core Libraries &amp;amp; Statistics&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;NumPy&lt;/li&gt;
&lt;li&gt;SciPy&lt;/li&gt;
&lt;li&gt;Pandas&lt;/li&gt;
&lt;li&gt;StatsModels&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;visualization&#34;&gt;Visualization&lt;/h2&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Matplotlib&lt;/li&gt;
&lt;li&gt;Seaborn&lt;/li&gt;
&lt;li&gt;Plotly&lt;/li&gt;
&lt;li&gt;Bokeh&lt;/li&gt;
&lt;li&gt;Pydot&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;machine-learning&#34;&gt;Machine Learning&lt;/h2&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;Scikit-learn&lt;/li&gt;
&lt;li&gt;XGBoost&lt;/li&gt;
&lt;li&gt;Eli5&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deep-learning&#34;&gt;Deep Learning&lt;/h2&gt;
&lt;ol start=&#34;13&#34;&gt;
&lt;li&gt;TensorFlow&lt;/li&gt;
&lt;li&gt;PyTorch&lt;/li&gt;
&lt;li&gt;Keras&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;distributed-deep-learning&#34;&gt;Distributed Deep Learning&lt;/h2&gt;
&lt;ol start=&#34;16&#34;&gt;
&lt;li&gt;Dist-keras / elephas / spark-deep-learning&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;natural-language-processing&#34;&gt;Natural Language Processing&lt;/h2&gt;
&lt;ol start=&#34;17&#34;&gt;
&lt;li&gt;NLTK&lt;/li&gt;
&lt;li&gt;SpaCy&lt;/li&gt;
&lt;li&gt;Gensim&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;data-scraping&#34;&gt;Data Scraping&lt;/h2&gt;
&lt;ol start=&#34;20&#34;&gt;
&lt;li&gt;Scrapy&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Top Websites for Machine Learning</title>
      <link>http://csyezheng.github.io/post/machine-learning/top-websites/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/machine-learning/top-websites/</guid>
      
        <description>&lt;p&gt;&lt;a href=&#34;https://aihub.cloud.google.com/&#34;&gt;AI Hub&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Skincare</title>
      <link>http://csyezheng.github.io/post/health/skincare/</link>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/health/skincare/</guid>
      
        <description>&lt;h1 id=&#34;skincare&#34;&gt;Skincare&lt;/h1&gt;
&lt;h2 id=&#34;cleanse-清洁&#34;&gt;Cleanse (清洁)&lt;/h2&gt;
&lt;h3 id=&#34;oil-cleanser&#34;&gt;oil cleanser&lt;/h3&gt;
&lt;h3 id=&#34;mild-cleanser&#34;&gt;mild cleanser&lt;/h3&gt;
&lt;p&gt;油性皮肤用用 38～40 度的热水比较好。比皮表温度稍高但又不觉得烫，容易把溢出的油脂洗掉。&lt;/p&gt;
&lt;p&gt;使用尽量柔软的毛巾，毛巾每周清洗、日晒，保持清洁。&lt;/p&gt;
&lt;p&gt;先把洗面奶挤在手上搓出泡沫，在往脸上扑，而不是直接在脸上搓泡沫，减少洗脸的时候对角质层的摩擦。&lt;/p&gt;
&lt;p&gt;洗完脸用毛巾擦脸的时候不要太使劲，减少摩擦。&lt;/p&gt;
&lt;p&gt;洗完脸，要及时擦干，使用爽肤水。&lt;/p&gt;
&lt;h4 id=&#34;cetaphil&#34;&gt;Cetaphil&lt;/h4&gt;
&lt;p&gt;Cetaphil cleanser has a high ph level which isn&amp;rsquo;t really ideal for a cleanser, so if you&amp;rsquo;re planning to buy one, then don&amp;rsquo;t. Look for a gentler one and do some research.&lt;/p&gt;
&lt;p&gt;Cleanser: Cetaphil&lt;/p&gt;
&lt;p&gt;Eye cream: CeraVe&lt;/p&gt;
&lt;p&gt;Moisturizer: CeraVe&lt;/p&gt;
&lt;p&gt;sunscreen: CeraVe&lt;/p&gt;
&lt;h2 id=&#34;toner-爽肤水&#34;&gt;Toner (爽肤水)&lt;/h2&gt;
&lt;p&gt;Simple Kind To Skin Soothing Facial Toner&lt;/p&gt;
&lt;h2 id=&#34;moisturizer-保湿霜&#34;&gt;Moisturizer (保湿霜)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cerave&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sunscreen-防晒霜&#34;&gt;Sunscreen (防晒霜)&lt;/h2&gt;
&lt;p&gt;每日查看UV index高于3，则抹防晒霜，UV index高于6就要尽量减少出门以及曝光时间了！&lt;/p&gt;
&lt;h4 id=&#34;碧柔&#34;&gt;碧柔&lt;/h4&gt;
&lt;p&gt;Biore Watery Essence，更适合涂脸。Biore water gel 更适合涂身体。&lt;/p&gt;
&lt;p&gt;抗氧化衰老长斑，不防晒黑，日常通勤足够用了。&lt;/p&gt;
&lt;h4 id=&#34;安耐晒&#34;&gt;安耐晒&lt;/h4&gt;
&lt;p&gt;防晒效果更好，长时间户外运动。&lt;/p&gt;
&lt;p&gt;If you’re planning a vacation by the sea or in the mountains, &lt;strong&gt;ANESSA&lt;/strong&gt; must be your first choise. If you just walk 20 minutes a day to work, &lt;strong&gt;Biore&lt;/strong&gt; will surprise you.&lt;/p&gt;
&lt;h2 id=&#34;other&#34;&gt;Other&lt;/h2&gt;
&lt;h3 id=&#34;sheet-masks-防毒面具&#34;&gt;Sheet masks (防毒面具)&lt;/h3&gt;
&lt;p&gt;If you plan to use sheet masks, cleanse and use the toner. Then apply the sheet mask for 15 minutes and then apply a small amount of moisturizer.&lt;/p&gt;
&lt;h3 id=&#34;exfoliant-去角质霜&#34;&gt;Exfoliant (去角质霜)&lt;/h3&gt;
&lt;p&gt;Mizon 8% AHA Peeling Serum (new)&lt;/p&gt;
&lt;p&gt;If you plan to use the exfoliant, cleanse first then exfoliate, then toner, then moisturizer.&lt;/p&gt;
&lt;h4 id=&#34;eye-cream&#34;&gt;Eye Cream&lt;/h4&gt;
&lt;p&gt;Mizon Snail Repair Eye Cream&lt;/p&gt;
&lt;h2 id=&#34;last-but-no-least&#34;&gt;Last but no least&lt;/h2&gt;
&lt;h3 id=&#34;change-pillow-cases&#34;&gt;change pillow cases&lt;/h3&gt;
&lt;p&gt;change your pillow cases every 2-3 days&lt;/p&gt;
&lt;h3 id=&#34;drink-water&#34;&gt;drink water&lt;/h3&gt;
&lt;p&gt;drink water. It&amp;rsquo;s good for your overall body not just the face.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://np.reddit.com/r/AsianBeauty/wiki/new_user_guide&#34;&gt;http://np.reddit.com/r/AsianBeauty/wiki/new_user_guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://np.reddit.com/r/AsianBeauty/wiki/theabroutine&#34;&gt;http://np.reddit.com/r/AsianBeauty/wiki/theabroutine&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Bigger Leaner Stronger 5-DAY WORKOUT ROUTINE</title>
      <link>http://csyezheng.github.io/post/health/bls-5-day-workout-routine/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/health/bls-5-day-workout-routine/</guid>
      
        <description>&lt;h2 id=&#34;phase-1&#34;&gt;PHASE 1&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--push&#34;&gt;WORKOUT 1 | PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press(斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press(哑铃卧推)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Triceps Pushdown(肱三头肌下拉)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--pull-and-calves&#34;&gt;WORKOUT 2 | PULL AND CALVES&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift (杠铃硬拉)&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;One-Arm Dumbbell Row (单臂哑铃划船)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Wide-Grip) (宽握高位下拉)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press Calf Raise* (腿举)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--upper-body-and-core&#34;&gt;WORKOUT 3 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Seated Dumbbell Press (坐姿哑铃推举)&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Side Lateral Raise* (哑铃侧平举)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Rear Lateral Raise (Seated)*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cable Crunch&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-4--legs&#34;&gt;WORKOUT 4 | LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-5--upper-body-and-core&#34;&gt;WORKOUT 5 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Close-Grip Bench Press&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Curl&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Triceps Press&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Hammer Curl&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Captain’s Chair Leg Raise&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;deload-1&#34;&gt;DELOAD 1&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--deload-push&#34;&gt;WORKOUT 1 | DELOAD PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press (哑铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--deload-pull&#34;&gt;WORKOUT 2 | DELOAD PULL&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Row&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press(哑铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--deload-legs&#34;&gt;WORKOUT 3 | DELOAD LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;phase-2&#34;&gt;PHASE 2&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--push-1&#34;&gt;WORKOUT 1 | PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Dumbbell Bench Press&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lying Triceps Extension(“Skullcrusher”)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--pull-and-calves-1&#34;&gt;WORKOUT 2 | PULL AND CALVES&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Cable Row (Wide-Grip)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Close-Grip)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--upper-body-and-core-1&#34;&gt;WORKOUT 3 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Arnold Dumbbell Press&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Rear Delt Row&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Side Lateral Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Captain’s Chair Leg Raise&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-4--legs-1&#34;&gt;WORKOUT 4 | LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Romanian Deadlift&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Lunge (In-Place)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Standing Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-5--upper-body-and-core-1&#34;&gt;WORKOUT 5 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dip*&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Hammer Curl&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Triceps Pushdown&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Curl&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Plank&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;deload-2&#34;&gt;DELOAD 2&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--deload-push-1&#34;&gt;WORKOUT 1 | DELOAD PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press  (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press(哑铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--deload-pull-1&#34;&gt;WORKOUT 2 | DELOAD PULL&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Row&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Wide-Grip)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--deload-legs-1&#34;&gt;WORKOUT 3 | DELOAD LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;phase-3&#34;&gt;PHASE 3&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--push-2&#34;&gt;WORKOUT 1 | PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press(哑铃卧推)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Triceps Pushdown&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--pull-and-calves-2&#34;&gt;WORKOUT 2 | PULL AND CALVES&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Row&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Chin-Up&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Standing Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--upper-body-and-core-2&#34;&gt;WORKOUT 3 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Seated Dumbbell Press&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Side Lateral Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Rear Lateral Raise(Bent-Over)*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Plank&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-4--legs-2&#34;&gt;WORKOUT 4 | LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Lunge (Reverse)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-5--upper-body-and-core-2&#34;&gt;WORKOUT 5 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Close-Grip Bench Press&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;E-Z Bar Curl&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Triceps Press&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Hammer Curl&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Weighted Sit-Up&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;deload-3&#34;&gt;DELOAD 3&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--deload-push-2&#34;&gt;WORKOUT 1 | DELOAD PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press(哑铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--deload-pull-2&#34;&gt;WORKOUT 2 | DELOAD PULL&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Row&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Wide-Grip)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--deload-legs-2&#34;&gt;WORKOUT 3 | DELOAD LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;phase-4&#34;&gt;PHASE 4&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--push-3&#34;&gt;WORKOUT 1 | PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Dumbbell Bench Press&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lying Triceps Extension(“Skullcrusher”)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--pull-and-calves-3&#34;&gt;WORKOUT 2 | PULL AND CALVES&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;One-Arm Dumbbell Row&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Wide-Grip)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--upper-body-and-core-3&#34;&gt;WORKOUT 3 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Arnold Dumbbell Press&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Rear Delt Row&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Side Lateral Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Weighted Sit-Up&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-4--legs-3&#34;&gt;WORKOUT 4 | LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Romanian Deadlift&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Single-Leg Split Squat&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-5--upper-body-and-core-3&#34;&gt;WORKOUT 5 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dip*&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alternating Dumbbell Curl&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Triceps Pushdown&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;E-Z Bar Curl&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hanging Leg Raise&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;deload-4&#34;&gt;DELOAD 4&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--deload-push-3&#34;&gt;WORKOUT 1 | DELOAD PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press(哑铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--deload-pull-3&#34;&gt;WORKOUT 2 | DELOAD PULL&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Row&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Wide-Grip)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--deload-legs-3&#34;&gt;WORKOUT 3 | DELOAD LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;phase-5&#34;&gt;PHASE 5&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--push-4&#34;&gt;WORKOUT 1 | PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press(哑铃卧推)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Triceps Pushdown&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--pull-and-calves-4&#34;&gt;WORKOUT 2 | PULL AND CALVES&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Cable Row (Close-Grip)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Close-Grip)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--upper-body-and-core-4&#34;&gt;WORKOUT 3 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Seated Dumbbell Press&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Side Lateral Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Rear Delt Row&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lying Leg Raise&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-4--legs-4&#34;&gt;WORKOUT 4 | LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Single-Leg Split Squat&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Standing Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-5--upper-body-and-core-4&#34;&gt;WORKOUT 5 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Close-Grip Bench Press&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Curl&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Seated Triceps Press&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alternating Dumbbell Curl&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Abdominal Rollout&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;deload-5&#34;&gt;DELOAD 5&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--deload-push-4&#34;&gt;WORKOUT 1 | DELOAD PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press(哑铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--deload-pull-4&#34;&gt;WORKOUT 2 | DELOAD PULL&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Row&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Wide-Grip)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--deload-legs-4&#34;&gt;WORKOUT 3 | DELOAD LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;phase-6&#34;&gt;PHASE 6&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--push-5&#34;&gt;WORKOUT 1 | PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Dumbbell Bench Press&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lying Triceps Extension(“Skullcrusher”)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--pull-and-calves-5&#34;&gt;WORKOUT 2 | PULL AND CALVES&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Row&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pull-Up&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Standing Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--upper-body-and-core-5&#34;&gt;WORKOUT 3 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Arnold Dumbbell Press&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Rear Delt Row&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Side Lateral Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Abdominal Rollout&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-4--legs-5&#34;&gt;WORKOUT 4 | LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Romanian Deadlift&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Lunge (Walking)&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press Calf Raise*&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-5--upper-body-and-core-5&#34;&gt;WORKOUT 5 | UPPER BODY AND CORE&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dip*&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Hammer Curl&lt;/td&gt;
&lt;td&gt;Warm-up and 3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Triceps Pushdown&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Curl&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Weighted Sit-Up&lt;/td&gt;
&lt;td&gt;3 hard sets&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;deload-6&#34;&gt;DELOAD 6&lt;/h2&gt;
&lt;h4 id=&#34;workout-1--deload-push-5&#34;&gt;WORKOUT 1 | DELOAD PUSH&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Bench Press (杠铃卧推)&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Incline Barbell Bench Press (斜杠铃卧推)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dumbbell Bench Press&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-2--deload-pull-5&#34;&gt;WORKOUT 2 | DELOAD PULL&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Deadlift&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Row&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lat Pulldown (Wide-Grip)&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;workout-3--deload-legs-5&#34;&gt;WORKOUT 3 | DELOAD LEGS&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Barbell Squat&lt;/td&gt;
&lt;td&gt;Warm-up and 2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Press&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Leg Curl (Lying or Seated)*&lt;/td&gt;
&lt;td&gt;2 sets of 3 reps with last hard-set weight&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
      
    </item>
    
    <item>
      <title>workout</title>
      <link>http://csyezheng.github.io/post/health/workout/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/health/workout/</guid>
      
        <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Barbell Bench Press (杠铃卧推)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://5b0988e595225.cdn.sohucs.com/images/20180322/aa0a1bde910643dabb999b9a3dcee6a6.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Incline Barbell Bench Press(斜杠铃卧推)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://09imgmini.eastday.com/mobile/20191023/2019102312_1b11b8e01a3a4134b76f43e0b2bb2279_0427.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dumbbell Bench Press(哑铃卧推)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic4.zhimg.com/v2-664ad0c87755d121160782d81a1547cf_b.webp&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Triceps Pushdown(肱三头肌下拉)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.mp.itc.cn/upload/20170730/9e93b96db66d4a83bd8a93221c78f532_th.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Barbell Deadlift (杠铃硬拉)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.mp.itc.cn/upload/20160906/6bab46ef41164e0cb902000d48bd676b.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One-Arm Dumbbell Row (单臂哑铃划船)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic.rmb.bdstatic.com/9933e9835d7a8290fc3d3a92411078a53820.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hiphotos.baidu.com/feed/pic/item/d4628535e5dde7112553be13abefce1b9c166156.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lat Pulldown (Wide-Grip) (宽握高位下拉)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hiphotos.baidu.com/feed/pic/item/6a600c338744ebf86d8499dad5f9d72a6159a75a.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Leg Press Calf Raise* (腿举)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://02.imgmini.eastday.com/mobile/20171106/20171106105141_25e75f88fa6a404730953d1b0ab48e87_16.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Seated Dumbbell Press (坐姿哑铃推举)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://5b0988e595225.cdn.sohucs.com/images/20180717/5a37e7d636c744449f0fe8791b94b475.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dumbbell Side Lateral Raise*&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://5b0988e595225.cdn.sohucs.com/images/20180717/73993cb12ac544abbc06207695cbbfff.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Search Architecture</title>
      <link>http://csyezheng.github.io/post/back-end/search-architecture/</link>
      <pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/back-end/search-architecture/</guid>
      
        <description>&lt;h2 id=&#34;搜索服务使用说明&#34;&gt;搜索服务使用说明&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;&lt;script src=&#34;http://csyezheng.github.io/js/raphael.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://csyezheng.github.io/js/flowchart.min.js&#34;&gt;&lt;/script&gt;
&lt;div id=&#34;diagram-draw&#34; align=&#34;center&#34;&gt;&lt;/div&gt;
&lt;script id=&#34;code&#34;&gt;
	&#34;\nst=\u003estart: 开始\ne=\u003eend: 结束\n\nop1=\u003eoperation: 服务订阅\ncond1=\u003econdition: 是否已创建应用\nop2=\u003eoperation: 订阅成功\nop3=\u003eoperation: 服务管理\nop4=\u003eoperation: 服务创建\npara1=\u003eparallel: 选择服务类型\nst(right)-\u003eop1-\u003econd1\ncond1(yes)-\u003eop2-\u003eop3-\u003eop4-\u003epara1\ncond1(no)-\u003eop1\n\nop5=\u003eoperation: 垂直搜索\nop6=\u003eoperation: 统一搜索\nop7=\u003eoperation: 空白模板\npara2=\u003eparallel: 数据接入\nop201=\u003eoperation: 勾选垂直搜索\nop202=\u003eoperation: 流程配置\ncond201=\u003econdition: 用户是否分流\npara1(path1, bottom)-\u003eop5-\u003eop7-\u003epara2\npara1(path2, right)-\u003eop6-\u003eop201-\u003eop202-\u003econd201\n\nop8=\u003eoperation: 流计算-\u003eMySQL: \npara3=\u003eparallel: 搜索配置\npara2(path1, left)-\u003eop8\npara2(path2, bottom)-\u003epara3\n\nop11=\u003eoperation: Query参数\nop12=\u003eoperation: Query理解\nop13=\u003eoperation: Query理解\npara4=\u003eparallel: 智能交互\npara3(path1, left)-\u003eop11(bottom)-\u003eop12(bottom)-\u003eop13\npara3(path2, bottom)-\u003epara4\n\nop14=\u003eoperation: 联想字段\nop15=\u003eoperation: 测试\nop16=\u003eoperation: 发布\nop17=\u003eoperation: 生成服务ID\npara4(path1, right)-\u003eop14\npara4(path2, bottom)-\u003eop15-\u003eop16-\u003eop17\n\ncond202=\u003econdition: 是否识别意图\nop203=\u003eoperation: 内容节点\nop204=\u003eoperation: 测试\nop205=\u003eoperation: 发布\ncond201(yes)-\u003econd202\ncond201(no)-\u003eop203\ncond202(yes)-\u003eop203\ncond202(no)-\u003eop203\nop203-\u003eop204-\u003eop205-\u003eop17\n&#34;
	var source = document.getElementById( &#34;code&#34; ).innerText;
	source = source.replace(/\\n/g, &#39;\n&#39;);
	source = source.replace(/\\u003e/g, &#39;&gt;&#39;);
	source = source.replace(/\\&#34;/g, &#39;&#34;&#39;);
	var diagram = flowchart.parse( source );
	diagram.drawSVG( &#39;diagram-draw&#39; );
&lt;/script&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;
&lt;script src=&#34;http://csyezheng.github.io/js/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://csyezheng.github.io/js/mindmap.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://csyezheng.github.io/js/kity.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://csyezheng.github.io/js/kityminder.core.min.js&#34;&gt;&lt;/script&gt;


&lt;link rel=&#34;stylesheet&#34; href=&#34;http://csyezheng.github.io/css/mindmap.css&#34; /&gt;


&lt;div id=&#34;&#34; class=&#34;mindmap mindmap-lg&#34;&gt;
    &lt;ul&gt;
&lt;li&gt;搜索运营
&lt;ul&gt;
&lt;li&gt;运营分析
&lt;ul&gt;
&lt;li&gt;Dashboard
&lt;ul&gt;
&lt;li&gt;TopN&lt;/li&gt;
&lt;li&gt;dashboard&lt;/li&gt;
&lt;li&gt;badcase&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;热搜词统计&lt;/li&gt;
&lt;li&gt;用户行为明细&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;词库管理
&lt;ul&gt;
&lt;li&gt;同义词
&lt;ul&gt;
&lt;li&gt;手动新增&lt;/li&gt;
&lt;li&gt;自动挖掘&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;专有名词&lt;/li&gt;
&lt;li&gt;听用词&lt;/li&gt;
&lt;li&gt;核心词&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;业务管理
&lt;ul&gt;
&lt;li&gt;直通车&lt;/li&gt;
&lt;li&gt;黑名单&lt;/li&gt;
&lt;li&gt;提示次&lt;/li&gt;
&lt;li&gt;敏感词&lt;/li&gt;
&lt;li&gt;纠错词&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;query-understanding-framework-architecture&#34;&gt;Query Understanding Framework Architecture&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.mdpi.com/applsci/applsci-10-01127/article_deploy/html/images/applsci-10-01127-g003-550.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;spatial-and-temporal-parsing&#34;&gt;Spatial and Temporal Parsing&lt;/h4&gt;
&lt;h4 id=&#34;concept-recognition&#34;&gt;Concept Recognition&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.mdpi.com/applsci/applsci-10-01127/article_deploy/html/images/applsci-10-01127-g004-550.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;named-entity-recognition&#34;&gt;Named Entity Recognition&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.mdpi.com/applsci/applsci-10-01127/article_deploy/html/images/applsci-10-01127-g005-550.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;query-expansion&#34;&gt;Query Expansion&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.mdpi.com/applsci/applsci-10-01127/article_deploy/html/images/applsci-10-01127-g006-550.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;system-design&#34;&gt;System Design&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.mdpi.com/applsci/applsci-10-01127/article_deploy/html/images/applsci-10-01127-g007.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Bigger Leaner Stronger</title>
      <link>http://csyezheng.github.io/post/health/bigger-leaner-stronger/</link>
      <pubDate>Sat, 20 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/health/bigger-leaner-stronger/</guid>
      
        <description>&lt;h3 id=&#34;workouts&#34;&gt;Workouts&lt;/h3&gt;
&lt;h3 id=&#34;meal-plans&#34;&gt;Meal Plans&lt;/h3&gt;
&lt;h2 id=&#34;part-1-whats-in-this-for-you&#34;&gt;Part 1: What’s in This for You?&lt;/h2&gt;
&lt;h4 id=&#34;1-the-promise&#34;&gt;1. The Promise&lt;/h4&gt;
&lt;p&gt;You absolutely, positively can have the lean, muscular, and powerful body that you dream about.&lt;/p&gt;
&lt;h4 id=&#34;2-who-is-mike-matthews-and-why-should-i-care&#34;&gt;2. Who Is Mike Matthews and Why Should I Care?&lt;/h4&gt;
&lt;h4 id=&#34;3-why-bigger-leaner-stronger-is-different&#34;&gt;3. Why Bigger Leaner Stronger Is Different&lt;/h4&gt;
&lt;h2 id=&#34;part-2-key-things-they-arent-telling-you&#34;&gt;Part 2: Key Things “They” Aren’t Telling You&lt;/h2&gt;
&lt;h4 id=&#34;4-the-hidden-barrier&#34;&gt;4. The Hidden Barrier&lt;/h4&gt;
&lt;h4 id=&#34;5-what-most-men-will-never-know-about-getting-fit--part-1&#34;&gt;5. What Most Men Will Never Know about Getting Fit – Part 1&lt;/h4&gt;
&lt;h4 id=&#34;6-what-most-men-will-never-know-about-getting-fit--part-2&#34;&gt;6. What Most Men Will Never Know about Getting Fit – Part 2&lt;/h4&gt;
&lt;h4 id=&#34;7-the-10-absolute-worst-fat-loss-myths-and-mistakes&#34;&gt;7. The 10 Absolute Worst Fat Loss Myths and Mistakes&lt;/h4&gt;
&lt;h4 id=&#34;8-the-10-absolute-worst-muscle-building-myths-and-mistakes&#34;&gt;8. The 10 Absolute Worst Muscle-Building Myths and Mistakes&lt;/h4&gt;
&lt;h4 id=&#34;9-the-3-little-big-things-about-rapid-fat-loss&#34;&gt;9. The 3 Little Big Things about Rapid Fat Loss&lt;/h4&gt;
&lt;h4 id=&#34;10-the-3-little-big-things-about-building-lean-muscle&#34;&gt;10. The 3 Little Big Things about Building Lean Muscle&lt;/h4&gt;
&lt;h2 id=&#34;part-3-how-to-win-the-inner-game-of-getting-fit&#34;&gt;Part 3: How to Win the “Inner Game” of Getting Fit&lt;/h2&gt;
&lt;h4 id=&#34;11-the-great-inner-game-secret&#34;&gt;11. The Great “Inner Game” Secret&lt;/h4&gt;
&lt;h4 id=&#34;12-the-anatomy-of-willpower&#34;&gt;12. The Anatomy of Willpower&lt;/h4&gt;
&lt;h4 id=&#34;13-13-easy-ways-to-boost-your-willpower-and-self-control&#34;&gt;13. 13 Easy Ways to Boost Your Willpower and Self-Control&lt;/h4&gt;
&lt;h4 id=&#34;14-use-it-or-lose-it-how-to-train-your-willpower&#34;&gt;14. Use It or Lose It: How to Train Your Willpower&lt;/h4&gt;
&lt;h4 id=&#34;15-finding-your-biggest-fitness-whys&#34;&gt;15. Finding Your Biggest Fitness Whys&lt;/h4&gt;
&lt;h2 id=&#34;part-4-the-last-diet-advice-youll-ever-need&#34;&gt;Part 4: The Last Diet Advice You’ll Ever Need&lt;/h2&gt;
&lt;h4 id=&#34;16-welcome-to-the-wonderful-world-of-flexible-dieting&#34;&gt;16. Welcome to the Wonderful World of Flexible Dieting&lt;/h4&gt;
&lt;h4 id=&#34;17-the-easiest-way-to-calculate-your-calories-and-macros&#34;&gt;17. The Easiest Way to Calculate Your Calories and Macros&lt;/h4&gt;
&lt;h4 id=&#34;18-the-truth-about-preworkout-and-postworkout-nutrition&#34;&gt;18. The Truth about Preworkout and Postworkout Nutrition&lt;/h4&gt;
&lt;h4 id=&#34;19-how-to-make-meal-plans-that-really-work&#34;&gt;19. How to Make Meal Plans That Really Work&lt;/h4&gt;
&lt;h4 id=&#34;20-how-to-cheat-on-your-diet-without-ruining-it&#34;&gt;20. How to “Cheat” on Your Diet Without Ruining It&lt;/h4&gt;
&lt;h2 id=&#34;part-5-the-last-exercise-advice-youll-ever-need&#34;&gt;Part 5: The Last Exercise Advice You’ll Ever Need&lt;/h2&gt;
&lt;h4 id=&#34;21-the-ultimate-workout-plan-for-men--strength-training&#34;&gt;21. The Ultimate Workout Plan for Men – Strength Training&lt;/h4&gt;
&lt;h4 id=&#34;22-the-ultimate-workout-plan-for-men--cardio&#34;&gt;22. The Ultimate Workout Plan for Men – Cardio&lt;/h4&gt;
&lt;h4 id=&#34;23-the-best-exercises-for-building-your-best-body-ever&#34;&gt;23. The Best Exercises for Building Your Best Body Ever&lt;/h4&gt;
&lt;h4 id=&#34;24-the-definitive-guide-to-the-big-three&#34;&gt;24. The Definitive Guide to the “Big Three”&lt;/h4&gt;
&lt;h2 id=&#34;part-6-dont-buy-another-supplement-until-you-read-this&#34;&gt;Part 6: Don’t Buy Another Supplement Until You Read This&lt;/h2&gt;
&lt;h4 id=&#34;25-the-great-supplement-hoax&#34;&gt;25. The Great Supplement Hoax&lt;/h4&gt;
&lt;h4 id=&#34;26-the-smart-supplement-buyers-guide&#34;&gt;26. The Smart Supplement Buyer’s Guide&lt;/h4&gt;
&lt;h2 id=&#34;part-7-the-bigger-leaner-stronger-program&#34;&gt;Part 7: The Bigger Leaner Stronger Program&lt;/h2&gt;
&lt;h4 id=&#34;27-you-paint-by-the-numbers-your-body-does-the-rest&#34;&gt;27. You Paint by the Numbers, Your Body Does the Rest&lt;/h4&gt;
&lt;h4 id=&#34;28-the-bigger-leaner-stronger-diet-plan&#34;&gt;28. The Bigger Leaner Stronger Diet Plan&lt;/h4&gt;
&lt;h4 id=&#34;29-the-bigger-leaner-stronger-training-plan&#34;&gt;29. The Bigger Leaner Stronger Training Plan&lt;/h4&gt;
&lt;h4 id=&#34;30-the-bigger-leaner-stronger-supplementation-plan&#34;&gt;30. The Bigger Leaner Stronger Supplementation Plan&lt;/h4&gt;
&lt;h4 id=&#34;31-the-right-and-wrong-ways-to-track-your-progress&#34;&gt;31. The Right and Wrong Ways to Track Your Progress&lt;/h4&gt;
&lt;h4 id=&#34;32-how-to-break-through-weight-loss-plateaus&#34;&gt;32. How to Break Through Weight Loss Plateaus&lt;/h4&gt;
&lt;h4 id=&#34;33-how-to-break-through-weight-gain-plateaus&#34;&gt;33. How to Break Through Weight Gain Plateaus&lt;/h4&gt;
&lt;h2 id=&#34;part-8-the-beginning&#34;&gt;Part 8: The Beginning&lt;/h2&gt;
&lt;h4 id=&#34;34-the-bigger-leaner-stronger-quickstart-guide&#34;&gt;34. The Bigger Leaner Stronger Quickstart Guide&lt;/h4&gt;
&lt;h4 id=&#34;35-from-here-your-body-will-change&#34;&gt;35. From Here, Your Body Will Change&lt;/h4&gt;
&lt;h4 id=&#34;36-frequently-asked-questions&#34;&gt;36. Frequently Asked Questions&lt;/h4&gt;
&lt;h4 id=&#34;37-would-you-do-me-a-favor&#34;&gt;37. Would You Do Me a Favor?&lt;/h4&gt;
</description>
      
    </item>
    
    <item>
      <title>Bert</title>
      <link>http://csyezheng.github.io/post/deep-learning/bert/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/deep-learning/bert/</guid>
      
        <description>&lt;h1 id=&#34;bert-可解释性-从头说起&#34;&gt;BERT 可解释性-从&amp;quot;头&amp;quot;说起&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;一、背景介绍&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;搜索场景下用户搜索的 query 和召回文章标题(title)的相关性对提升用户的搜索体验有很大帮助。query-title 分档任务要求针对 query 和 title 按文本相关性进行 5 个档位的分类(1~5 档)，各档位从需求满足及语义匹配这两方面对 query-doc 的相关度进行衡量，档位越大表示相关性越高，如 1 档表示文本和语义完全不相关，而 5 档表示文本和语义高度相关，完全符合 query 的需求。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic2.zhimg.com/80/v2-58cac5479dcc451b4d30133b67fb8c5d_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们尝试将 Bert 模型应用在 query-title 分档任务上，将 query 和 title 作为句对输入到 bert 中，取最后一层 cls 向量用做 5 分类(如上图)，最后得到的结果比 LSTM-Attention 交互式匹配模型要好。虽然知道了 bert&lt;strong&gt;能&lt;/strong&gt;解决这个问题，我们更好奇的是&amp;rdquo;&lt;strong&gt;为什么&lt;/strong&gt;&amp;quot;：为什么 bert 的表现能这么好？这里面有没有可解释的部分呢？&lt;/p&gt;
&lt;p&gt;因为 Multi-head-attention 是 bert 的主要组成部分，所以我们从&amp;quot;头&amp;quot;入手，希望弄清楚各个 head 对 bert 模型有什么作用。为了研究某个 head 对模型的影响，我们需要比较有这个 head 和没有这个 head 模型的前后表现。这里定义一下 HEAD-MASK 操作，其实就是针对某个 head，直接将这个 head 的 attention 值置成 0，这样对于任何输入这个 head 都只能输出 0 向量。&lt;/p&gt;
&lt;p&gt;通过 HEAD-MASK 操作对各个 head 进行对比实验，发现了下面几个有趣的点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;attention-head 很冗余/鲁棒，去掉 20%的 head 模型不受影响&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;各层 transformer 之间不是串行关系，去掉一整层 attention-head 对下层影响不大&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;各个 head 有固定的功能&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;某些 head 负责分词&lt;/li&gt;
&lt;li&gt;某些 head 提取语序关系&lt;/li&gt;
&lt;li&gt;某些 head 负责提取 query-title 之间 term 匹配关系&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面我们开始实验正文，看看这些结论是怎么得到的&lt;/p&gt;
&lt;h3 id=&#34;二bert-模型-attention-head-实验&#34;&gt;&lt;strong&gt;二、Bert 模型 Attention-Head 实验&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;attention-head 是 bert 的基本组成模块，本次实验想要研究各个 head 都对模型作出了什么贡献。通过 Mask 掉某个 head，对比模型前后表现的差异来研究这个 head 对模型有什么样的作用(对训练好的 bert 做 head-mask，不重新训练，对比测试集的表现)。&lt;/p&gt;
&lt;p&gt;bert-base 模型共 12 层每层有 12 个 head，下面实验各个 head 提取的特征是否有明显的模式(Bert 模型为在 query-title 数据上 finetune 好的中文&lt;strong&gt;字&lt;/strong&gt;模型)&lt;/p&gt;
&lt;h3 id=&#34;21-attention-head-比较冗余&#34;&gt;&lt;strong&gt;2.1 Attention-Head 比较冗余&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;标准大小的 bert 一共有 12*12 共 144 个 head.我们尝试对训练好的 bert 模型，随机 mask 掉一定比例的 head,再在测试数据集上测试分档的准确率(&lt;strong&gt;五分类&lt;/strong&gt;)。&lt;/p&gt;
&lt;p&gt;下图的柱状图的数值表示相比于 bseline(也就是不做任何 head-mask)模型 acc 的相对提升,如+1%表示比 baseline 模型的 acc 相对提高了 1%，从下面的图可以看到，随机 mask 掉低于 20%的 head，在测试数据集上模型的 acc 不会降低，甚至当 mask 掉 10%的 head 的时候模型表现比不做 head mask 的时候还提升了 1%。当 mask 掉超过一定数量的 head 后，模型表现持续下降，mask 掉越多表现越差。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic3.zhimg.com/80/v2-5725214f86d8232f6060e7177d0e92ca_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;同时为了弄清楚底层和高层的 transformer 哪个对于 query-title 分类更加的重要，分别对底层(layer0 ~ layer5 )和高层(layer6~layer11)的 head 做 mask, 去掉的 head 比例控制在 0~50%(占总 head 数量)之间，50%表示去掉了底层或者是高层 100%的 head 下面的图很清晰的说明了底层和高层的 attention-head 关系，橙色部分表示只 mask 掉高层(6 - 11 层)的 head,蓝色部分表示只 mask 掉底层(0 - 5 层)的 head。&lt;/p&gt;
&lt;p&gt;显然高层的 attention-head 非常的依赖底层的 head，底层的 attention-head 负责提取输入文本的各种特征，而高层的 attention 负责将这些特征结合起来。具体表现在当 mask 掉底层(0~5 层)的 80%的 head(图中横坐标为 40%)和 mask 掉底层的 100%的 head(图中横坐标为 50%)时，模型在测试数据集上表现下降剧烈(图中蓝色部分)，说明了去掉大部分的底层 head 后只依赖高层的 head 是不行的，高层的 head 并没有提取输入的特征。相反去掉大部分高层的 head 后模型下降的并没有那么剧烈(图中橙色部分)，说明了底层的 head 提取到了很多对于本任务有用的输入特征，这部分特征通过残差连接可以直接传导到最后一层用做分类。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic2.zhimg.com/80/v2-39143ffec66598679568a993dac38b69_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;这个结论后面也可以用于指导模型蒸馏，实验结果表明底层的 transformer 比高层的 transformer 更加的重要，显然我们在蒸馏模型时需要保留更多的底层的 head&lt;/p&gt;
&lt;p&gt;那么对于模型来说是否有某些层的 head 特别能影响 query-title 分类呢？假设将 bert 中所有的 attention-head 看做一个 12*12 的方阵，下面是按行 mask 掉一整行 head 后模型在测试数据上的表现，柱状图上的数值表示相比 baseline 模型的相对提升。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic4.zhimg.com/80/v2-e19db86266c333175066bf06d28c21bb_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到 mask 掉第 5 层～第 9 层的 head 都模型都有比较大的正面提升，特别是当去掉整个第 8 层的 attention-head 的时候测试数据准确率相对提升了 2.3%，从上图可以得到两个结论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bert 模型非常的健壮或者是冗余度很高&lt;/li&gt;
&lt;li&gt;Bert 模型各层之间不是串行依赖的关系，信息并不是通过一层一层 transformer 层来传递的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;bert 模型非常的健壮或者是冗余度很高，直接去掉一整层的 attention-head 并不会对模型的最终表现有太大的影响。 直接去掉整层的 attention-head 模型表现并没有大幅度的下降，说明各层提取的特征信息并不是一层一层的串行传递到分类器的，而是通过残差连接直接传导到对应的层。&lt;/p&gt;
&lt;h3 id=&#34;22-某些-head-负责判断词的边界使得字模型带有分词信息&#34;&gt;&lt;strong&gt;2.2 某些 head 负责判断词的边界(使得字模型带有分词信息)&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在我们的 query-title 分档场景中，发现词粒度的 bert 和字粒度的 bert 最终的表现是差不多的，而对于 rnn 模型来说字粒度的 rnn 很难达到词粒度 rnn 的效果，我们希望研究一下为什么词粒度和字粒度的 bert 表现差不多。&lt;/p&gt;
&lt;p&gt;使用的 bert 可视化工具**&lt;a href=&#34;https://link.zhihu.com/?target=https%3A//github.com/jessevig/bertviz&#34;&gt;bert_viz&lt;/a&gt;**&lt;img src=&#34;https://www.zhihu.com/equation?tex=%5E%7B%5B2%5D%7D&#34; alt=&#34;[公式]&#34;&gt;观察各层 attention-head 的 attention 权重分布，可以发现某些 head 带有很明显的分词信息。推测这部分 attention-head 是专门用于提取分词信息的 head。当当前的字可能是词的结尾时，att 权重会偏向 sep,当这个字为词的结尾可能性越大(常见的词结尾)，sep 的权重会越高。当当前字不是词结尾时，att 会指向下一个字。**这种模式非常明显，直接拿这个 attention-head 的结果用于分词准确率为 70%。**&lt;/p&gt;
&lt;p&gt;下面 gif 为我们模型中第 1 层第 3 个 head 的 attention 分布权重图，可以发现 attention 权重很明显带有词的边界信息，当当前的字是结尾时 attention 权重最大的 token 为&amp;quot;SEP&amp;rdquo;，若当前字不是结尾时 attention 权重最大的为下一个字。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic2.zhimg.com/v2-47dbfcf64677c3dfd7152735e64a58e9_b.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;这种用于提取分词信息的 head 有很多，且不同的 head 有不同的分词粒度，如果将多个粒度的分词综合考虑(有一个 head 分词正确就行)，则直接用 attention-head 切词的准确率在 96%，这也是为什么词粒度 bert 和字粒度 bert 表现差不多的原因。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic2.zhimg.com/80/v2-bde0a5f3b6c50b5716e074306bca1cbd_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;猜测字粒度 bert 带词边界信息是通过 bert 的预训练任务 MLM 带来的，语言模型的训练使得 bert 对各个字之间的组合非常的敏感，从而能够区分词的边界信息。&lt;/p&gt;
&lt;h3 id=&#34;23-某些-head-负责编码输入的顺序&#34;&gt;&lt;strong&gt;2.3 某些 head 负责编码输入的顺序&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;我们知道 bert 的输入为 token_emb+pos_emb+seg_type_emb 这三个部分相加而成，而文本输入的顺序完全是用 pos_emb 来隐式的表达。bert 中某些 head 实际上负责提取输入中的位置信息。这种 attention-head 有明显的上下对齐的模式，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic1.zhimg.com/80/v2-11ce4ed825f4130f0d16f3e6562c8430_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;原输入: query=&amp;quot;京东小哥&amp;rdquo;, title=&amp;quot;京东小哥最近在干嘛&amp;rdquo;,bert 模型判定为 4 档&lt;/p&gt;
&lt;p&gt;将 title 顺序打乱: query=&amp;quot;京东小哥&amp;rdquo;, title=&amp;quot;近东嘛最都在干哥小京&amp;rdquo;,bert 模型判定为&lt;strong&gt;2 档&lt;/strong&gt; 将 title 顺序打乱: query=&amp;quot;京东小哥&amp;rdquo;, title=&amp;quot;近东嘛最都在干哥小京&amp;rdquo;,mask 掉 7 个怀疑用于提取语序的 head,bert 模型判定为&lt;strong&gt;3 档&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面的图分别对比了不做 mask，随机 mask 掉 7 个 head(重复 100 次取平均值)，mask 掉 7 个特定的 head(怀疑带有语序信息的 head) 从下面的图看到，mask 掉 7 个特定的 head 后整体分档提升为 3 档，而随机 mask 掉 7 个 head 结果仍然为 2 档，且档位概率分布和不 mask 的情况差别不大。&lt;/p&gt;
&lt;p&gt;这个 case 说明了我们 mask 掉的 7 个特定的 head 应该是负责提取输入的顺序信息，也就是语序信息。将这部分 head mask 掉后，bert 表现比较难察觉到 title 中的乱序，从而提升了分档。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic1.zhimg.com/80/v2-baf0efbdabfcf5459e942e5a5d609f8c_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;24-某些-head-负责-query-和-title-中相同部分的-term-匹配&#34;&gt;&lt;strong&gt;2.4 某些 head 负责 query 和 title 中相同部分的 term 匹配&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;query 和 title 中是否有相同的 term 是我们的分类任务中非常关键的特征，假如 query 中大部分 term 都能在 title 中找到，则 query 和 title 相关性一般比较高。如 query=&amp;quot;京东小哥&amp;quot;就能完全在 title=&amp;quot;京东小哥最近在干嘛&amp;quot;中找到，两者的文本相关性也很高。我们发现部分 attention-head 负责提取这种 term 匹配特征，这种 head 的 attention 权重分布一般如下图，可以看到上句和下句中相同 term 的权重很高(颜色越深表示权重越大)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic4.zhimg.com/80/v2-c2fa3ba68b6cc0c7ccdbfe1d4c182dbb_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中在第 2~第 4 层有 5 个 head 匹配的模式特别明显。我们发现虽然 bert 模型中 attention-head 很冗余，去掉一些 head 对模型不会有太大的影响，但是有少部分 head 对模型非常重要，下面展示这 5 个 head 对模型的影响，表格中的数值表示与 baseline 模型的 acc 相对提升值。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic1.zhimg.com/80/v2-e3302aae2032e8ff09b807f1f8e2a97c_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;利用测试数据作为标准，分别测试随机 mask 掉 5 个 head 和 mask 掉 5 个指定的 head(这些 head 在 attention 可视化上都有明显的 query-title 匹配的模式)。从结果可以看到去掉这些负责 query-title 匹配的 head 后模型表现剧烈下降，只去掉这 5 个 head 就能让模型表现下降 50%。甚至 mask 掉 0~5 层其他 head，只保留这 5 个 head 时模型仍维持 baseline 模型 82%的表现，说明了 query-title 的 term 匹配在我们的任务中是非常重要的。&lt;/p&gt;
&lt;p&gt;这也许是为什么双塔 bert 在我们的场景下表现会那么差的原因(Bert+LSTM 实验中两个模型结合最后的表现差于只使用 Bert, Bert 的输入为双塔输入)，因为 query 和 title 分别输入，使得这些 head 没有办法提取 term 的匹配特征(相当于 mask 掉了这些 head)，而这些匹配特征对于我们的分类任务是至关重要的&lt;/p&gt;
&lt;h3 id=&#34;241-finetune-对于负责-term-匹配-attention-head-的影响&#34;&gt;&lt;strong&gt;2.4.1 finetune 对于负责 term 匹配 attention-head 的影响&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在 query-title 分档任务中 query 和 title 中是否有相同的 term 是很重要的特征，那么在 finetune 过程中负责 query-title 中相同 term 匹配的 head 是否有比较明显的增强呢？&lt;/p&gt;
&lt;p&gt;下面以 case 为例说明： query=&amp;quot;我在伊朗长大&amp;rdquo; title=&amp;quot;假期电影《我在伊朗长大》&amp;rdquo;&lt;/p&gt;
&lt;p&gt;下图展示了 query-title 数据&lt;em&gt;&lt;strong&gt;finetune 前&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;某个&lt;/strong&gt;负责 term 匹配的 head 的 attention 分配图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic4.zhimg.com/80/v2-1fe9e219c26f2708b7f9e7cb1b251d2b_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;没有 finetune 前&lt;/strong&gt;，可以看到某些 head 也会对上下句中重复的 term 分配比较大的 attention 值，这个特质可能是来自预训练任务 NSP(上下句预测)。因为假如上句和下句有出现相同的 term，则它们是上下句的概率比较大，所以 bert 有一些 head 专门负责提取这种匹配的信息。&lt;/p&gt;
&lt;p&gt;除了上下句相同的 term 有比较大的注意力，每个 term 对自身也有比较大的注意力权重（体现在图中对角线上的值都比较大) 为了更直观的看&lt;strong&gt;训练前后&lt;/strong&gt;哪部分的 attention 值有比较大的改变，分别展示训练后 attention&lt;strong&gt;增强&lt;/strong&gt;(微调前-微调后&amp;gt;0)和训练后 attention&lt;strong&gt;减弱&lt;/strong&gt;(微调前-微调后&amp;lt;0)的 attention 分配图。可以观察到比较明显的几个点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;query 和 title 中 term 匹配的 attention 值变大了 从下图可以看到, query 和 title 中具有相同 term 时 attention 相比于训练前是有比较大的增强。说明在下游任务(query-title 分档)训练中增强了这个 head 的相同 term 匹配信息的抽取能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://pic4.zhimg.com/80/v2-edb5789f6481831d6f60495980be5d97_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;term 和自身的 attention 变小了 模型将重点放在找 query 和 title 中是否有相同的 term，弱化了 term 对自身的注意力权重&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://pic3.zhimg.com/80/v2-3bd82ee8721a541b2b992490bc0d8b86_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分隔符 sep 的 attention 值变小了。 有**&lt;a href=&#34;https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1906.04341.pdf&#34;&gt;论文&lt;/a&gt;**指出当某个 token 的 attention 指向 sep 时表示一种不分配的状态(即此时没有找到合适的 attention 分配方式)，在经过 finetune 后 term 指向 sep 的权重变小了，表示经过 query-title 数据训练后这个 head 的 attention 分配更加的明确了。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;242-是否有某个-head-特别能影响模型&#34;&gt;&lt;strong&gt;2.4.2 是否有某个 head 特别能影响模型&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;从上面的实验可以看到，bert 模型有比较多冗余的 head。去掉一部分这些 head 并不太影响模型，但是有少部分 head 特别能影响模型如上面提到的负责提取上下句中 term 匹配信息的 head，只去掉 5 个这种 head 就能让模型的表现下降 50%。那么是否有某个 head 特别能影响结果呢？&lt;/p&gt;
&lt;p&gt;下面实验每次只 mask 掉一个 head，看模型在测试数据中表现是否上升/下降。下图中将 bert 的 144 个 head 看作 12X12 的矩阵，矩阵内每个元素表示去掉这个 head 后模型在测试数据上的表现。其中 0 表示去掉后对模型的影响不太大。元素内的值表示相对于 baseline 的表现提升，如+1%表示相比 baseline 的 acc 提高了 1%。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic2.zhimg.com/80/v2-df23645337d194720fdc725f3ef16661_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看到对于 bert 的大部分 head，单独去掉这个 head 对模型并不会造成太大的影响，而有少部分 head 确实特别能影响模型，比如负责上下句(query-title)中相同 term 匹配的 head。即使去掉一个这种 head 也会使得模型的表现下降。同时注意到高层(第 10 层)有一个 head 去掉后模型表现变化也很大，实验发现这个 head 功能是负责抽取底层 head 输出的特征，也就是 3-4 层中 head 抽取到输入的 query-title 有哪些相同 term 特征后，这部分信息会传递到第 10 层进一步进行提取，最后影响分类。&lt;/p&gt;
&lt;h3 id=&#34;243-高层-head-是如何提取底层-head-特征-一个典型-case&#34;&gt;&lt;strong&gt;2.4.3 高层 head 是如何提取底层 head 特征-一个典型 case&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;上图中，在第 10 层有一个 head 去掉后特别能影响模型，观察其 attention 的分布，cls 的 attention 都集中在 query 和 title 中相同的 term 上，似乎是在对底层 term 匹配 head 抽取到的特征进一步的提取，将这种匹配特征保存到 cls 中(cls 最后一层会用于分类)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic3.zhimg.com/80/v2-eabcfa5e4f4cce8da54f5ac32a49ba9e_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;在没有做任何 head-mask 时, 可以看到 cls 的 attention 主要分配给和 query 和 title 中的共同 term &amp;ldquo;紫熨斗&amp;rdquo;，而 mask 掉 5 个 2~4 层的 head(具有 term 匹配功能)时, 第 10 层的 cls 注意力分配明显被改变，分散到更多的 term 中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pic2.zhimg.com/80/v2-f02a2af3967dda0e4770082473040881_1440w.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;这个 case 展示了高层 attention-head 是如何依赖底层的 head 的特征，进一步提取底层的特征并最后作为重要特征用于 query-title 分类。&lt;/p&gt;
&lt;h3 id=&#34;结语&#34;&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;本文主要探讨了在 query-title 分类场景下,bert 模型的可解释性。主要从 attention-head 角度入手，发现 attention 一方面非常的冗余，去掉一部分 head 其实不会对模型造成多大的影响。另外一方面有一些 head 却非常的能影响模型，即使去掉一个都能让模型表现变差不少。同时发现不同的 head 实际上有特定的功能，比如底层的 head 负责对输入进行特征提取，如分词、提取输入的语序关系、提取 query 和 title(也就是上下句)中相同的 term 信息等。这部分底层的 head 提取到的特征会通过残差连接送到高层的 head 中，高层 head 会对这部分特征信息进行进一步融合，最终作为分类特征输入到分类器中。&lt;/p&gt;
&lt;p&gt;本文重点讨论了哪些 head 是对模型有正面作用，也就是去掉这些 head 后模型表现变差了。但是如果知道了哪些 head 为什么对模型有负面作用，也就是为什么去掉某些 head 模型效果会更好，实际上对于我们有更多的指导作用。这部分信息能够帮助我们在模型加速，提升模型表现上少走弯路。&lt;/p&gt;
&lt;h3 id=&#34;参考文献&#34;&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;[1] Clark K, Khandelwal U, Levy O, et al. What Does BERT Look At? An Analysis of BERT&amp;rsquo;s Attention[J]. arXiv preprint arXiv:1906.04341, 2019.&lt;/p&gt;
&lt;p&gt;[2] Vig J. A multiscale visualization of attention in the transformer model[J]. arXiv preprint arXiv:1906.05714, 2019.&lt;/p&gt;
&lt;p&gt;作者：vincehou，腾讯 TEG 应用研究员&lt;/p&gt;
&lt;p&gt;更多干货尽在&lt;a href=&#34;https://www.zhihu.com/org/teng-xun-ji-zhu-gong-cheng&#34;&gt;腾讯技术&lt;/a&gt;，官方QQ交流群已建立，交流讨论可加：957411539。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Tensorflow</title>
      <link>http://csyezheng.github.io/post/deep-learning/tensorflow/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/deep-learning/tensorflow/</guid>
      
        <description>&lt;h1 id=&#34;tensorflow&#34;&gt;TensorFlow&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;http://ww1.sinaimg.cn/large/0083FLjsgy1gg7bk10ef7j30qo0f03zd.jpg&#34; alt=&#34;https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;install-tensorflow-2&#34;&gt;Install TensorFlow 2&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Version&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Python version&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Compiler&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Build tools&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;tensorflow-2.2.0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3.5-3.8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GCC 7.3.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Bazel 2.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;tensorflow-2.1.0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2.7, 3.5-3.7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GCC 7.3.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Bazel 0.27.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;tensorflow-2.0.0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2.7, 3.3-3.7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;GCC 7.3.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Bazel 0.26.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -U cuda-10.1.243-2-x86_64.pkg.tar.xz
sudo pacman -U cudnn-7.6.5.32-2-x86_64.pkg.tar.xz
pip install tensorflow-gpu
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;data-input-pipelines&#34;&gt;Data input pipelines&lt;/h2&gt;
&lt;h2 id=&#34;keras&#34;&gt;Keras&lt;/h2&gt;
&lt;h3 id=&#34;sequential-api&#34;&gt;Sequential API&lt;/h3&gt;
&lt;h4 id=&#34;when-to-use-a-sequential-model&#34;&gt;When to use a Sequential model&lt;/h4&gt;
&lt;p&gt;A Sequential model is appropriate for &lt;strong&gt;a plain stack of layers&lt;/strong&gt; where each layer has &lt;strong&gt;exactly one input tensor and one output tensor&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A Sequential model is &lt;strong&gt;not appropriate&lt;/strong&gt; when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your model has multiple inputs or multiple outputs&lt;/li&gt;
&lt;li&gt;Any of your layers has multiple inputs or multiple outputs&lt;/li&gt;
&lt;li&gt;You need to do layer sharing&lt;/li&gt;
&lt;li&gt;You want non-linear topology (e.g. a residual connection, a multi-branch model)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Sequential constructor accepts a &lt;code&gt;name&lt;/code&gt; argument, just like any layer or model in Keras. This is useful to annotate TensorBoard graphs with semantically meaningful names.&lt;/p&gt;
&lt;h4 id=&#34;specifying-the-input-shape-in-advance&#34;&gt;Specifying the input shape in advance&lt;/h4&gt;
&lt;p&gt;it can be very useful when building a Sequential model incrementally to be able to display the summary of the model so far, including the current output shape. In this case, you should start your model by passing an &lt;code&gt;Input&lt;/code&gt; object to your model, so that it knows its input shape from the start.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model = keras.Sequential()
model.add(keras.Input(shape=(4,)))
model.add(layers.Dense(2, activation=&amp;quot;relu&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A simple alternative is to just pass an &lt;code&gt;input_shape&lt;/code&gt; argument to your first layer.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model = keras.Sequential()
model.add(layers.Dense(2, activation=&amp;quot;relu&amp;quot;, input_shape=(4,)))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In general, it&amp;rsquo;s a recommended &lt;strong&gt;best practice&lt;/strong&gt; to always specify the input shape of a Sequential model in advance if you know what it is.&lt;/p&gt;
&lt;h4 id=&#34;a-common-debugging-workflow-add--summary&#34;&gt;A common debugging workflow: &lt;code&gt;add()&lt;/code&gt; + &lt;code&gt;summary()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;When building a new Sequential architecture, it&amp;rsquo;s useful to incrementally stack layers with &lt;code&gt;add()&lt;/code&gt; and frequently print model summaries.&lt;/p&gt;
&lt;h4 id=&#34;feature-extraction-with-a-sequential-model&#34;&gt;Feature extraction with a Sequential model&lt;/h4&gt;
&lt;p&gt;quickly creating a model that extracts the outputs of all intermediate layers in a Sequential model:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;initial_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential(
    [
        keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)),
        layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;),
        layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;),
        &lt;span style=&#34;color:#75715e&#34;&gt;# layers.Conv2D(32, 3, activation=&amp;#34;relu&amp;#34;, name=&amp;#34;my_intermediate_layer&amp;#34;),&lt;/span&gt;
        layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;),
    ]
)
feature_extractor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(
    inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;initial_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inputs,
    outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; initial_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers],
    &lt;span style=&#34;color:#75715e&#34;&gt;# only extract features from one layer:&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# outputs=initial_model.get_layer(name=&amp;#34;my_intermediate_layer&amp;#34;).output,&lt;/span&gt;
)

&lt;span style=&#34;color:#75715e&#34;&gt;# Call feature extractor on test input.&lt;/span&gt;
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))
features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_extractor(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;transfer-learning-with-a-sequential-model&#34;&gt;Transfer learning with a Sequential model&lt;/h4&gt;
&lt;h3 id=&#34;keras-functional-api&#34;&gt;Keras functional API&lt;/h3&gt;
&lt;h3 id=&#34;train_and_evaluate&#34;&gt;train_and_evaluate&lt;/h3&gt;
&lt;h3 id=&#34;write-custom-layers-and-models&#34;&gt;Write custom layers and models&lt;/h3&gt;
&lt;h3 id=&#34;save-and-serialize-models&#34;&gt;Save and serialize models&lt;/h3&gt;
&lt;h3 id=&#34;customizing-what-happens-in-fit&#34;&gt;Customizing what happens in fit&lt;/h3&gt;
&lt;h3 id=&#34;writing-a-training-loop-from-scratch&#34;&gt;Writing a training loop from scratch&lt;/h3&gt;
&lt;h3 id=&#34;keras-recurrent-neural-networks&#34;&gt;Keras Recurrent Neural Networks&lt;/h3&gt;
&lt;h3 id=&#34;masking-and-padding&#34;&gt;Masking and padding&lt;/h3&gt;
&lt;h3 id=&#34;write-custom-callbacks&#34;&gt;Write custom callbacks&lt;/h3&gt;
&lt;h3 id=&#34;transfer-learning&#34;&gt;Transfer learning&lt;/h3&gt;
&lt;h2 id=&#34;estimators&#34;&gt;Estimators&lt;/h2&gt;
&lt;h2 id=&#34;save-a-model&#34;&gt;Save a model&lt;/h2&gt;
&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;[&lt;strong&gt;TensorFlow 2.0 is now available!&lt;/strong&gt;]([https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html#:~:text=Today%2C%20we&amp;rsquo;re%20delighted%20to,TensorFlow%202.0%20is%20now%20available!&amp;amp;text=TensorFlow%202.0%20provides%20a%20comprehensive,build%20scalable%20ML%2Dpowered%20applications.](&lt;a href=&#34;https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html#:~:text=Today%2C&#34;&gt;https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html#:~:text=Today%2C&lt;/a&gt; we&amp;rsquo;re delighted to,TensorFlow 2.0 is now available!&amp;amp;text=TensorFlow 2.0 provides a comprehensive,build scalable ML-powered applications.))&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://afteracademy.com/blog/getting-started-with-tensorflow-2-tutorial-step-by-step-guide&#34;&gt;&lt;strong&gt;Getting started with Tensorflow 2.0 Tutorial&lt;/strong&gt; &lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Multi-label classification</title>
      <link>http://csyezheng.github.io/post/machine-learning/multi-label-classification/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/machine-learning/multi-label-classification/</guid>
      
        <description>&lt;p&gt;In the multi-label problem there is no constraint on how many of the classes the instance can be assigned to. Formally, multi-label classification is the problem of finding a model that maps inputs &lt;strong&gt;x&lt;/strong&gt; to binary vectors &lt;strong&gt;y&lt;/strong&gt; (assigning a value of 0 or 1 for each element (label) in &lt;strong&gt;y&lt;/strong&gt;).&lt;/p&gt;
&lt;h2 id=&#34;problem-transformation-methods&#34;&gt;Problem transformation methods&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transformation into binary classification problems&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;binary relevance&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;amounts to independently training one binary classifier for each label.&lt;/p&gt;
&lt;p&gt;Although this method of dividing the task into multiple binary tasks may resemble superficially the one-vs.-all (OvA) and one-vs.-rest (OvR) methods for multiclass classification, it is essentially different from both, because a single classifier under binary relevance deals with a single label, without any regard to other labels whatsoever.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;classifier chain&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It differs from binary relevance in that labels are predicted sequentially, and the output of all previous classifiers (i.e. positive or negative for a particular label) are input as features to subsequent classifiers.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transformation into multi-class classification problem&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;label powerset&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ensemble methods&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A set of multi-class classifiers can be used to create a multi-label ensemble classifier. For a given example, each classifier outputs a single class (corresponding to a single label in the multi-label problem). These predictions are then combined by an ensemble method, usually a voting scheme where every class that receives a requisite percentage of votes from individual classifiers (often referred to as the discrimination threshold[8]) is predicted as a present label in the multi-label output.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;adapted-algorithms&#34;&gt;Adapted algorithms&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ML-kNN&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clare&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kernel methods for vector output&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BP-MLL&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;statistics-and-evaluation-metrics&#34;&gt;Statistics and evaluation metrics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hamming loss&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;the fraction of the wrong labels to the total number of labels&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;**Precision, recall and $F_{1}$ score**&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;implementations-and-datasets&#34;&gt;Implementations and datasets&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://scikit-learn.org/stable/modules/multiclass.html&#34;&gt;multi-labels algorithms and metrics&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A list of commonly used multi-label data-sets is available at the &lt;a href=&#34;http://mulan.sourceforge.net/datasets.html&#34;&gt;Mulan website&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;competition&#34;&gt;Competition&lt;/h2&gt;
&lt;h3 id=&#34;toxic-comment-classification-challengehttpswwwkagglecomcjigsaw-toxic-comment-classification-challenge&#34;&gt;&lt;a href=&#34;https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge&#34;&gt;Toxic Comment Classification Challenge&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://stackabuse.com/python-for-nlp-multi-label-text-classification-with-keras/&#34;&gt;https://stackabuse.com/python-for-nlp-multi-label-text-classification-with-keras/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5&#34;&gt;https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;questions-from-cross-validated-stack-exchangehttpswwwkagglecomstackoverflowstatsquestions&#34;&gt;&lt;a href=&#34;https://www.kaggle.com/stackoverflow/statsquestions&#34;&gt;Questions from Cross Validated Stack Exchange&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.mimacom.com/text-classification/&#34;&gt;https://blog.mimacom.com/text-classification/&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Python and Java Service</title>
      <link>http://csyezheng.github.io/post/back-end/python-and-java-service/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/back-end/python-and-java-service/</guid>
      
        <description>&lt;h1 id=&#34;python和java服务器通信实现的理解和比较&#34;&gt;Python和Java服务器通信实现的理解和比较&lt;/h1&gt;
&lt;h3 id=&#34;python的wsgi和java的servlet-api&#34;&gt;Python的WSGI和Java的Servlet API&lt;/h3&gt;
&lt;h4 id=&#34;python的wsgi&#34;&gt;Python的WSGI&lt;/h4&gt;
&lt;p&gt;最近在学习使用Python进行WebServer的编程，发现WSGI（Web Server Gateway Interface）的概念。PythonWeb服务器网关接口（Python Web Server Gateway Interface，缩写为WSGI）是Python应用程序或框架和Web服务器之间的一种接口，已经被广泛接受，它已基本达成它的可移植性方面的目标。WSGI 没有官方的实现，因为WSGI更像一个协议。只要遵照这些协议，WSGI应用(Application)都可以在任何服务器(Server)上运行，反之亦然。&lt;/p&gt;
&lt;p&gt;如果没有WSGI，你选择的Python网络框架将会限制所能够使用的 Web 服务器。&lt;/p&gt;
&lt;p&gt;这就意味着，你基本上只能使用能够正常运行的服务器与框架组合，而不能选择你希望使用的服务器或框架。&lt;/p&gt;
&lt;p&gt;那么，你怎样确保可以在不修改 Web 服务器代码或网络框架代码的前提下，使用自己选择的服务器，并且匹配多个不同的网络框架呢？为了解决这个问题，就出现了PythonWeb 服务器网关接口（Web Server Gateway Interface，WSGI）。&lt;/p&gt;
&lt;p&gt;WSGI的出现，让开发者可以将网络框架与 Web 服务器的选择分隔开来，不再相互限制。现在，你可以真正地将不同的 Web 服务器与网络开发框架进行混合搭配，选择满足自己需求的组合。例如，你可以使用Gunicorn或Nginx/uWSGI或Waitress服务器来运行Django、Flask或Pyramid应用。正是由于服务器和框架均支持WSGI，才真正得以实现二者之间的自由混合搭配。&lt;/p&gt;
&lt;h4 id=&#34;java的servlet-api&#34;&gt;Java的Servlet API&lt;/h4&gt;
&lt;p&gt;下面将类比Java来说明一下：&lt;/p&gt;
&lt;p&gt;如果没有Java Servlet API，你选择的Java Web容器（Java Socket编程框架实现）将会限制所能够使用的Java Web框架（因为没有Java Servlet API，那么SpringMVC可能会实现一套SpringMVCHttpRequest和SpringMVCHttpResponse标准，Struts2可能会实现一套Struts2HttpRequest和Struts2HttpResponse标准，如果Tomcat只支持SpringMVC的API，那么选择Tomcat服务器就只能使用SpringMVC的Web框架来写服务端代码）。&lt;/p&gt;
&lt;p&gt;这就意味着，你基本上只能使用能够正常运行的服务器（Tomcat）与框架（SpringMVC）组合，而不能选择你希望使用的服务器或框架（比如：我要换成Tomcat + Struts2的组合）。&lt;/p&gt;
&lt;p&gt;注意：这里假设没有Java Servlet API，这样就相当于SpringMVC和Struts2可能都要自己实现一套Servlet封装HttpRequest和HttpResponse，这样从SpringMVC更换成Struts2就几乎需要重写服务器端的代码。为了解决这个问题，Java提出了Java Servlet API协议，让所有的Web服务框架都实现此Java Servlet API协议来和Java Web服务器（例如：Tomcat）交互，而复杂的网络连接控制等等都交由Java Web服务器来控制，Java Web服务器用Java Socket编程实现了复杂的网络连接管理。&lt;/p&gt;
&lt;h4 id=&#34;详细说说python的wsgi&#34;&gt;详细说说Python的WSGI&lt;/h4&gt;
&lt;p&gt;Python Web 开发中，服务端程序可以分为两个部分，一是服务器程序，二是应用程序。前者负责把客户端请求接收，整理，后者负责具体的逻辑处理。为了方便应用程序的开发，我们把常用的功能封装起来，成为各种Web开发框架，例如 Django, Flask, Tornado。不同的框架有不同的开发方式，但是无论如何，开发出的应用程序都要和服务器程序配合，才能为用户提供服务。这样，服务器程序就需要为不同的框架提供不同的支持。这样混乱的局面无论对于服务器还是框架，都是不好的。对服务器来说，需要支持各种不同框架，对框架来说，只有支持它的服务器才能被开发出的应用使用。&lt;/p&gt;
&lt;p&gt;这时候，标准化就变得尤为重要。我们可以设立一个标准，只要服务器程序支持这个标准，框架也支持这个标准，那么他们就可以配合使用。一旦标准确定，双方各自实现。这样，服务器可以支持更多支持标准的框架，框架也可以使用更多支持标准的服务器。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务器端：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;服务器必须将可迭代对象的内容传递给客户端，可迭代对象会产生bytestrings，必须完全完成每个bytestring后才能请求下一个。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;服务器程序会在每次客户端的请求传来时，调用我们写好的应用程序，并将处理好的结果返回给客户端。&lt;/p&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Web Server Gateway Interface是Python编写Web业务统一接口。&lt;/li&gt;
&lt;li&gt;无论多么复杂的Web应用程序，入口都是一个WSGI处理函数。&lt;/li&gt;
&lt;li&gt;Web应用程序就是写一个WSGI的处理函数，主要功能在于交互式地浏览和修改数据，生成动态Web内容，针对每个HTTP请求进行响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;实现python的web应用程序能被访问的方式&#34;&gt;实现Python的Web应用程序能被访问的方式&lt;/h4&gt;
&lt;p&gt;要使 Python 写的程序能在 Web 上被访问，还需要搭建一个支持 Python 的 HTTP 服务器（也就是实现了WSGI server（WSGI协议）的Http服务器）。有如下几种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以自己使用Python Socket编程实现一个Http服务器&lt;/li&gt;
&lt;li&gt;使用支持Python的开源的Http服务器（如：uWSGI，wsgiref，Mod_WSGI等等）。如果是使用Nginx，Apache，Lighttpd等Http服务器需要单独安装支持WSGI server的模块插件。&lt;/li&gt;
&lt;li&gt;使用Python开源Web框架（如：Flask，Django等等）内置的Http服务器（Django自带的WSGI Server，一般测试使用）&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;python标准库对wsgi的实现&#34;&gt;Python标准库对WSGI的实现&lt;/h5&gt;
&lt;p&gt;wsgiref 是Python标准库给出的 WSGI 的参考实现。simple_server 这一模块实现了一个简单的 HTTP 服务器。&lt;/p&gt;
&lt;p&gt;Python源码中的wsgiref的simple_server.py正好说明上面的分工情况，server的主要作用是接受client的请求，並把的收到的请求交給RequestHandlerClass处理，RequestHandlerClass处理完成后回传结果给client&lt;/p&gt;
&lt;h5 id=&#34;uwsgi服务器&#34;&gt;uWSGI服务器&lt;/h5&gt;
&lt;p&gt;uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。注意uwsgi是一种通信协议，而uWSGI是实现uwsgi协议和WSGI协议的Web服务器。&lt;/p&gt;
&lt;h5 id=&#34;django框架内置的wsgi-server服务器&#34;&gt;Django框架内置的WSGI Server服务器&lt;/h5&gt;
&lt;p&gt;Django的WSGIServer继承自wsgiref.simple_server.WSGIServer，而WSGIRequestHandler继承自wsgiref.simple_server.WSGIRequestHandler&lt;/p&gt;
&lt;p&gt;之前说到的application，在Django中一般是django.core.handlers.wsgi.WSGIHandler对象，WSGIHandler继承自django.core.handlers.base.BaseHandler，这个是Django处理request的核心逻辑，它会创建一个WSGIRequest实例，而WSGIRequest是从http.HttpRequest继承而来&lt;/p&gt;
&lt;h4 id=&#34;python和java的类比&#34;&gt;Python和Java的类比&lt;/h4&gt;
&lt;h5 id=&#34;python和java的服务器结构&#34;&gt;Python和Java的服务器结构&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;独立WSGI server（实现了Http服务器功能） + Python Web应用程序
&lt;ul&gt;
&lt;li&gt;例如：Gunicorn，uWSGI + Django，Flask&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;独立Servlet引擎（Java应用服务器）（实现了Http服务器功能） + Java Web应用程序
&lt;ul&gt;
&lt;li&gt;例如：Jetty，Tomcat + SpringMVC，Struts2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;python和java服务器共同点&#34;&gt;Python和Java服务器共同点&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;WSGI server（例如Gunicorn和uWSGI）
&lt;ul&gt;
&lt;li&gt;WSGI server服务器内部都有组建来实现Socket连接的创建和管理。&lt;/li&gt;
&lt;li&gt;WSGI server服务器都实现了Http服务器功能，能接受Http请求，并且通过Python Web应用程序处理之后返回动态Web内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Java应用服务器（Jetty和Tomcat）
&lt;ul&gt;
&lt;li&gt;Java应用服务器内部都有Connector组件来实现Socket连接的创建和管理。&lt;/li&gt;
&lt;li&gt;Java应用服务器都实现了Http服务器功能，能接受Http请求，并且通过Java Web应用程序处理之后返回动态Web内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考文章：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;%5Bhttps://birdben.github.io/2017/03/05/Java/Python%E5%92%8CJava%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%9A%E4%BF%A1%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%90%86%E8%A7%A3%E5%92%8C%E6%AF%94%E8%BE%83/%5D(https://birdben.github.io/2017/03/05/Java/Python%E5%92%8CJava%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%9A%E4%BF%A1%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%90%86%E8%A7%A3%E5%92%8C%E6%AF%94%E8%BE%83/)&#34;&gt;Python和Java服务器通信实现的理解和比较&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Machine Learning Crash Course Courses</title>
      <link>http://csyezheng.github.io/post/machine-learning/crash-course/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/machine-learning/crash-course/</guid>
      
        <description>&lt;h1 id=&#34;machine-learning-crash-course-courses&#34;&gt;Machine Learning Crash Course Courses&lt;/h1&gt;
&lt;h2 id=&#34;ml-concepts&#34;&gt;ML Concepts&lt;/h2&gt;
&lt;h4 id=&#34;introduction-to-ml&#34;&gt;Introduction to ML&lt;/h4&gt;
&lt;p&gt;First, it gives you a tool to reduce the time you spend programming.&lt;/p&gt;
&lt;p&gt;Second, it will allow you to customize your products, making them better for specific groups of people.&lt;/p&gt;
&lt;p&gt;Third, machine learning lets you solve problems that you, as a programmer, have no idea how to do by hand.&lt;/p&gt;
&lt;p&gt;machine learning &lt;strong&gt;changes the way you think about a problem&lt;/strong&gt;. Software engineers are trained to think logically and mathematically; we use assertions to prove properties of our program are correct.  With machine learning, the focus shifts from a mathematical science to a natural science: we&amp;rsquo;re making observations about an uncertain world, running experiments, and using statistics, not logic, to analyze the results of the experiment. The ability to think like a scientist  will expand your horizons and open up new areas that you couldn&amp;rsquo;t explore without it.&lt;/p&gt;
&lt;h4 id=&#34;framing-框架处理&#34;&gt;Framing (框架处理)&lt;/h4&gt;
&lt;p&gt;What is (supervised) machine learning? Concisely put, it is the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML systems learn how to combine input to produce useful predictions on never-before-seen data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;labels-标签&#34;&gt;Labels (标签)&lt;/h6&gt;
&lt;p&gt;A &lt;strong&gt;label&lt;/strong&gt; is the thing we&amp;rsquo;re predicting—the &lt;code&gt;y&lt;/code&gt; variable in simple linear regression.&lt;/p&gt;
&lt;h6 id=&#34;features-特征&#34;&gt;Features (特征)&lt;/h6&gt;
&lt;p&gt;A &lt;strong&gt;feature&lt;/strong&gt; is an input variable—the &lt;code&gt;x&lt;/code&gt; variable in simple linear regression. A simple machine learning project might use a single feature, while a more sophisticated machine learning project could use millions of features.&lt;/p&gt;
&lt;h6 id=&#34;examples-样本&#34;&gt;Examples (样本)&lt;/h6&gt;
&lt;p&gt;An &lt;strong&gt;example&lt;/strong&gt; is a particular instance of data, &lt;strong&gt;x&lt;/strong&gt;. (We put &lt;strong&gt;x&lt;/strong&gt; in boldface to indicate that it is a vector.) We break examples into two categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;labeled examples&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;labeled example&lt;/strong&gt; includes both feature(s) and the label.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;unlabeled examples&lt;/p&gt;
&lt;p&gt;An &lt;strong&gt;unlabeled example&lt;/strong&gt; contains features but not the label.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;models-模型&#34;&gt;Models (模型)&lt;/h6&gt;
&lt;p&gt;A model defines the relationship between features and label.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Training&lt;/strong&gt; means creating or &lt;strong&gt;learning&lt;/strong&gt; the model. That is, you show the model labeled examples and enable the model to gradually learn the relationships between features and label.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inference&lt;/strong&gt; means applying the trained model to unlabeled examples. That is, you use the trained model to make useful predictions (&lt;code&gt;y&#39;&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;regression-vs-classification-回归与分类&#34;&gt;Regression vs. classification (回归与分类)&lt;/h6&gt;
&lt;p&gt;A &lt;strong&gt;regression&lt;/strong&gt; model predicts continuous values.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;classification&lt;/strong&gt; model predicts discrete values (离散值).&lt;/p&gt;
&lt;h4 id=&#34;descending-into-ml&#34;&gt;Descending into ML&lt;/h4&gt;
&lt;h6 id=&#34;linear-regression&#34;&gt;Linear Regression&lt;/h6&gt;
&lt;p&gt;$$
y&amp;rsquo; = b + w_1x_1 + w_2x_2 + w_3x_3
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$y′$ is the predicted &lt;strong&gt;label&lt;/strong&gt; (a desired output).&lt;/li&gt;
&lt;li&gt;$b$ is the &lt;strong&gt;bias&lt;/strong&gt; (the y-intercept), sometimes referred to as $w_0$.&lt;/li&gt;
&lt;li&gt;$w1$ is the &lt;strong&gt;weight&lt;/strong&gt; of &lt;strong&gt;feature&lt;/strong&gt; 1. Weight is the same concept as the &amp;ldquo;slope&amp;rdquo; m in the traditional equation of a line.&lt;/li&gt;
&lt;li&gt;$x_1$ is a &lt;strong&gt;feature&lt;/strong&gt; (a known input).&lt;/li&gt;
&lt;li&gt;a more sophisticated model might rely on multiple features, each having a separate weight ($w_1$, $w_2$, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;training-and-loss&#34;&gt;Training and Loss&lt;/h6&gt;
&lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt; a model simply means learning (determining) good values for all the weights and the bias from labeled examples. In supervised learning, a machine learning algorithm builds a model by examining many examples and attempting to find a model that &lt;strong&gt;minimizes loss&lt;/strong&gt;; this process is called &lt;strong&gt;empirical risk minimization&lt;/strong&gt; (&lt;strong&gt;经验风险最小化&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loss is the penalty for a bad prediction&lt;/strong&gt;. That is, &lt;strong&gt;loss&lt;/strong&gt; is a number &lt;strong&gt;indicating how bad the model&amp;rsquo;s prediction was on a single example&lt;/strong&gt;. If the model&amp;rsquo;s prediction is perfect, the loss is zero; otherwise, the loss is greater. The goal of training a model is to find a set of weights and biases that have &lt;em&gt;low&lt;/em&gt; loss, on average, across all examples.&lt;/p&gt;
&lt;p&gt;You might be wondering whether you could &lt;strong&gt;create a mathematical function—a loss function—that would aggregate the individual losses in a meaningful fashion.&lt;/strong&gt;&lt;/p&gt;
&lt;h6 id=&#34;squared-loss-a-popular-loss-function&#34;&gt;Squared loss: a popular loss function&lt;/h6&gt;
&lt;p&gt;The linear regression models we&amp;rsquo;ll examine here use a loss function called &lt;strong&gt;squared loss&lt;/strong&gt; (also known as &lt;strong&gt;L2 loss&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mean square error&lt;/strong&gt; (&lt;strong&gt;MSE&lt;/strong&gt;) is the average squared loss per example over the whole dataset. To calculate MSE, sum up all the squared losses for individual examples and then divide by the number of examples:
$$
MSE = \frac{1}{N}\sum_{(x,y)\in{D}} (y - prediction(x))^2
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$(x,y)$ is an example in which&lt;/li&gt;
&lt;li&gt;$x$ is the set of features (for example, chirps/minute, age, gender) that the model uses to make predictions.&lt;/li&gt;
&lt;li&gt;$y$ is the example&amp;rsquo;s label (for example, temperature).&lt;/li&gt;
&lt;li&gt;$prediction(x)$ is a function of the &lt;strong&gt;weights&lt;/strong&gt; and &lt;strong&gt;bias&lt;/strong&gt; in combination with the set of &lt;strong&gt;features&lt;/strong&gt; x.&lt;/li&gt;
&lt;li&gt;$D$ is a data set containing many labeled examples, which are $(x,y)$ pairs.&lt;/li&gt;
&lt;li&gt;$N$ is the number of examples in $D$.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reducing-loss-降低损失&#34;&gt;Reducing Loss (降低损失)&lt;/h4&gt;
&lt;h6 id=&#34;an-iterative-approach-迭代方法&#34;&gt;An Iterative Approach (迭代方法)&lt;/h6&gt;
&lt;p&gt;&lt;img src=&#34;https://developers.google.cn/machine-learning/crash-course/images/GradientDescentDiagram.svg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;A Machine Learning model is trained by starting with an initial guess for the weights and bias and iteratively adjusting those guesses until learning the weights and bias with the lowest possible loss.&lt;/p&gt;
&lt;p&gt;Usually, you iterate until overall loss stops changing or at least changes extremely slowly. When that happens, we say that the model has &lt;strong&gt;converged&lt;/strong&gt; (&lt;strong&gt;收敛&lt;/strong&gt;).&lt;/p&gt;
&lt;h6 id=&#34;gradient-descent-梯度下降法&#34;&gt;Gradient Descent (梯度下降法)&lt;/h6&gt;
&lt;p&gt;For the kind of regression problems we&amp;rsquo;ve been examining, the resulting plot of loss vs. $w_1$ will always be &lt;strong&gt;convex&lt;/strong&gt; (凸形). In other words, the plot will always be bowl-shaped, &lt;strong&gt;Convex problems have only one minimum&lt;/strong&gt;; that is, only one place where the slope is exactly 0. That minimum is where the loss function converges.&lt;/p&gt;
&lt;p&gt;Calculating the loss function for every conceivable value of $w_{1}$ **over the entire data set would be an inefficient way** of finding the convergence point. Let&amp;rsquo;s examine a better mechanism—very popular in machine learning—called **gradient descent**.&lt;/p&gt;
&lt;p&gt;The first stage in gradient descent is to pick a starting value (a starting point) for $w_{1}$. **The starting point doesn&amp;rsquo;t matter much**; therefore, many algorithms simply set $w_{1}$ to 0 or pick a random value.&lt;/p&gt;
&lt;p&gt;The gradient descent algorithm then calculates the gradient of the loss curve at the starting point. the gradient of the loss is equal to the &lt;strong&gt;derivative&lt;/strong&gt; (&lt;strong&gt;slope&lt;/strong&gt;) of the curve, and tells you which way is &amp;ldquo;warmer&amp;rdquo; or &amp;ldquo;colder.&amp;rdquo; When there are multiple weights, the &lt;strong&gt;gradient&lt;/strong&gt; is a &lt;strong&gt;vector&lt;/strong&gt; of &lt;strong&gt;partial derivatives&lt;/strong&gt; with respect to the weights.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note that a gradient is a vector&lt;/strong&gt;, so it has both of the following characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a direction&lt;/li&gt;
&lt;li&gt;a magnitude (大小)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://developers.google.cn/machine-learning/crash-course/images/GradientDescentGradientStep.svg?dcb_=0.336975579495699&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h6 id=&#34;learning-rate-学习速率&#34;&gt;Learning Rate (学习速率)&lt;/h6&gt;
&lt;p&gt;As noted, the gradient vector has both a direction and a magnitude. Gradient descent algorithms multiply the gradient by a scalar known as the &lt;strong&gt;learning rate&lt;/strong&gt; (also sometimes called &lt;strong&gt;step size&lt;/strong&gt;) to determine the next point. For example, if the gradient magnitude is 2.5 and the learning rate is 0.01, then the gradient descent algorithm will pick the next point 0.025 away from the previous point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hyperparameters&lt;/strong&gt; are the knobs that programmers tweak in machine learning algorithms. Most machine learning programmers spend a fair amount of time tuning the learning rate.&lt;/p&gt;
&lt;p&gt;If you pick a learning rate that is &lt;strong&gt;too small&lt;/strong&gt;, learning will take too long, Conversely, if you specify a learning rate that is &lt;strong&gt;too large&lt;/strong&gt;, the next point will perpetually bounce haphazardly across the bottom of the well like a quantum mechanics experiment gone horribly wrong.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The ideal learning rate:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The ideal learning rate in one-dimension is 1f(x)″ (the inverse of the second derivative of f(x) at x).&lt;/li&gt;
&lt;li&gt;The ideal learning rate for 2 or more dimensions is the inverse of the &lt;a href=&#34;https://wikipedia.org/wiki/Hessian_matrix&#34;&gt;Hessian&lt;/a&gt; (matrix of second partial derivatives).&lt;/li&gt;
&lt;li&gt;The story for general convex functions is more complex.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;stochastic-gradient-descent-随机梯度下降法&#34;&gt;Stochastic Gradient Descent (随机梯度下降法)&lt;/h6&gt;
&lt;p&gt;&lt;strong&gt;batch&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In gradient descent, a &lt;strong&gt;batch&lt;/strong&gt; is the total number of examples you use to calculate the gradient in a single iteration.&lt;/p&gt;
&lt;p&gt;A large data set with randomly sampled examples probably contains &lt;strong&gt;redundant&lt;/strong&gt; data. In fact, redundancy becomes more likely as the batch size grows. Some redundancy can be useful to &lt;strong&gt;smooth&lt;/strong&gt; out noisy gradients, but enormous batches tend not to carry much more predictive value than large batches.&lt;/p&gt;
&lt;p&gt;By choosing examples at random from our data set, we could estimate (albeit, noisily) a big average from a much smaller one. &lt;strong&gt;Stochastic gradient descent&lt;/strong&gt; (&lt;strong&gt;SGD&lt;/strong&gt;) takes this idea to the extreme&amp;ndash;it uses &lt;strong&gt;only a single example (a batch size of 1) per iteration&lt;/strong&gt;. Given enough iterations, SGD works but is very noisy. The term &amp;ldquo;stochastic&amp;rdquo; indicates that the one example comprising each batch is chosen at random.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mini-batch stochastic gradient descent&lt;/strong&gt; (&lt;strong&gt;mini-batch SGD&lt;/strong&gt;) is a compromise between full-batch iteration and SGD. A mini-batch is typically between 10 and 1,000 examples, chosen at random. Mini-batch SGD reduces the amount of noise in SGD but is still more efficient than full-batch.&lt;/p&gt;
&lt;h4 id=&#34;first-steps-with-tf&#34;&gt;First Steps with TF&lt;/h4&gt;
&lt;p&gt;Programming Exercises&lt;/p&gt;
&lt;p&gt;If you are unfamiliar with NumPy or pandas, please begin by doing the following two Colab exercises:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/numpy_ultraquick_tutorial.ipynb?utm_source=mlcc&amp;amp;utm_campaign=colab-external&amp;amp;utm_medium=referral&amp;amp;utm_content=numpy_tf2-colab&amp;amp;hl=en&#34;&gt;NumPy Ultraquick Tutorial&lt;/a&gt; Colab exercise, which provides all the NumPy information you need for this course.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=mlcc&amp;amp;utm_campaign=colab-external&amp;amp;utm_medium=referral&amp;amp;utm_content=pandas_tf2-colab&amp;amp;hl=en&#34;&gt;pandas UltraQuick Tutorial&lt;/a&gt; Colab exercise, which provides all the pandas information you need for this course.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After gaining competency in NumPy and pandas, do the following two Colab exercises to explore linear regression and hyperparameter tuning in tf.keras:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb?utm_source=mlcc&amp;amp;utm_campaign=colab-external&amp;amp;utm_medium=referral&amp;amp;utm_content=linear_regression_synthetic_tf2-colab&amp;amp;hl=en&#34;&gt;Linear Regression with Synthetic Data&lt;/a&gt; Colab exercise, which explores linear regression with a toy dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/linear_regression_with_a_real_dataset.ipynb?utm_source=mlcc&amp;amp;utm_campaign=colab-external&amp;amp;utm_medium=referral&amp;amp;utm_content=linear_regression_real_tf2-colab&amp;amp;hl=en&#34;&gt;Linear Regression with a Real Dataset&lt;/a&gt; Colab exercise, which guides you through the kinds of analysis you should do on a real dataset.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;generalization-泛化&#34;&gt;Generalization (泛化)&lt;/h4&gt;
&lt;p&gt;Video Lecture
Peril of Overfitting&lt;/p&gt;
&lt;h4 id=&#34;training-and-test-sets&#34;&gt;Training and Test Sets&lt;/h4&gt;
&lt;p&gt;Video Lecture
Splitting Data
Playground Exercise&lt;/p&gt;
&lt;h4 id=&#34;validation-set&#34;&gt;Validation Set&lt;/h4&gt;
&lt;p&gt;Check Your Intuition
Video Lecture
Another Partition
Programming Exercise&lt;/p&gt;
&lt;h4 id=&#34;representation-表示法&#34;&gt;Representation (表示法)&lt;/h4&gt;
&lt;p&gt;Video Lecture
Feature Engineering
Qualities of Good Features
Cleaning Data&lt;/p&gt;
&lt;h4 id=&#34;feature-crosses-特征组合&#34;&gt;Feature Crosses (特征组合)&lt;/h4&gt;
&lt;p&gt;Video Lecture
Encoding Nonlinearity
Crossing One-Hot Vectors
Playground Exercises
Programming Exercise&lt;/p&gt;
&lt;p&gt;Check Your Understanding&lt;/p&gt;
&lt;h4 id=&#34;regularization-simplicity-正则化简单性&#34;&gt;Regularization: Simplicity (正则化：简单性)&lt;/h4&gt;
&lt;p&gt;Playground Exercise: Overcrossing?
Video Lecture
L2 Regularization
Lambda
Playground Exercise: L2 Regularization
Check Your Understanding&lt;/p&gt;
&lt;h4 id=&#34;logistic-regression&#34;&gt;Logistic Regression&lt;/h4&gt;
&lt;p&gt;Video Lecture
Calculating a Probability
Loss and Regularization&lt;/p&gt;
&lt;h4 id=&#34;classification&#34;&gt;Classification&lt;/h4&gt;
&lt;p&gt;Video Lecture
Thresholding
True vs. False; Positive vs. Negative
Accuracy
Precision and Recall
Check Your Understanding: Accuracy, Precision, Recall
ROC Curve and AUC
Check Your Understanding: ROC and AUC
Prediction Bias
Programming Exercise&lt;/p&gt;
&lt;h4 id=&#34;regularization-sparsity-正则化稀疏性&#34;&gt;Regularization: Sparsity (正则化：稀疏性)&lt;/h4&gt;
&lt;p&gt;Video Lecture
L1 Regularization
Playground Exercise
Check Your Understanding&lt;/p&gt;
&lt;h4 id=&#34;neural-networks&#34;&gt;Neural Networks&lt;/h4&gt;
&lt;p&gt;Video Lecture
Structure
Playground Exercises
Programming Exercise&lt;/p&gt;
&lt;h4 id=&#34;training-neural-nets&#34;&gt;Training Neural Nets&lt;/h4&gt;
&lt;p&gt;Video Lecture
Best Practices&lt;/p&gt;
&lt;h4 id=&#34;multi-class-neural-nets&#34;&gt;Multi-Class Neural Nets&lt;/h4&gt;
&lt;p&gt;Video Lecture
One vs. All
Softmax
Programming Exercise&lt;/p&gt;
&lt;h4 id=&#34;embeddings-嵌入&#34;&gt;Embeddings (嵌入)&lt;/h4&gt;
&lt;p&gt;Video Lecture
Motivation from Collaborative Filtering
Categorical Input Data
Translating to a Lower-Dimensional Space
Obtaining Embeddings&lt;/p&gt;
&lt;h2 id=&#34;ml-engineering&#34;&gt;ML Engineering&lt;/h2&gt;
&lt;h4 id=&#34;production-ml-systems&#34;&gt;Production ML Systems&lt;/h4&gt;
&lt;h4 id=&#34;static-vs-dynamic-training&#34;&gt;Static vs. Dynamic Training&lt;/h4&gt;
&lt;p&gt;Video Lecture
Check Your Understanding&lt;/p&gt;
&lt;h4 id=&#34;static-vs-dynamic-inference&#34;&gt;Static vs. Dynamic Inference&lt;/h4&gt;
&lt;p&gt;Video Lecture
Check Your Understanding&lt;/p&gt;
&lt;h4 id=&#34;data-dependencies&#34;&gt;Data Dependencies&lt;/h4&gt;
&lt;p&gt;Video Lecture
Check Your Understanding&lt;/p&gt;
&lt;h4 id=&#34;fairness&#34;&gt;Fairness&lt;/h4&gt;
&lt;p&gt;Video Lecture
Types of Bias
Identifying Bias
Evaluating for Bias
Programming Exercise
Check Your Understanding&lt;/p&gt;
&lt;h2 id=&#34;ml-systems-in-the-real-world&#34;&gt;ML Systems in the Real World&lt;/h2&gt;
&lt;h4 id=&#34;cancer-prediction&#34;&gt;Cancer Prediction&lt;/h4&gt;
&lt;h4 id=&#34;literature&#34;&gt;Literature&lt;/h4&gt;
&lt;h4 id=&#34;guidelines&#34;&gt;Guidelines&lt;/h4&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;h4 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h4&gt;
</description>
      
    </item>
    
    <item>
      <title>notes of deep learning with python</title>
      <link>http://csyezheng.github.io/post/deep-learning/notes-deep-learning-with-python/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csyezheng.github.io/post/deep-learning/notes-deep-learning-with-python/</guid>
      
        <description>&lt;h1 id=&#34;deep-learning-with-python&#34;&gt;Deep Learning with Python&lt;/h1&gt;
&lt;h2 id=&#34;part-1---fundamentals-of-deep-learning&#34;&gt;PART 1 - FUNDAMENTALS OF DEEP LEARNING&lt;/h2&gt;
&lt;h3 id=&#34;1what-is-deep-learning&#34;&gt;1.What is deep learning?&lt;/h3&gt;
&lt;h4 id=&#34;artificial-intelligence-machine-learning-and-deep-learning&#34;&gt;Artificial intelligence, machine learning, and deep learning&lt;/h4&gt;
&lt;h4 id=&#34;before-deep-learning-a-brief-history-of-machine-learning&#34;&gt;Before deep learning: a brief history of machine learning&lt;/h4&gt;
&lt;h4 id=&#34;why-deep-learning-why-now&#34;&gt;Why deep learning? Why now?&lt;/h4&gt;
&lt;h3 id=&#34;2before-we-begin-the-mathematical-building-blocks-of-neural-networks&#34;&gt;2.Before we begin: the mathematical building blocks of neural networks&lt;/h3&gt;
&lt;h4 id=&#34;a-first-look-at-a-neural-network&#34;&gt;A first look at a neural network&lt;/h4&gt;
&lt;h4 id=&#34;data-representations-for-neural-networks&#34;&gt;Data representations for neural networks&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;tensor&lt;/strong&gt;: it’s a container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions (note that in the context of tensors, a &lt;strong&gt;dimension&lt;/strong&gt; is often called an &lt;strong&gt;axis&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;A tensor is defined by three key attributes: Number of axes (rank), Shape, Data type.&lt;/p&gt;
&lt;p&gt;Because the contents of the tensors manipulated by tensor operations can be interpreted as coordinates of points in some geometric space, &lt;strong&gt;all tensor operations have a geometric interpretation&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;the-gears-of-neural-networks-tensor-operations&#34;&gt;The gears of neural networks: tensor operations&lt;/h4&gt;
&lt;p&gt;Neural networks consist entirely of chains of tensor operations and that all of these tensor operations are just geometric transformations of the input data. It follows that &lt;strong&gt;you can interpret a neural network as a very complex geometric transformation in a high-dimensional space&lt;/strong&gt;, implemented via a long series of simple steps.&lt;/p&gt;
&lt;p&gt;Uncrumpling paper balls is what machine learning is about: &lt;strong&gt;finding neat representations for complex, highly folded data manifolds&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;the-engine-of-neural-networks-gradient-based-optimization&#34;&gt;The engine of neural networks: gradient-based optimization&lt;/h4&gt;
&lt;p&gt;training loop:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Draw a batch of training samples x and corresponding targets y.&lt;/li&gt;
&lt;li&gt;Run the network on x (a step called the forward pass) to obtain predictions y_pred .&lt;/li&gt;
&lt;li&gt;Compute the loss of the network on the batch, a measure of the mismatch
between y_pred and y .&lt;/li&gt;
&lt;li&gt;Update all weights of the network in a way that slightly reduces the loss on this batch.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;One naive solution would be to freeze all weights in the network except the one scalar coefficient being considered, and try different values for this coefficient. But such an approach would be horribly inefficient, because you’d need to compute two forward passes (which are expensive) for every individual coefficient (of which there are many, usually thousands and sometimes up to millions).&lt;/p&gt;
&lt;p&gt;A much better approach is to take advantage of the fact that all operations used in the network are differentiable, and &lt;strong&gt;compute the gradient of the loss with regard to the network’s coefficients&lt;/strong&gt;. You can then &lt;strong&gt;move the coefficients in the opposite direction from the gradient, thus decreasing the loss&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For every differentiable function f(x) (&lt;strong&gt;differentiable means “can be derived”&lt;/strong&gt;: for example, smooth, continuous functions can be derived),&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;gradient&lt;/strong&gt; is the derivative of a tensor operation. It’s the generalization of the concept of &lt;strong&gt;derivatives&lt;/strong&gt; to functions of multidimensional inputs: that is, to functions that take tensors as inputs.&lt;/p&gt;
&lt;p&gt;You saw earlier that the derivative of a function f(x) of a single coefficient can be interpreted as the &lt;strong&gt;slope&lt;/strong&gt; of the curve of f. Likewise, gradient(f)(W0) can be interpreted as the &lt;strong&gt;tensor&lt;/strong&gt; describing the curvature of f(W) around W0.&lt;/p&gt;
&lt;p&gt;For this reason, in much the same way that, for a function f(x), you can reduce the value of f(x) by moving x a little in the opposite direction from the derivative, with a function f(W) of a tensor, you can &lt;strong&gt;reduce f(W) by moving W in the opposite direction from the gradient&lt;/strong&gt;: for example, W1 = W0 - step * gradient(f)(W0)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mini-batch stochastic gradient descent&lt;/strong&gt; (mini-batch SGD):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Draw a batch of training samples x and corresponding targets y.&lt;/li&gt;
&lt;li&gt;Run the network on x to obtain predictions y_pred.&lt;/li&gt;
&lt;li&gt;Compute the loss of the network on the batch, a measure of the mismatch
between y_pred and y .&lt;/li&gt;
&lt;li&gt;Compute the gradient of the loss with regard to the network’s parameters (a
backward pass).&lt;/li&gt;
&lt;li&gt;Move the parameters a little in the opposite direction from the gradient for example W -= step * gradient—thus reducing the loss on the batch a bit.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that a variant of the mini-batch SGD algorithm would be to draw a single sample and target at each iteration, rather than drawing a batch of data. This would be &lt;strong&gt;true SGD&lt;/strong&gt; (as opposed to &lt;strong&gt;mini-batch SGD&lt;/strong&gt;). Alternatively, going to the opposite extreme, you could run every step on all data available, which is called &lt;strong&gt;batch SGD&lt;/strong&gt;. Each update would then be more accurate, but far more expensive. The efficient compromise between these two extremes is to use mini-batches of reasonable size.&lt;/p&gt;
&lt;p&gt;Additionally, there exist &lt;strong&gt;multiple variants of SGD&lt;/strong&gt; that differ by taking into account previous weight updates when computing the next weight update, rather than just looking at the current value of the gradients. There is, for instance, &lt;strong&gt;SGD with momentum&lt;/strong&gt;, as well as &lt;strong&gt;Adagrad&lt;/strong&gt;, &lt;strong&gt;RMSP rop&lt;/strong&gt;, and several others. Such variants are known as &lt;strong&gt;optimization methods&lt;/strong&gt; or &lt;strong&gt;optimizers&lt;/strong&gt;. In particular, the concept of momentum, which is used in many of these variants, deserves your attention. &lt;strong&gt;Momentum addresses two issues with SGD: convergence speed and local minima.&lt;/strong&gt;&lt;/p&gt;
&lt;h6 id=&#34;chaining-derivatives-the-backpropagation-algorithm&#34;&gt;Chaining derivatives: the Backpropagation algorithm&lt;/h6&gt;
&lt;p&gt;Calculus tells us that such a chain of functions can be derived using the following identity, called the &lt;strong&gt;chain rule&lt;/strong&gt;: f(g(x)) = f&amp;rsquo;(g(x)) * g&amp;rsquo;(x). Applying the chain rule to the computation of the gradient values of a neural network gives rise to an algorithm called &lt;strong&gt;Backpropagation&lt;/strong&gt; (also sometimes called &lt;strong&gt;reverse-mode differentiation&lt;/strong&gt;). Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, applying the chain rule to compute the contribution that each parameter had in the loss value.&lt;/p&gt;
&lt;h4 id=&#34;looking-back-at-our-first-example&#34;&gt;Looking back at our first example&lt;/h4&gt;
&lt;h3 id=&#34;3getting-started-with-neural-networks&#34;&gt;3.Getting started with neural networks&lt;/h3&gt;
&lt;h4 id=&#34;anatomy-of-a-neural-network&#34;&gt;Anatomy of a neural network&lt;/h4&gt;
&lt;p&gt;Figure 3.1 Relationship between the network, layers, loss function, and optimizer&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/03fig01.jpg&#34; alt=&#34;Relationship between the network, layers, loss function, and optimizer&#34;&gt;&lt;/p&gt;
&lt;p&gt;Different layers are appropriate for different tensor formats and different types of data processing. For instance, simple vector data, stored in 2D tensors of shape (samples, features) , is often processed by densely connected layers, also called fully connected or dense layers (the Dense class in Keras). Sequence data, stored in 3D tensors of shape (samples, timesteps, features), is typically processed by recurrent layers such as an LSTM layer. Image data, stored in 4D tensors, is usually processed by 2D convolution layers Conv2D).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from keras import layers

# A dense layer with 32 output units
layer = layers.Dense(32, input_shape=(784,))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the network architecture is defined, you still have to choose two more things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Loss function&lt;/strong&gt; (objective function)—The quantity that will be minimized during
training. It represents a measure of success for the task at hand.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Optimizer&lt;/strong&gt;—Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD). A neural network that has multiple outputs may have multiple loss functions (one per output).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Choosing the right objective function for the right problem is extremely important: your network will take any shortcut it can, to minimize the loss; so if the objective doesn’t fully correlate with success for the task at hand, your network will end up doing things you may not have wanted.&lt;/p&gt;
&lt;p&gt;Fortunately, when it comes to common problems such as classification, regression, and sequence prediction, there are simple guidelines you can follow to choose the correct loss. For instance, you’ll use &lt;strong&gt;binary crossentropy&lt;/strong&gt; for a two-class classification problem, &lt;strong&gt;categorical crossentropy&lt;/strong&gt; for a many-class classification problem, &lt;strong&gt;mean-squared error&lt;/strong&gt; for a regression problem, &lt;strong&gt;connectionist temporal classification&lt;/strong&gt; (CTC) for a sequence-learning problem, and so on. Only when you’re working on truly new research problems will you have to develop your own objective functions. In the next few chapters, we’ll detail explicitly which loss functions to choose for a wide range of common tasks.&lt;/p&gt;
&lt;h4 id=&#34;introduction-to-keras&#34;&gt;Introduction to Keras&lt;/h4&gt;
&lt;p&gt;There are two ways to define a model: using the Sequential class (only for linear
stacks of layers, which is the most common network architecture by far) or the functional API (for directed acyclic graphs of layers, which lets you build completely arbitrary architectures).&lt;/p&gt;
&lt;p&gt;what type of network architectures work for different kinds of problems, how to pick the right learning configuration, and how to tweak a model until it gives the results you want to see.&lt;/p&gt;
&lt;h4 id=&#34;setting-up-a-deep-learning-workstation&#34;&gt;Setting up a deep-learning workstation&lt;/h4&gt;
&lt;h6 id=&#34;jupyter-notebooks-the-preferred-way-to-run-deep-learning-experiments&#34;&gt;Jupyter notebooks: the preferred way to run deep-learning experiments&lt;/h6&gt;
&lt;p&gt;you don’t have to rerun all of your previous code if something goes wrong late in an experiment.&lt;/p&gt;
&lt;h4 id=&#34;classifying-movie-reviews-a-binary-classification-example&#34;&gt;Classifying movie reviews: a binary classification example&lt;/h4&gt;
&lt;p&gt;There are two key architecture decisions to be made about such a stack of Dense layers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How many layers to use&lt;/li&gt;
&lt;li&gt;How many hidden units to choose for each layer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In chapter 4, you’ll learn formal principles to guide you in making these choices.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;relu&lt;/strong&gt; (rectified linear unit) is a function meant to zero out negative values
&lt;img src=&#34;https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/03fig04_alt.jpg&#34; alt=&#34;Figure 3.4  The rectified linear unit function&#34;&gt;&lt;/p&gt;
&lt;p&gt;whereas a &lt;strong&gt;sigmoid&lt;/strong&gt; “squashes” arbitrary values into the [0, 1] interval  outputting something that can be interpreted as a probability.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/03fig05_alt.jpg&#34; alt=&#34;Figure 3.5 The sigmoid function&#34;&gt;&lt;/p&gt;
&lt;h6 id=&#34;what-are-activation-functions-and-why-are-they-necessary&#34;&gt;What are activation functions, and why are they necessary?&lt;/h6&gt;
&lt;p&gt;Without an activation function like relu (also called a non-linearity), the Dense layer would consist of two linear operations—a dot product and an addition:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;output = dot(W, input) + b
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In order to get access to a much richer hypothesis space that would benefit from deep representations, you need a non-linearity, or activation function. &lt;strong&gt;relu&lt;/strong&gt; is the most popular activation function in deep learning, but there are many other candidates, which all come with similarly strange names: prelu, elu, and so on.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Crossentropy&lt;/strong&gt; is usually the best choice when you’re dealing with models that &lt;strong&gt;output probabilities&lt;/strong&gt;. Crossentropy is a quantity from the field of Information Theory &lt;strong&gt;that measures the distance between probability distributions&lt;/strong&gt; or, in this case, between the ground-truth distribution and your predictions.&lt;/p&gt;
&lt;h6 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;In a &lt;strong&gt;binary classification problem&lt;/strong&gt; (two output classes), your network &lt;strong&gt;should end with a Dense layer with one unit and a sigmoid activation&lt;/strong&gt;: the output of your network should be a scalar between 0 and 1, &lt;strong&gt;encoding a probability&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;With such a scalar &lt;strong&gt;sigmoid&lt;/strong&gt; output on a binary classification problem, the loss function you should use is &lt;strong&gt;binary_crossentropy&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;rmsprop&lt;/strong&gt; optimizer is generally a good enough choice, whatever your problem. That’s one less thing for you to worry about.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;classifying-newswires-a-multiclass-classification-example&#34;&gt;Classifying newswires: a multiclass classification example&lt;/h4&gt;
&lt;p&gt;Because you have many classes, this problem is an instance of &lt;strong&gt;multi-class classification&lt;/strong&gt;; and because each data point should be classified into only one category, the problem is more specifically an instance of &lt;strong&gt;single-label, multiclass classification&lt;/strong&gt;. If each data point could belong to multiple categories (in this case, topics), you’d be facing a &lt;strong&gt;multilabel, multiclass classification&lt;/strong&gt; problem.&lt;/p&gt;
&lt;p&gt;In the previous example, you used 16-dimensional intermediate layers, but a 16-dimensional space may be too limited to learn to separate 46 different classes: &lt;strong&gt;such small layers may act as information bottlenecks, permanently dropping relevant information&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(64, activation=&#39;relu&#39;, input_shape=(10000,)))
model.add(layers.Dense(64, activation=&#39;relu&#39;))
model.add(layers.Dense(46, activation=&#39;softmax&#39;))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are two other things you should note about this architecture:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You end the network with a Dense layer of size 46. This means for each input sample, the network will output a 46-dimensional vector. &lt;strong&gt;Each entry in this vector (each dimension) will encode a different output class.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The last layer uses a &lt;strong&gt;softmax&lt;/strong&gt; activation. You saw this pattern in the MNIST example. It means the network will &lt;strong&gt;output a probability distribution over the 46 different output classes&lt;/strong&gt;—for every input sample, the network will produce a 46 dimensional output vector, &lt;strong&gt;where output[i] is the probability that the sample belongs to class i&lt;/strong&gt; . &lt;strong&gt;The 46 scores will sum to 1&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The best loss function to use in this case is &lt;strong&gt;categorical_crossentropy&lt;/strong&gt;. &lt;strong&gt;It measures the distance between two probability distributions&lt;/strong&gt;: here, &lt;strong&gt;between the probability distribution output by the network and the true distribution of the labels.&lt;/strong&gt; By minimizing the distance between these two distributions, you train the network to output something as close as possible to the true labels.&lt;/p&gt;
&lt;p&gt;Plotting the training and validation loss:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import matplotlib.pyplot as plt
loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;Training loss&#39;)
plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;)
plt.title(&#39;Training and validation loss&#39;)
plt.xlabel(&#39;Epochs&#39;)
plt.ylabel(&#39;Loss&#39;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Plotting the training and validation accuracy:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plt.clf()  # Clears the figure
acc = history.history[&#39;acc&#39;]
val_acc = history.history[&#39;val_acc&#39;]
plt.plot(epochs, acc, &#39;bo&#39;, label=&#39;Training acc&#39;)
plt.plot(epochs, val_acc, &#39;b&#39;, label=&#39;Validation acc&#39;)
plt.title(&#39;Training and validation accuracy&#39;)
plt.xlabel(&#39;Epochs&#39;)
plt.ylabel(&#39;Loss&#39;)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The only thing this approach would change is the choice of the loss function. The loss function used in listing 3.21, &lt;strong&gt;categorical_crossentropy&lt;/strong&gt;, expects the labels to follow a &lt;strong&gt;categorical encoding&lt;/strong&gt;. With &lt;strong&gt;integer labels&lt;/strong&gt;, you should use **sparse_categorical_ crossentropy**.&lt;/p&gt;
&lt;h6 id=&#34;the-importance-of-having-sufficiently-large-intermediate-layers&#34;&gt;The importance of having sufficiently large intermediate layers&lt;/h6&gt;
&lt;p&gt;We mentioned earlier that because the final outputs are 46-dimensional, you should avoid intermediate layers with many fewer than 46 hidden units.&lt;/p&gt;
&lt;h6 id=&#34;wrapping-up-1&#34;&gt;Wrapping up&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you’re trying to classify data points among N classes, your network should &lt;strong&gt;end with a Dense layer of size N&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In a &lt;strong&gt;single-label, multiclass classification&lt;/strong&gt; problem, your network should end with a &lt;strong&gt;softmax&lt;/strong&gt; activation so that it will output a probability distribution over the N output classes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Categorical crossentropy&lt;/strong&gt; is almost always the loss function you should use for such problems. It minimizes the distance between the probability distributions output by the network and the true distribution of the targets.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are two ways to handle labels in &lt;strong&gt;multiclass classification&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encoding the labels via categorical encoding (also known as one-hot encoding) and using &lt;strong&gt;categorical_crossentropy&lt;/strong&gt; as a loss function&lt;/li&gt;
&lt;li&gt;Encoding the labels as integers and using the &lt;strong&gt;sparse_categorical_crossentropy&lt;/strong&gt; loss function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you need to classify data into a large number of categories, you should &lt;strong&gt;avoid&lt;/strong&gt; creating information bottlenecks in your network due to &lt;strong&gt;intermediate layers that are too small&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;predicting-house-prices-a-regression-example&#34;&gt;Predicting house prices: a regression example&lt;/h4&gt;
&lt;p&gt;And each feature in the input data (for example, the crime rate) has a different scale. For instance, some values are proportions, which take values between 0 and 1; others take values between 1 and 12, others between 0 and 100, and so on.&lt;/p&gt;
&lt;p&gt;It would be problematic to feed into a neural network values that all take wildly different ranges. The network might be able to automatically adapt to such heterogeneous data, but it would definitely make learning more difficult. A widespread best practice to deal with such data is to do feature-wise normalization: for each feature in the input data (a column in the input data matrix), you subtract the mean of the feature and divide by the standard deviation, so that the feature is centered around 0 and has a unit standard deviation.&lt;/p&gt;
&lt;p&gt;In general, the less training data you have, the worse overfitting will be, and &lt;strong&gt;using a small network is one way to mitigate overfitting&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;the &lt;strong&gt;mse&lt;/strong&gt; loss function—&lt;strong&gt;mean squared error&lt;/strong&gt;, the square of the difference between the predictions and the targets. This is a widely used loss function &lt;strong&gt;for regression problems&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You’re also monitoring a new metric during training: &lt;strong&gt;mean absolute error&lt;/strong&gt; (&lt;strong&gt;MAE&lt;/strong&gt;). It’s the absolute value of the difference between the predictions and the targets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;K-fold validation&lt;/strong&gt;&lt;/p&gt;
&lt;h6 id=&#34;wrapping-up-2&#34;&gt;Wrapping up&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Regression is done using different loss functions than what we used for classification. Mean squared error (MSE) is a loss function commonly used for regression.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Similarly, evaluation metrics to be used for regression differ from those used for classification; naturally, the concept of accuracy doesn’t apply for regression. A common regression metric is mean absolute error (MAE).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When features in the input data have values in different ranges, each feature should be scaled independently as a preprocessing step.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When there is little data available, using K-fold validation is a great way to reliably evaluate a model.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When little training data is available, it’s preferable to use a small network with few hidden layers (typically only one or two), in order to avoid severe overfitting.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4fundamentals-of-machine-learning&#34;&gt;4.Fundamentals of machine learning&lt;/h3&gt;
&lt;h4 id=&#34;four-branches-of-machine-learning&#34;&gt;Four branches of machine learning&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Mini-batch&lt;/strong&gt; or &lt;strong&gt;batch&lt;/strong&gt;—A small set of samples (typically between 8 and 128)
that are processed simultaneously by the model. &lt;strong&gt;The number of samples is&lt;/strong&gt;
&lt;strong&gt;often a power of 2, to facilitate memory allocation on GPU&lt;/strong&gt;. When training, a
&lt;strong&gt;mini-batch is used to compute a single gradient-descent update applied to&lt;/strong&gt;
&lt;strong&gt;the weights of the model.&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;evaluating-machine-learning-models&#34;&gt;Evaluating machine-learning models&lt;/h4&gt;
&lt;p&gt;In machine learning, the goal is to achieve models that &lt;strong&gt;generalize&lt;/strong&gt;—that perform well on never-before-seen data—and &lt;strong&gt;overfitting&lt;/strong&gt; is the central obstacle.&lt;/p&gt;
&lt;p&gt;three classic &lt;strong&gt;evaluation recipes&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;simple hold-out validation&lt;/li&gt;
&lt;li&gt;K-fold validation&lt;/li&gt;
&lt;li&gt;iterated K-fold validation with shuffling.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data representativeness: you usually should &lt;strong&gt;randomly shuffle your data before splitting it into training and test sets&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The arrow of time: If you’re trying to predict the future given the past (for example, tomorrow’s weather, stock movements, and so on), you &lt;strong&gt;should not randomly shuffle your data before splitting it&lt;/strong&gt;, because doing so will create a temporal leak.&lt;/p&gt;
&lt;p&gt;Redundancy in your data: &lt;strong&gt;Make sure your training set and validation set are disjoint.&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;data-preprocessing-feature-engineering-and-feature-learning&#34;&gt;Data preprocessing, feature engineering, and feature learning&lt;/h4&gt;
&lt;h5 id=&#34;data-preprocessing-for-neural-networks&#34;&gt;Data preprocessing for neural networks&lt;/h5&gt;
&lt;p&gt;Data preprocessing aims at making the raw data at hand more amenable to neural networks. This includes &lt;strong&gt;vectorization&lt;/strong&gt;, &lt;strong&gt;normalization&lt;/strong&gt;, &lt;strong&gt;handling missing values&lt;/strong&gt;, and &lt;strong&gt;feature extraction&lt;/strong&gt;.&lt;/p&gt;
&lt;h6 id=&#34;value-normalization&#34;&gt;VALUE NORMALIZATION&lt;/h6&gt;
&lt;p&gt;In general, &lt;strong&gt;it isn’t safe to feed into&lt;/strong&gt; a neural network data that takes relatively large values (for example, multidigit integers, which are much larger than the initial values taken by the weights of a network) or data that is heterogeneous (for example, data where one feature is in the range 0–1 and another is in the range 100–200). &lt;strong&gt;Doing so can trigger large gradient updates that will prevent the network from converging&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To make learning easier for your network, your data should have the following characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Take small values—&lt;strong&gt;Typically, most values should be in the 0–1 range&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Be homogenous—That is, &lt;strong&gt;all features should take values in roughly the same range&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additionally, the following stricter normalization practice is common and can help, although it isn’t always necessary&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normalize each feature independently to &lt;strong&gt;have a mean of 0.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Normalize each feature independently to have a &lt;strong&gt;standard deviation of 1&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;handling-missing-values&#34;&gt;HANDLING MISSING VALUES&lt;/h6&gt;
&lt;p&gt;In general, with neural networks, &lt;strong&gt;it’s safe to input missing values as 0&lt;/strong&gt;, with the condition that 0 isn’t already a meaningful value. The network will learn from exposure to the data that the value 0 means missing data and will start ignoring the value.&lt;/p&gt;
&lt;h5 id=&#34;feature-engineering&#34;&gt;Feature engineering&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Feature engineering&lt;/strong&gt; is the process of using your own knowledge about the data and about the machine-learning algorithm at hand (in this case, a neural network) to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.&lt;/p&gt;
&lt;p&gt;That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.&lt;/p&gt;
&lt;p&gt;Before deep learning, feature engineering used to be critical, because classical shallow algorithms didn’t have hypothesis spaces rich enough to learn useful features by themselves.&lt;/p&gt;
&lt;p&gt;Fortunately, modern deep learning removes the need for most feature engineering, because neural networks are capable of automatically extracting useful features from raw data.&lt;/p&gt;
&lt;p&gt;Good features let you solve a problem with far less data.&lt;/p&gt;
&lt;h4 id=&#34;overfitting-and-underfitting&#34;&gt;Overfitting and underfitting&lt;/h4&gt;
&lt;p&gt;You must evaluate an array of different architectures (on your validation set, not on your test set, of course) &lt;strong&gt;in order to find the correct model size for your data&lt;/strong&gt;. The general workflow to find an appropriate model size is &lt;strong&gt;to start with relatively few layers and parameters, and increase the size of the layers or add new layers until&lt;/strong&gt; you see diminishing returns with regard to validation loss.&lt;/p&gt;
&lt;h6 id=&#34;adding-weight-regularization&#34;&gt;Adding weight regularization&lt;/h6&gt;
&lt;p&gt;You may be familiar with the principle of Occam’s razor: given two explanations for something, the explanation most likely to be correct is the simplest one—the one that makes fewer assumptions.&lt;/p&gt;
&lt;p&gt;Thus a common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights to take only small values, which makes the distribution of weight values more regular. This is called weight regularization, and it’s done by adding to the loss function of the network a cost associated with having large weights.&lt;/p&gt;
&lt;p&gt;This cost comes in two flavors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;L1 regularization—The cost added is proportional to the absolute value of the weight coefficients (the L1 norm of the weights).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;L2 regularization—The cost added is proportional to the square of the value of the weight coefficients (the L2 norm of the weights).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that because &lt;strong&gt;this penalty is only added at training time&lt;/strong&gt;, &lt;strong&gt;the loss&lt;/strong&gt; for this network will be much &lt;strong&gt;higher at training than at test time&lt;/strong&gt;.&lt;/p&gt;
&lt;h6 id=&#34;adding-dropout&#34;&gt;Adding dropout&lt;/h6&gt;
&lt;p&gt;Let’s say a given layer would normally return a vector &lt;code&gt;[0.2, 0.5, 1.3, 0.8, 1.1] &lt;/code&gt; for a given input sample during training. &lt;strong&gt;After applying dropout, this vector will have a few zero entries distributed at random&lt;/strong&gt;: for example, [0, 0.5, 1.3, 0, 1.1]. &lt;strong&gt;The dropout rate is the fraction of the features that are zeroed out; it’s usually set between 0.2 and 0.5.&lt;/strong&gt; &lt;strong&gt;At test time, no units are dropped out&lt;/strong&gt;; instead, the layer’s output values are &lt;strong&gt;scaled down by a factor equal to the dropout rate&lt;/strong&gt;, &lt;strong&gt;to balance for&lt;/strong&gt; the fact that more units are active than at training time.&lt;/p&gt;
&lt;p&gt;To recap, these are &lt;strong&gt;the most common ways to prevent overfitting in neural  networks&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get more training data.&lt;/li&gt;
&lt;li&gt;Reduce the capacity of the network.&lt;/li&gt;
&lt;li&gt;Add weight regularization.&lt;/li&gt;
&lt;li&gt;Add dropout.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;the-universal-workflow-of-machine-learning&#34;&gt;The universal workflow of machine learning&lt;/h4&gt;
&lt;p&gt;For &lt;strong&gt;balanced-classification problems&lt;/strong&gt;, where every class is equally likely, &lt;strong&gt;accuracy&lt;/strong&gt; and &lt;strong&gt;area under the receiver operating characteristic curve&lt;/strong&gt; (ROC AUC) are common metrics. For &lt;strong&gt;class-imbalanced problems&lt;/strong&gt;, you can use &lt;strong&gt;precision&lt;/strong&gt; and &lt;strong&gt;recall&lt;/strong&gt;. For &lt;strong&gt;ranking problems&lt;/strong&gt; or &lt;strong&gt;multilabel classification&lt;/strong&gt;, you can use &lt;strong&gt;mean average precision&lt;/strong&gt;. And it isn’t uncommon to have to define your own &lt;strong&gt;custom metric&lt;/strong&gt; by which to measure success. To get a sense of the diversity of machine-learning success metrics and how they relate to different problem domains, it’s helpful to browse the data science competitions on &lt;strong&gt;Kaggle&lt;/strong&gt; (&lt;a href=&#34;https://kaggle.com&#34;&gt;https://kaggle.com&lt;/a&gt;); they showcase a wide range of problems and evaluation metrics.&lt;/p&gt;
&lt;h6 id=&#34;preparing-your-data&#34;&gt;Preparing your data&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;As you saw previously, your data should be formatted as tensors.&lt;/li&gt;
&lt;li&gt;The values taken by these tensors should usually be scaled to small values: for example, in the [-1, 1] range or [0, 1] range.&lt;/li&gt;
&lt;li&gt;If different features take values in different ranges (heterogeneous data), then the data should be normalized.&lt;/li&gt;
&lt;li&gt;You may want to do some feature engineering, especially for small-data problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;developing-a-model-that-does-better-than-a-baseline&#34;&gt;Developing a model that does better than a baseline&lt;/h6&gt;
&lt;p&gt;Assuming that things go well, you need to make three key choices to build your
first working model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Last-layer activation&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss function&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optimization configuration&lt;/strong&gt;—What optimizer will you use? What will its learning rate be? In most cases, it’s safe to go with &lt;strong&gt;rmsprop&lt;/strong&gt; and its &lt;strong&gt;default learning rate&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Problem type&lt;/th&gt;
&lt;th&gt;Last-layer activation&lt;/th&gt;
&lt;th&gt;Loss function&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Binary classification&lt;/td&gt;
&lt;td&gt;sigmoid&lt;/td&gt;
&lt;td&gt;binary_crossentropy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Multiclass, single-label classification&lt;/td&gt;
&lt;td&gt;softmax&lt;/td&gt;
&lt;td&gt;categorical_crossentropy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Multiclass, multilabel classification&lt;/td&gt;
&lt;td&gt;sigmoid&lt;/td&gt;
&lt;td&gt;binary_crossentropy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Regression to arbitrary values&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;mse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Regression to values between 0 and 1&lt;/td&gt;
&lt;td&gt;sigmoid&lt;/td&gt;
&lt;td&gt;mse or binary_crossentropy&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h6 id=&#34;scaling-up-developing-a-model-that-overfits&#34;&gt;Scaling up: developing a model that overfits&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Add layers.&lt;/li&gt;
&lt;li&gt;Make the layers bigger.&lt;/li&gt;
&lt;li&gt;Train for more epochs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;regularizing-your-model-and-tuning-your-hyperparameters&#34;&gt;Regularizing your model and tuning your hyperparameters&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;Add dropout.&lt;/li&gt;
&lt;li&gt;Try different architectures: add or remove layers.&lt;/li&gt;
&lt;li&gt;Add L1 and/or L2 regularization.&lt;/li&gt;
&lt;li&gt;Try different hyperparameters (such as the number of units per layer or the learning rate of the optimizer) to find the optimal configuration.&lt;/li&gt;
&lt;li&gt;Optionally, iterate on feature engineering: add new features, or remove features that don’t seem to be informative.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;part-2---deep-learning-in-practice&#34;&gt;PART 2 - DEEP LEARNING IN PRACTICE&lt;/h2&gt;
&lt;h3 id=&#34;5deep-learning-for-computer-vision&#34;&gt;5.Deep learning for computer vision&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-convnets&#34;&gt;Introduction to convnets&lt;/h4&gt;
&lt;h4 id=&#34;training-a-convnet-from-scratch-on-a-small-dataset&#34;&gt;Training a convnet from scratch on a small dataset&lt;/h4&gt;
&lt;h4 id=&#34;the-relevance-of-deep-learning-for-small-data-problems&#34;&gt;The relevance of deep learning for small-data problems&lt;/h4&gt;
&lt;h4 id=&#34;using-a-pretrained-convnet&#34;&gt;Using a pretrained convnet&lt;/h4&gt;
&lt;h4 id=&#34;visualizing-what-convnets-learn&#34;&gt;Visualizing what convnets learn&lt;/h4&gt;
&lt;h3 id=&#34;6deep-learning-for-text-and-sequences&#34;&gt;6.Deep learning for text and sequences&lt;/h3&gt;
&lt;h4 id=&#34;working-with-text-data&#34;&gt;Working with text data&lt;/h4&gt;
&lt;h4 id=&#34;understanding-recurrent-neural-networks&#34;&gt;Understanding recurrent neural networks&lt;/h4&gt;
&lt;h4 id=&#34;advanced-use-of-recurrent-neural-networks&#34;&gt;Advanced use of recurrent neural networks&lt;/h4&gt;
&lt;h4 id=&#34;sequence-processing-with-convnets&#34;&gt;Sequence processing with convnets&lt;/h4&gt;
&lt;h3 id=&#34;7advanced-deep-learning-best-practices&#34;&gt;7.Advanced deep-learning best practices&lt;/h3&gt;
&lt;h4 id=&#34;going-beyond-the-sequential-model-the-keras-functional-api&#34;&gt;Going beyond the Sequential model: the Keras functional API&lt;/h4&gt;
&lt;h4 id=&#34;inspecting-and-monitoring-deep-learning-models-using-keras-callbacks-and-tensorboard&#34;&gt;Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard&lt;/h4&gt;
&lt;h4 id=&#34;getting-the-most-out-of-your-models&#34;&gt;Getting the most out of your models&lt;/h4&gt;
&lt;h3 id=&#34;8generative-deep-learning&#34;&gt;8.Generative deep learning&lt;/h3&gt;
&lt;h4 id=&#34;text-generation-with-lstm&#34;&gt;Text generation with LSTM&lt;/h4&gt;
&lt;h4 id=&#34;deepdream&#34;&gt;DeepDream&lt;/h4&gt;
&lt;h4 id=&#34;neural-style-transfer&#34;&gt;Neural style transfer&lt;/h4&gt;
&lt;h4 id=&#34;generating-images-with-variational-autoencoders&#34;&gt;Generating images with variational autoencoders&lt;/h4&gt;
&lt;h4 id=&#34;introduction-to-generative-adversarial-networks&#34;&gt;Introduction to generative adversarial networks&lt;/h4&gt;
&lt;h3 id=&#34;9conclusions&#34;&gt;9.Conclusions&lt;/h3&gt;
&lt;h4 id=&#34;key-concepts-in-review&#34;&gt;Key concepts in review&lt;/h4&gt;
&lt;h4 id=&#34;the-limitations-of-deep-learning&#34;&gt;The limitations of deep learning&lt;/h4&gt;
&lt;h4 id=&#34;the-future-of-deep-learning&#34;&gt;The future of deep learning&lt;/h4&gt;
&lt;h4 id=&#34;staying-up-to-date-in-a-fast-moving-field&#34;&gt;Staying up to date in a fast-moving field&lt;/h4&gt;
&lt;h4 id=&#34;final-wordscd-c&#34;&gt;Final wordscd C&lt;/h4&gt;
</description>
      
    </item>
    
  </channel>
</rss>
