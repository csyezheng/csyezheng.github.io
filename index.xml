<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ye Zheng&#39;s Blog</title>
    <link>http://www.yezheng.pro/</link>
    <description>Recent content on Ye Zheng&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 06 Dec 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="http://www.yezheng.pro/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>http://www.yezheng.pro/about/</link>
      <pubDate>Mon, 25 Sep 2017 21:38:52 +0800</pubDate>
      
      <guid>http://www.yezheng.pro/about/</guid>
      
        <description>&lt;p&gt;I&amp;rsquo;m graduated from the Hebei GEO University with a degree in marketing, because I thought computers were cool from an early age, so I chose programmers as my future employment direction in my third year of college. In the third year of college, I learned some front-end knowledge, and in the fourth year of college I learned some C ++ related knowledge. After graduating, I naturally found a job related to programming.&lt;/p&gt;
&lt;p&gt;In the first company, I was mainly engaged in web crawling. I was responsible for scraping various financial data including stock exchanges, performing data cleaning, and completing an announcement classification system during the period. I worked as a data development engineer in the second company, and solved development problems such as real-time data forwarding, reception, and storage. I worked as a back-end development engineer at a third company and built the entire edx-based online learning system.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>evaluate the quality of the training phrases in intents</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/chatbot/evaluate-the-quality-of-the-training-phrases-in-intents/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/chatbot/evaluate-the-quality-of-the-training-phrases-in-intents/</guid>
      
        <description>&lt;p&gt;This tutorial shows you how to analyze and evaluate the quality of the training phrases supplied to your &lt;a href=&#34;https://dialogflow.com/&#34;&gt;Dialogflow&lt;/a&gt; agent&amp;rsquo;s intents. The purpose of this analysis is to avoid confusing the agent with phrases irrelevant to the intents supplied to, or more relevant to, other intents.&lt;/p&gt;
&lt;p&gt;The approach you take is to generate semantic embeddings of the training phrases by using the &lt;a href=&#34;https://www.tensorflow.org/hub/&#34;&gt;TensorFlow Hub&lt;/a&gt; (&lt;code&gt;tf.Hub&lt;/code&gt;) Universal Sentence Encoder module. You then compute cohesion and separation measurements based on the similarity between embeddings within the same intents and different intents. The tutorial also identifies &amp;ldquo;confusing&amp;rdquo; training phrases, where they are nearer—in the embedding space—to intents that are different from the ones supplied for.&lt;/p&gt;
&lt;p&gt;You can find the code for this tutorial in this &lt;a href=&#34;https://colab.research.google.com/drive/1QQblWJX5aZ6TajVXNAogFpVJlzYDbMtX&#34;&gt;Colab notebook&lt;/a&gt;. The article assumes that you have a basic background knowledge of Dialogflow. To learn more about Dialogflow, see this &lt;a href=&#34;https://cloud.google.com/solutions/building-and-deploying-chatbot-dialogflow&#34;&gt;multi-part tutorial&lt;/a&gt; on how to build, secure, and scale a chatbot by using Dialogflow Enterprise Edition on Google Cloud.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://dialogflow.com/&#34;&gt;Dialogflow&lt;/a&gt; lets you build conversational interfaces on top of your products and services by providing a powerful natural-language understanding (NLU) engine to process and understand natural language input. Use cases for Dialogflow include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Building booking and reservation bots for airlines, cinemas, and so on.&lt;/li&gt;
&lt;li&gt;Simplifying a system for ordering fast food for delivery.&lt;/li&gt;
&lt;li&gt;Enabling efficient customer service through semi-automated call centers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although you can implement complex conversational flows to handle a user utterance, Dialogflow fundamentally performs the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The user asks questions like, &amp;ldquo;What is the total of my bill for the last month?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;agent&lt;/em&gt; parses the input and matches it to an &lt;em&gt;intent&lt;/em&gt; such as &lt;code&gt;bill_value_inquiry&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The agent also extracts &lt;em&gt;entities&lt;/em&gt; information, like &amp;ldquo;last month&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Given the intent of the extracted entities, the agent then invokes a &lt;em&gt;fulfillment&lt;/em&gt; to respond to the user&amp;rsquo;s request.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following table describes the key concepts in the Dialogflow platform.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Term&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://dialogflow.com/docs/agents&#34;&gt;agent&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Agents are best described as NLU modules that can be integrated into your system. An agent converts text or spoken user requests into actionable data, when a user&amp;rsquo;s input matches an intent in your agent.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://dialogflow.com/docs/intents&#34;&gt;intent&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;In a conversation, intents map user input to responses. In each intent, you define examples (training phrases) of user utterances that can trigger the intent, what to extract from each utterance, and how to respond.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://dialogflow.com/docs/entities&#34;&gt;entities&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Where intents allow your agent to understand the motivation behind a particular user input, entities are used to pick out specific pieces of information that your users mention. For example, street addresses, product names, or amounts with units can be used to fulfill the user&amp;rsquo;s request.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://dialogflow.com/docs/fulfillment&#34;&gt;fulfillment&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Fulfillment allows you to use the entity information extracted by the agent to generate dynamic responses or trigger actions on your backend on an intent-by-intent basis.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For more details on Dialogflow concepts, see the &lt;a href=&#34;https://dialogflow.com/docs/&#34;&gt;Dialogflow documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Intents are essential to a Dialogflow system, because they link the user request to the right business logic to fulfill it. For example, a Dialogflow system for a telecom services provider might have intents like &lt;code&gt;bill_value_inquiry&lt;/code&gt;, &lt;code&gt;pay_bill&lt;/code&gt;, &lt;code&gt;upgrade_contract&lt;/code&gt;, &lt;code&gt;cancel_contract&lt;/code&gt;, and &lt;code&gt;add_service&lt;/code&gt;. However, in order to match the user utterance (text or speech) to the right intent, intents need to be trained with a set of relevant training phrases. For example, for a weather inquiry intent, training phrases might be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;What is the weather like right now?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;What is the temperature in Cairo tomorrow?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Do I need to take an umbrella with me to Zurich next week?&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When you create several intents in your system, some phrases you supply to an intent might be confusing or misleading—for example, a phrase that&amp;rsquo;s more relevant to another intent might be used to train the wrong intent. For example, suppose you have a Dialogflow agent that serves as the source of truth for a sales organization. You might have two intents for fetching contacts: one for the internal account teams and one for the customer. You might call these &lt;code&gt;get_internal_contacts&lt;/code&gt; and &lt;code&gt;get_external_contacts&lt;/code&gt;. A typical training phrase for each intent would be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;get_internal_contacts&lt;/code&gt;: &amp;ldquo;Who is the point of contact for Customer X?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get_external_contacts&lt;/code&gt;: &amp;ldquo;How do I get in contact with Customer X?&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suppose that your users supplied the following request as they were looking for the external contacts: &amp;ldquo;Contacts for Customer X&amp;rdquo;. This request can confuse the Dialogflow agent because the phrase can match both intents. If the wrong intent matches, users will have a poor experience because they must change the formulation of the request, which is annoying and time consuming.&lt;/p&gt;
&lt;p&gt;Therefore, you want to make sure that phrases within the same intent are more similar, while phrases between different intents are less similar. The rest of the tutorial explains how to evaluate the quality of the training phrase supplied for each intent, and how to identify potentially confusing training phrases.&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach&lt;/h2&gt;
&lt;p&gt;The approach used in this tutorial is to compute the similarity between two phrases and, by extension, to compute the similarity matrix for all the training phrases. Once you have that matrix, you can compute the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cohesion&lt;/strong&gt;: The average similarity value between each pair of phrases in the same intent. That value is computed for each intent. The higher the intent cohesion value, the better the intent training phrases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Separation&lt;/strong&gt;: Given two intents, the average distance between each pair of training phrases in the two intents.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Confusing phrases&lt;/strong&gt;: Training phrases that are highly similar to training phrases in other intents.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To compute a similarity value between two phrases, you must convert each phrase to a real-value feature vector, which represents the semantics of the phrase (&lt;a href=&#34;https://developers.google.com/machine-learning/glossary/#embeddings&#34;&gt;embeddings&lt;/a&gt;). To help with this task, the tutorial uses &lt;a href=&#34;https://www.tensorflow.org/hub/&#34;&gt;TensorFlow Hub&lt;/a&gt; (&lt;code&gt;tf.Hub&lt;/code&gt;), a library used for the publication, discovery, and consumption of reusable &lt;a href=&#34;https://tfhub.dev/&#34;&gt;modules&lt;/a&gt; of machine learning models. These modules can be pre-trained models or embeddings that are extracted from text, images, and so on. You can browse the &lt;a href=&#34;https://tfhub.dev/s?module-type=text-embedding&#34;&gt;available text embeddings&lt;/a&gt;. The tutorial uses the &lt;a href=&#34;https://tfhub.dev/google/universal-sentence-encoder/2&#34;&gt;Universal Sentence Encoder&lt;/a&gt; (v2) module, which is used to encode text into 512 dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural-language tasks.&lt;/p&gt;
&lt;p&gt;In this tutorial, you use &lt;a href=&#34;https://wikipedia.org/wiki/Cosine_similarity&#34;&gt;cosine similarity&lt;/a&gt; as a proximity metric between two embedding vectors. Given two real-value vectors (in our example, two embedding vectors extracted from two training phrases), cosine similarity calculates the cosine of the angle between them, using the following formula:&lt;/p&gt;
&lt;p&gt;$$ \cos(A,B) = \frac{\sum_{i=1}^{n}A_iB_i}{\sqrt{\sum_{i=1}^{n}{A_i^2}}\sqrt{\sum_{i=1}^{n}{B_i^2}}} $$&lt;/p&gt;
&lt;p&gt;cos⁡(A,B)=∑i=1nAiBi∑i=1nAi2∑i=1nBi2&lt;/p&gt;
&lt;p&gt;In this formula, &lt;em&gt;n&lt;/em&gt; is the number of elements in the vector. The smaller the angle between the vectors, the bigger the cosine value of this angle, indicating higher similarity. The cosine similarity value between any two vectors is always between 0 and 1.&lt;/p&gt;
&lt;p&gt;Figure 1 shows an overview of the approach:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-eval-intents.svg&#34; alt=&#34;Overview of evaluating intents cohesion and separation&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;: Overview of evaluating intents cohesion and separation&lt;/p&gt;
&lt;p&gt;The figure illustrates the following sequence:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Import the intents and their training phrases.&lt;/li&gt;
&lt;li&gt;Generate embeddings for the training phrases using the &lt;code&gt;tf.Hub&lt;/code&gt; Universal Sentence Encoder pre-trained module.&lt;/li&gt;
&lt;li&gt;Create a visualization of the generated embeddings in a two-dimensional space.&lt;/li&gt;
&lt;li&gt;Compute the embeddings cosine similarity matrix containing the pairwise similarity values between all the training phrases in different intents.&lt;/li&gt;
&lt;li&gt;Calculate the cohesion and separation metrics.&lt;/li&gt;
&lt;li&gt;Identify the confusing phrases.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;objectives&#34;&gt;Objectives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;(Optional) Create a Dialogflow agent.&lt;/li&gt;
&lt;li&gt;Import intents with training phrases.&lt;/li&gt;
&lt;li&gt;Run the Colab notebook for intent quality assessment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;This tutorial uses the following billable components of Google Cloud:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dialogflow&lt;/strong&gt;: Standard Edition is free, while Enterprise Edition offers paid enterprise support. You can choose which edition to use when you create your Dialogflow agent. Your account can include agents from both editions. For more details, refer to the &lt;a href=&#34;https://dialogflow.com/pricing&#34;&gt;Dialogflow Pricing page&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;before-you-begin&#34;&gt;Before you begin&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In the Google Cloud Console, on the project selector page, select or create a Google Cloud project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you don&amp;rsquo;t plan to keep the resources that you create in this procedure, create a project instead of selecting an existing project. After you finish these steps, you can delete the project, removing all resources associated with the project.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://console.cloud.google.com/projectselector2/home/dashboard&#34;&gt;Go to the project selector page&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure that billing is enabled for your Cloud project. &lt;a href=&#34;https://cloud.google.com/billing/docs/how-to/modify-project&#34;&gt;Learn how to confirm that billing is enabled for your project&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enable the Dialogflow API.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://console.cloud.google.com/flows/enableapi?apiid=dialogflow.googleapis.com&#34;&gt;Enable the API&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a service account to call the Dialogflow API.&lt;/p&gt;
&lt;p&gt;Create service account&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;strong&gt;Service account details&lt;/strong&gt; dialog, enter the account name and description as shown in the following screenshot, and then click &lt;strong&gt;Create&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set the role to &lt;strong&gt;Dialogflow API Client&lt;/strong&gt; and click &lt;strong&gt;Continue&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;completing-the-tutorial-in-the-colab-notebook&#34;&gt;Completing the tutorial in the Colab notebook&lt;/h2&gt;
&lt;p&gt;The following sections walk through the steps discussed in the &lt;a href=&#34;https://cloud.google.com/solutions/assessing-the-quality-of-training-phrases-in-dialogflow-intents#approach&#34;&gt;approach&lt;/a&gt; section to calculate the cohesion and separation metrics and to identify confusing phrases.&lt;/p&gt;
&lt;h3 id=&#34;getting-started-with-the-colab-notebook&#34;&gt;Getting started with the Colab notebook&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to the Colab notebook: &lt;a href=&#34;https://colab.research.google.com/drive/1QQblWJX5aZ6TajVXNAogFpVJlzYDbMtX&#34;&gt;https://colab.research.google.com/drive/&amp;hellip;&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make a local copy to your Google Drive.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-copy.png&#34; alt=&#34;Copying the notebook to your Google Drive&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In Cloud Shell, install the Python libraries needed for the rest of the tutorial, before importing the required libraries and modules.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!pip install --quiet --upgrade tensorflow dialogflow scipy tensorflow-hub seaborn
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set your Google Cloud &lt;code&gt;PROJECT_ID&lt;/code&gt; and the &lt;code&gt;SERVICE_ACCOUNT_EMAIL&lt;/code&gt; that you created in the &lt;a href=&#34;https://cloud.google.com/solutions/assessing-the-quality-of-training-phrases-in-dialogflow-intents#before-you-begin&#34;&gt;Before you begin&lt;/a&gt; section.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-id-email.png&#34; alt=&#34;Set your Google Cloud PROJECT_ID and SERVICE_ACCOUNT_EMAIL&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Authenticate your session to create a key for your service account:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auth.authenticate_user()
!gcloud config set project {PROJECT_ID}
!gcloud iam service-accounts keys create sa-key.json \
    --iam-account={SERVICE_ACCOUNT_EMAIL} --project={PROJECT_ID}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After you run these commands, a link is displayed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the link to authenticate your user account.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Copy the authentication code from the web page, and paste it in the &lt;strong&gt;Enter verification code&lt;/strong&gt; field in the notebook:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-verification.png&#34; alt=&#34;Enter verification code field in the notebook&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;setting-up-a-dialogflow-agent&#34;&gt;Setting up a Dialogflow agent&lt;/h3&gt;
&lt;p&gt;If you already have a Dialogflow agent that you want to use in this tutorial, you can skip this step. However, if you don&amp;rsquo;t have an agent, or you want to set up a new one, you can download a zip file with the content of an exported Dialogflow agent, called &lt;code&gt;intents-healthcheck&lt;/code&gt;. You import this agent into your Dialogflow account as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download the zip file of the imported agent:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gsutil cp gs://dialogflow-intent-health-check/intent-quality-demo.zip .
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;a href=&#34;https://dialogflow.com/&#34;&gt;https://dialogflow.com/&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click the &lt;a href=&#34;https://console.dialogflow.com/api-client/#/login&#34;&gt;Go to Console&lt;/a&gt; button on the top right.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the left menu, click &lt;strong&gt;Create new agent&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-console.png&#34; alt=&#34;Create new agent&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enter the &lt;strong&gt;agent name&lt;/strong&gt;: &lt;code&gt;intents-healthcheck&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select your Google Cloud project from the &lt;strong&gt;Google Project&lt;/strong&gt; list.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Google Cloud project can have only one Dialogflow agent. So if you don&amp;rsquo;t find your Google Cloud project in the list, an agent is already associated with your project.&lt;/li&gt;
&lt;li&gt;If you select &lt;strong&gt;Create a new project&lt;/strong&gt;, Dialogflow creates a Google Cloud project with the same name as your agent.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &lt;strong&gt;Create&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-agent-info.png&#34; alt=&#34;Entering information about the agent&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the left-hand menu, select the new agent and then click the &lt;strong&gt;Settings&lt;/strong&gt; &lt;em&gt;settings&lt;/em&gt; icon. Then in the menu in the middle of the page, select &lt;strong&gt;Export and Import&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-import-export.png&#34; alt=&#34;Export and Import dialog&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &lt;strong&gt;Restore from zip&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Select the &lt;code&gt;agent-backup.zip&lt;/code&gt; file you downloaded in step 1.&lt;/li&gt;
&lt;li&gt;Type &lt;code&gt;RESTORE&lt;/code&gt; in the text box at the bottom of the form to confirm.&lt;/li&gt;
&lt;li&gt;Click &lt;strong&gt;Restore&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-zip-restore.png&#34; alt=&#34;Restore the agent from a zip file&#34;&gt;&lt;/p&gt;
&lt;p&gt;After restoring the agent, Dialogflow creates five intents.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify the imported intents by selecting &lt;strong&gt;Intents&lt;/strong&gt; from the menu on the left. You find the following intents:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-imported-intents.png&#34; alt=&#34;Verifying the imported intents&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You use this restored agent for the rest of the tutorial.&lt;/p&gt;
&lt;h2 id=&#34;walking-through-the-code-in-the-colab-notebook&#34;&gt;Walking through the code in the Colab notebook&lt;/h2&gt;
&lt;p&gt;The sections that follow describe what the code in the notebook does when you run it.&lt;/p&gt;
&lt;h3 id=&#34;fetching-your-intents&#34;&gt;Fetching your intents&lt;/h3&gt;
&lt;p&gt;The following code fetches intents and their training phrases from the Dialogflow agent using the &lt;code&gt;fetch_intents_training_phrases&lt;/code&gt; method. This method returns a dictionary, where the keys are the intents named in your Dialogflow agent, and each value is a list of the training phrases in each entity. In the code, &lt;code&gt;project&lt;/code&gt; references the project to which your agent belongs, and &lt;code&gt;service_account_file&lt;/code&gt; references the file that you created earlier.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def get_intents(service_account_file, project):

    dialogflow_entity_client =  dialogflow.EntityTypesClient.from_service_account_file(service_account_file)
    parent = dialogflow_entity_client.project_agent_path(project)
    entities = list(dialogflow_entity_client.list_entity_types(parent))

    dialogflow_intents_client = dialogflow.IntentsClient.from_service_account_file(service_account_file)
    parent = dialogflow_intents_client.project_agent_path(project)
    intents = list(dialogflow_intents_client.list_intents(
        parent=parent,
        intent_view=dialogflow.enums.IntentView.INTENT_VIEW_FULL))

    entities_name_to_value = {}
    for intent in intents:
        entities_used = {entity.display_name
            for entity in intent.parameters}

        for entity in entities:
            if entity.display_name in entities_used \
                    and entity.display_name not in entities_name_to_value:
                entities_name_to_value[entity.display_name] = np.random.choice(
                    np.random.choice(entity.entities).synonyms, replace=False)

    intent_to_training_phrases = defaultdict(list)
    for intent in intents:
        for training_phrase in intent.training_phrases:
            parts = [entities_name_to_value[part.alias] if part.entity_type else part.text
                for part in training_phrase.parts]
            intent_to_training_phrases[intent.display_name].append(&amp;quot;&amp;quot;.join(parts))
        # Remove intents with no training phrases
        if not intent_to_training_phrases[intent.display_name]:
            del intent_to_training_phrases[intent.display_name]
    return intent_to_training_phrases
 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The following code verifies the retrieved intents:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;intent_training_phrases = fetch_intents_training_phrases(&amp;quot;sa-key.json&amp;quot;, project_id)
for intent in intent_training_phrases:
    print(&amp;quot;{}:{}&amp;quot;.format(intent, len(intent_training_phrases[intent])))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;fetch_intents_training_phrases&lt;/code&gt; method returns the following listing. This code snippet shows the intents in the demo &lt;code&gt;intents-healthcheck&lt;/code&gt; agent, followed by the count of the training phrases available in each intent.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;start_conversation:4
close_conversation:5
get_internal_contacts:17
request_help:7
get_external_contacts:6
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;generating-embeddings-for-the-training-phrases&#34;&gt;Generating embeddings for the training phrases&lt;/h3&gt;
&lt;p&gt;The following code downloads the &lt;code&gt;tf.Hub&lt;/code&gt; Universal Sentence Encoder pre-trained module:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;embed_module = hub.Module(&amp;quot;https://tfhub.dev/google/universal-sentence-encoder/2&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After the first use, the module is cached locally.&lt;/p&gt;
&lt;p&gt;The following code implements a method that accepts a list of sentences and returns a list of embeddings based on the &lt;code&gt;tf.Hub&lt;/code&gt; module:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def make_embeddings_fn():
    placeholder = tf.placeholder(dtype=tf.string)
    embed = embed_module(placeholder)
    session = tf.Session()
    session.run([tf.global_variables_initializer(), tf.tables_initializer()])
    def _embeddings_fn(sentences):
        computed_embeddings = session.run(
            embed, feed_dict={placeholder: sentences})
        return computed_embeddings
    return _embeddings_fn

generate_embeddings = make_embeddings_fn()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This method ensures that the &lt;code&gt;tf.Session&lt;/code&gt; is created and that the embedding module is loaded only once, not every time the method is called.&lt;/p&gt;
&lt;p&gt;The following code generates embeddings for the training phrases in the intents:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    intent: {
        training_phrase&#39;: [embedding_array]
    }
}

training_phrases_with_embeddings = defaultdict(list)
for intent_name, training_phrases_list in intent_training_phrases.items():
    computed_embeddings = generate_embeddings(training_phrases_list)
    training_phrases_with_embeddings[intent_name] = dict(zip(training_phrases_list, computed_embeddings))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This code snippet creates the &lt;code&gt;training_phrases_with_embeddings&lt;/code&gt; nested dictionary.&lt;/p&gt;
&lt;p&gt;The following code verifies the generated embeddings:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;training_phrases_with_embeddings = defaultdict(list)
for intent_name, training_phrases_list in intent_training_phrases.items():
    computed_embeddings = generate_embeddings(training_phrases_list)
    training_phrases_with_embeddings[intent_name] = dict(zip(training_phrases_list, computed_embeddings))
 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The following code snippet shows each training phrase in the &lt;code&gt;start_conversation&lt;/code&gt; intent, along with the first five elements of the embedding vector of each phrase. The Universal Sentence Encoder generates a 512-dimension embedding vector for each training phrase.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Ciao!:[-0.03649221  0.02498418 -0.03456857  0.02827227  0.00471277]
Howdy!:[-0.02732556 -0.00821852 -0.00794602  0.06356855 -0.03726532]
Hello!:[-0.0255452   0.00690543 -0.00611844  0.05633081 -0.0142823 ]
Hi!:[-0.03227544 -0.00985429 -0.01329378  0.06012927 -0.03646606]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;visualizing-embeddings-in-two-dimensional-space&#34;&gt;Visualizing embeddings in two-dimensional space&lt;/h3&gt;
&lt;p&gt;The following code reduces the dimensionality of the embeddings from 512 to 2 by using &lt;a href=&#34;https://en.wikipedia.org/wiki/Principal_component_analysis&#34;&gt;Principal Component Analysis&lt;/a&gt; to compute the principal components:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from sklearn.decomposition import PCA
embedding_vectors = None

for intent in training_phrases_with_embeddings:
    embeddings = list(training_phrases_with_embeddings[intent].values())
    if embedding_vectors is None:
        embedding_vectors = embeddings
    else:
        embedding_vectors = np.concatenate((only_embeddings, embeddings))

pca = PCA(n_components=3)
pca.fit(embedding_vectors)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This code snippet uses the &lt;code&gt;PCA&lt;/code&gt; class in &lt;code&gt;sklearn&lt;/code&gt; to generate a 2D representation of the training phrases embeddings.&lt;/p&gt;
&lt;p&gt;The following code generates a visualization of the phrase embeddings with the reduced dimensionality:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import matplotlib.pyplot as plt

fig = plt.figure(figsize=(15,10))
ax = fig.add_subplot(111)

legend = []

for color, intent in enumerate(training_phrases_with_embeddings):
    phrases = list(training_phrases_with_embeddings[intent].keys())
    embeddings = list(training_phrases_with_embeddings[intent].values())
    points = pca.transform(embeddings)
    xs = points[:,0]
    ys = points[:,1]
    ax.scatter(xs, ys, marker=&#39;o&#39;, s=100, c=&amp;quot;C&amp;quot;+str(color))
    for i, phrase in enumerate(phrases):
        ax.annotate(phrase, (xs[i], ys[i]))
    legend.append(intent)

ax.legend(legend)
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The following figure shows the resulting visualization: &lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-visualize-embeddings.png&#34; alt=&#34;Visualizing the phrase embeddings with the reduced dimensionality&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;computing-pairwise-similarity-between-phrases&#34;&gt;Computing pairwise similarity between phrases&lt;/h3&gt;
&lt;p&gt;The following code computes the pairwise cosine similarity for the training phrases embeddings, using &lt;code&gt;sklearn.metrics.pairwise.cosine_similarity&lt;/code&gt;. The code creates a Dataframe, &lt;code&gt;similarity_df&lt;/code&gt;, with the pairwise similarity values.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from sklearn.metrics.pairwise import cosine_similarity

flatten = []
for intent in training_phrases_with_embeddings:
        for phrase in training_phrases_with_embeddings[intent]:
            flatten.append((intent, phrase, training_phrases_with_embeddings[intent][phrase]))

data = []
for i in range(len(flatten)):
    for j in range(i+1, len(flatten)):
        intent_1 = flatten[i][0]
        phrase_1 = flatten[i][1]
        embedd_1 = flatten[i][2]
        intent_2 = flatten[j][0]
        phrase_2 = flatten[j][1]
        embedd_2 = flatten[j][2]
        similarity = cosine_similarity([embedd_1], [embedd_2])[0][0]
        record = [intent_1, phrase_1, intent_2, phrase_2, similarity]
        data.append(record)

similarity_df = pd.DataFrame(data,
    columns=[&amp;quot;Intent A&amp;quot;, &amp;quot;Phrase A&amp;quot;, &amp;quot;Intent B&amp;quot;, &amp;quot;Phrase B&amp;quot;, &amp;quot;Similarity&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The following code displays sample similarity records:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;different_intent = similarity_df[&#39;Intent A&#39;] != similarity_df[&#39;Intent B&#39;]
display(similarity_df[different_intent].sort_values(&#39;Similarity&#39;,
ascending=False).head(5))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The following code snippet shows the most similar training phrases that don&amp;rsquo;t belong to the same intent:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-similar-phrases.png&#34; alt=&#34;The most similar training phrases that don&amp;rsquo;t belong to the same intent&#34;&gt;&lt;/p&gt;
&lt;p&gt;Phrases in different intents that have high similarity value can be confusing to the Dialogflow agent, and could lead to directing the user input to the wrong intent.&lt;/p&gt;
&lt;h3 id=&#34;measuring-cohesion-and-separation-of-intents&#34;&gt;Measuring cohesion and separation of intents&lt;/h3&gt;
&lt;p&gt;The following code computes a cohesion value for each intent, as described in the &lt;a href=&#34;https://cloud.google.com/solutions/assessing-the-quality-of-training-phrases-in-dialogflow-intents#approach&#34;&gt;Approach section&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;same_intent = similarity_df[&#39;Intent A&#39;] == similarity_df[&#39;Intent B&#39;]
cohesion_df = pd.DataFrame(similarity_df[different_intent].groupby(&#39;Intent A&#39;, as_index=False)[&#39;Similarity&#39;].mean())
cohesion_df.columns = [&#39;Intent&#39;, &#39;Cohesion&#39;]
display(cohesion_df)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The result is a cohesion value for each intent:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-cohesion-values.png&#34; alt=&#34;Computing a cohesion value for each intent&#34;&gt;&lt;/p&gt;
&lt;p&gt;The following code computes the pairwise separation between intents, as described in the &lt;a href=&#34;https://cloud.google.com/solutions/assessing-the-quality-of-training-phrases-in-dialogflow-intents#approach&#34;&gt;Approach section&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;different_intent = similarity_df[&#39;Intent A&#39;] != similarity_df[&#39;Intent B&#39;]
separation_df = pd.DataFrame(similarity_df[different_intent].groupby([&#39;Intent A&#39;, &#39;Intent B&#39;], as_index=False)[&#39;Similarity&#39;].mean())
separation_df[&#39;Separation&#39;] = 1 - separation_df[&#39;Similarity&#39;]
del separation_df[&#39;Similarity&#39;]
display(separation_df.sort_values(&#39;Separation&#39;))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The result is the pairwise separation between intents:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/assessing-quality-of-training-phrases-pairwise-separation.png&#34; alt=&#34;Computing the pairwise separation between intents&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;further-improvements&#34;&gt;Further improvements&lt;/h2&gt;
&lt;p&gt;To improve the quality of the training phrases for your intents, consider the following approaches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Find the phrases in different intents with high similarity, and change or remove them.&lt;/li&gt;
&lt;li&gt;Find the phrases with the most similar phrases that belong to different intents.&lt;/li&gt;
&lt;li&gt;Add more training phrases in intents with low cohesion, and investigate training phrases in intents with low separation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cleaning-up&#34;&gt;Cleaning up&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Caution&lt;/strong&gt;: Deleting a project has the following effects:&lt;strong&gt;Everything in the project is deleted.&lt;/strong&gt; If you used an existing project for this tutorial, when you delete it, you also delete any other work you&amp;rsquo;ve done in the project.&lt;strong&gt;Custom project IDs are lost.&lt;/strong&gt; When you created this project, you might have created a custom project ID that you want to use in the future. To preserve the URLs that use the project ID, such as an &lt;code&gt;appspot.com&lt;/code&gt; URL, delete selected resources inside the project instead of deleting the whole project.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the Cloud Console, go to the&lt;/p&gt;
&lt;p&gt;Manage resources&lt;/p&gt;
&lt;p&gt;page.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://console.cloud.google.com/iam-admin/projects&#34;&gt;Go to Manage resources&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the project list, select the project that you want to delete, and then click &lt;strong&gt;Delete&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the dialog, type the project ID, and then click &lt;strong&gt;Shut down&lt;/strong&gt; to delete the project.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Read the &lt;a href=&#34;https://cloud.google.com/solutions/machine-learning/overview-extracting-and-serving-feature-embeddings-for-machine-learning&#34;&gt;Overview of extracting and serving feature embeddings for machine learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For more details about embeddings and &lt;code&gt;tf.Hub&lt;/code&gt;, see &lt;a href=&#34;https://cloud.google.com/solutions/machine-learning/overview-extracting-and-serving-feature-embeddings-for-machine-learning&#34;&gt;Overview of extracting and serving feature embeddings for machine learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Learn about the &lt;a href=&#34;https://cloud.google.com/solutions/architecture-of-a-serverless-ml-model&#34;&gt;Architecture of a serverless machine learning model&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Learn about &lt;a href=&#34;https://cloud.google.com/solutions/comparing-ml-model-predictions-using-cloud-dataflow-pipelines&#34;&gt;Comparing machine learning models for predictions in Cloud Dataflow pipelines&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Take the 5-course Coursera specialization on Machine Learning with &lt;a href=&#34;https://www.coursera.org/specializations/machine-learning-tensorflow-gcp&#34;&gt;TensorFlow on Google Cloud&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Learn about best practices for ML engineering in &lt;a href=&#34;https://developers.google.com/machine-learning/guides/rules-of-ml/&#34;&gt;Rules of ML&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Try out other Google Cloud features for yourself. Have a look at our &lt;a href=&#34;https://cloud.google.com/docs/tutorials&#34;&gt;tutorials&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/solutions/assessing-the-quality-of-training-phrases-in-dialogflow-intents&#34;&gt;Assessing the quality of training phrases in Dialogflow intents&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Joint intent and slot classification</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/chatbot/joint-intent-and-slot-classification/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/chatbot/joint-intent-and-slot-classification/</guid>
      
        <description>&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/NVIDIA/NeMo/blob/main/tutorials/nlp/Joint_Intent_and_Slot_Classification.ipynb&#34;&gt;Joint_Intent_and_Slot_Classification.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Named Entity Recognition using Spacy and Tensorflow</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/natural-language-processing/named-entity-recognition/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/natural-language-processing/named-entity-recognition/</guid>
      
        <description>&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://aihub.cloud.google.com/p/products%2F2290fc65-0041-4c87-a898-0289f59aa8ba&#34;&gt;Named Entity Recognition using Spacy and Tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Building a Recommendation System in TensorFlow</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/recommendation-system/building-a-recommendation-system-in-tensorflow/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/recommendation-system/building-a-recommendation-system-in-tensorflow/</guid>
      
        <description>&lt;h2 id=&#34;background-theory-for-recommendations&#34;&gt;Background theory for recommendations&lt;/h2&gt;
&lt;p&gt;the background theory for matrix factorization-based collaborative filtering as applied to recommendation systems.&lt;/p&gt;
&lt;h3 id=&#34;collaborative-filtering-for-recommendation-systems&#34;&gt;Collaborative filtering for recommendation systems&lt;/h3&gt;
&lt;p&gt;Collaborative filtering relies only on &lt;strong&gt;observed user behavior&lt;/strong&gt; to make recommendations—no profile data or content access is necessary.&lt;/p&gt;
&lt;p&gt;The basic &lt;strong&gt;assumption&lt;/strong&gt; is that similar user behavior reflects similar fundamental preferences, allowing a recommendation engine to make suggestions accordingly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For example&lt;/strong&gt;, suppose User 1 has viewed items A, B, C, D, E, and F. User 2 has viewed items A, B, D, E and F, but not C. Because both users viewed five of the same six items, it&amp;rsquo;s likely that they share some basic preferences. User 1 liked item C, and it&amp;rsquo;s probable that User 2 would also like item C if the user were aware of its existence.&lt;/p&gt;
&lt;h3 id=&#34;matrix-factorization-for-collaborative-filtering&#34;&gt;Matrix factorization for collaborative filtering&lt;/h3&gt;
&lt;p&gt;The collaborative filtering problem can be solved using matrix factorization.&lt;/p&gt;
&lt;p&gt;Suppose you have a &lt;strong&gt;matrix&lt;/strong&gt; consisting of &lt;strong&gt;user IDs&lt;/strong&gt; and their interactions with your products. &lt;strong&gt;Each row&lt;/strong&gt; corresponds to a unique user, and &lt;strong&gt;each column&lt;/strong&gt; corresponds to an &lt;strong&gt;item&lt;/strong&gt;. Each entry in the matrix captures a user&amp;rsquo;s rating or preference for a single item. The rating could be &lt;strong&gt;explicit&lt;/strong&gt;, directly generated by user feedback, or it could be &lt;strong&gt;implicit&lt;/strong&gt;, based on user purchases or time spent interacting with an article or video.&lt;/p&gt;
&lt;p&gt;Ratings in the &lt;code&gt;MovieLens&lt;/code&gt; dataset range from 1 to 5. Empty rating entries have value 0, meaning that a given user hasn&amp;rsquo;t rated the item.&lt;/p&gt;
&lt;h4 id=&#34;defining-the-matrix-factorization-method&#34;&gt;Defining the matrix factorization method&lt;/h4&gt;
&lt;p&gt;A ratings matrix consists of a matrix $R$, where entries $r_{ij}$ are ratings of user $i$ for item $j$.&lt;/p&gt;
&lt;p&gt;The matrix factorization method &lt;strong&gt;assumes&lt;/strong&gt; that there is a set of &lt;strong&gt;attributes&lt;/strong&gt; common to all items, with &lt;strong&gt;items differing&lt;/strong&gt; in the &lt;strong&gt;degree&lt;/strong&gt; to which they &lt;strong&gt;express these attributes&lt;/strong&gt;. Furthermore, the matrix factorization method &lt;strong&gt;assumes&lt;/strong&gt; that each user has their own expression for each of these attributes, independent of the items.  In this way, a &lt;strong&gt;user&amp;rsquo;s item rating can be approximated by summing&lt;/strong&gt; the user&amp;rsquo;s strength for each attribute weighted by the degree to which the item expresses this attribute. These attributes are sometimes called &lt;strong&gt;hidden or &lt;em&gt;latent&lt;/em&gt; factors&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Intuitively, it&amp;rsquo;s easy to see that these hypothetical latent factors actually exist. In the case of movies, it&amp;rsquo;s clear that many users prefer certain genres, actors, or directors.  Much of the power of the matrix factorization approach to collaborative filtering derives from the fact that it&amp;rsquo;s not necessary to know the number of  hypothetical latent factors that might comprise the entirety of a given user&amp;rsquo;s preferences. It&amp;rsquo;s &lt;strong&gt;simply assumed there are an arbitrary number of hypothetical latent factors&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;transforming-the-matrix-to-represent-latent-factors&#34;&gt;Transforming the matrix to represent latent factors&lt;/h4&gt;
&lt;p&gt;To translate the existence of latent factors into the matrix of ratings, you do this: for a set of users $U$ of size $u$ and items $I$ of size $i$, you &lt;strong&gt;pick an arbitrary number $k$ of latent factors&lt;/strong&gt; and &lt;strong&gt;factorize&lt;/strong&gt; the large matrix $R$ into two much smaller matrices $X$ (the &amp;ldquo;row factor&amp;rdquo;) and $Y$ (the &amp;ldquo;column factor&amp;rdquo;). Matrix $X$ has dimension $u × k$, and $Y$ has dimension $k × i$.&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;In linear algebra this is called a &lt;strong&gt;low-rank approximation&lt;/strong&gt;. Every user is represented by a vector in this $k$-dimensional space, and each row $x_u$ in $X$ corresponds to the strength of the user&amp;rsquo;s preferences for these $k$ factors. Similarly, every item represented by a vector in this $k$-dimensional space has a column $y_i$ in $Y$ corresponding to the item&amp;rsquo;s expression of the same $k$ factors.&lt;/p&gt;
&lt;p&gt;To calculate the predicted rating of user &lt;em&gt;u&lt;/em&gt; for item &lt;em&gt;i&lt;/em&gt;, you take the dot product of the two vectors:
$$
r_{ui} = x_u^T . y_i
$$
You can define a loss function measuring the accuracy of the approximation in the following way, sum the squared difference between the approximate rating $x_u^T⋅y_i$ and the actual rating from the training set $r_{ui}$.:
$$
L=\sum_{u,i}(r_{ui}−x_u^T⋅y_i)^2
$$
It&amp;rsquo;s common practice to add **regularization terms** to this loss function to help prevent **overfitting**. Adding **L2 regularization terms** for both row and column factors gives the following:
$$
L=\sum_{u,i}(r_{ui}−x_u^T⋅y_i)^2 + \lambda\sum_{u}||x_u||^2 + \lambda\sum_{i}||y_i||^2
$$
Here, $λ$ is a **regularization constant**, one of the model’s hyperparameters.&lt;/p&gt;
&lt;h3 id=&#34;the-wals-method-of-matrix-factorization&#34;&gt;The WALS method of matrix factorization&lt;/h3&gt;
&lt;h4 id=&#34;alternating-least-squares-method-交替最小二乘法&#34;&gt;Alternating least squares method (交替最小二乘法)&lt;/h4&gt;
&lt;p&gt;The alternating least squares method of matrix factorization is an &lt;strong&gt;iterative&lt;/strong&gt; method for determining the &lt;strong&gt;optimal factors&lt;/strong&gt; $X$ and $Y$ that best approximate $R$. In each iteration, &lt;strong&gt;one of&lt;/strong&gt; the row or column factors &lt;strong&gt;is held fixed&lt;/strong&gt; and &lt;strong&gt;the other is computed&lt;/strong&gt; by minimizing the loss function with respect to the other factor.&lt;/p&gt;
&lt;p&gt;First, you begin with the row factors:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set the column factors to constant values.&lt;/li&gt;
&lt;li&gt;Take the derivative of the loss function with respect to the row factors.&lt;/li&gt;
&lt;li&gt;Set the equation equal to zero.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\frac {\partial{L}} {\partial{x_u}} = −2 \sum_i (r_{ui} − x_u^T⋅y_i)y_i^T + 2\lambda_{xu}^T
$$&lt;/p&gt;
&lt;p&gt;$$
0 = −(r_u − x_u^TY^T)Y + \lambda x_u^T
$$&lt;/p&gt;
&lt;p&gt;$$
x_u^T(Y^TY + \lambda I) = r_uY
$$&lt;/p&gt;
&lt;p&gt;$$
x_u^T = r_uY(Y^TY + \lambda I)^{−1}
$$&lt;/p&gt;
&lt;p&gt;Alternating row and column factors, the iterative process is repeated until convergence.&lt;/p&gt;
&lt;h4 id=&#34;weighted-alternating-least-squares-wals-method-加权交替最小二乘法&#34;&gt;Weighted alternating least squares (WALS) method (加权交替最小二乘法)&lt;/h4&gt;
&lt;p&gt;$$
L^w = {W} \sum_{u,i}(r_{ui}−x_u^T⋅y_i)^2
$$&lt;/p&gt;
&lt;p&gt;In this equation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$$w_{ui} = \omega_{0}$$                                  for zero (unobserved) entries in the ratings matrix&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$$w_{ui} = \omega_{0} + f(c_{i})$$                   for observed entries&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$$c_{i} = \sum_{u,i}1 \text{  if  } r_{ui} &amp;gt; 0$$            the sum of the number of nonzero entries for column $i$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The weight is scaled by the sum of the nonzero entries in a row to normalize the weight for users who have rated a different number of items. This type of weighting allows for a more flexible model of the user&amp;rsquo;s preferences and produces better empirical results than the unweighted version.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The function $f$ varies&lt;/strong&gt; according to the dataset and whether ratings are explicit or implicit.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;MovieLens&lt;/code&gt; dataset contains &lt;strong&gt;explicit ratings&lt;/strong&gt;. In this case, a better choice for $f$ is one that weighs the observed entries linearly:&lt;/p&gt;
&lt;p&gt;$$f = \omega_{k}c_{i}$$   where $\omega_{k}$ is the observed weight.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For &lt;strong&gt;implicit ratings&lt;/strong&gt; related to dynamic events, where each rating corresponds to the number of times a video has been watched, an article read, or a web page viewed, the rating itself may have an exponential distribution due to user behavior. There will be many low-value ratings as users click on a page or video and navigate away quickly. There will be fewer large implicit ratings as users read an entire article, watch an entire video, or watch a given scheduled show multiple times. In this case, an appropriate $f$ is one that weights the observed ratings to account &lt;strong&gt;for this distribution&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$f = \left(\frac{1}{c_{i}}\right)^{e}$   where $e$ is the feature weight exponent.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;wals-compared-to-other-techniques&#34;&gt;WALS compared to other techniques&lt;/h3&gt;
&lt;p&gt;Many matrix factorization techniques are used for collaborative filtering, including &lt;strong&gt;SVD&lt;/strong&gt; and &lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt;. In some cases these techniques give better reduced-rank approximations than WALS. It&amp;rsquo;s worth noting the following advantages of WALS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The weights used in WALS make it suitable for &lt;strong&gt;implicit ratings&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;WALS includes &lt;strong&gt;algorithmic optimizations&lt;/strong&gt; that make it easy to incorporate weights and efficiently calculate row and column factor updates.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It&amp;rsquo;s relatively straightforward to create a &lt;strong&gt;distributed version&lt;/strong&gt; of the algorithm.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;create-the-model&#34;&gt;Create the Model&lt;/h2&gt;
&lt;h3 id=&#34;create-docker-image-environment&#34;&gt;Create Docker image environment&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;docker pull tensorflow/tensorflow:1.15.4-py3-jupyter
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;git clone https://github.com/GoogleCloudPlatform/tensorflow-recommendation-wals
cd tensorflow-recommendation-wals
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;vim Dockerfile
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;# Use an official tensorflow runtime as a parent image
FROM tensorflow/tensorflow:1.15.4-py3-jupyter

# Set the working directory to /app
WORKDIR /app

# Copy the requirement list into the container at /app
ADD requirements.txt /app

# Change mirrors and install vim
RUN sed -i &amp;quot;s@http://archive.ubuntu.com@http://mirrors.tuna.tsinghua.edu.cn@g&amp;quot; /etc/apt/sources.list &amp;amp;&amp;amp; sed -i &amp;quot;s@http://security.ubuntu.com@http://mirrors.tuna.tsinghua.edu.cn@g&amp;quot; /etc/apt/sources.list &amp;amp;&amp;amp; rm -Rf /var/lib/apt/lists/* &amp;amp;&amp;amp; apt-get update &amp;amp;&amp;amp; apt-get install -y vim

# Upgrading pip
RUN pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U

# set package index url
RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

# Install any needed packages specified in requirements.txt
RUN pip install -r requirements.txt

# Make port 8888 available to the world outside this container
EXPOSE 8888
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;docker build -t tfrec:latest --no-cache --network=host .
docker image ls
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;download-the-movielens-dataset&#34;&gt;Download the &lt;code&gt;MovieLens&lt;/code&gt; dataset&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;curl -O &#39;http://files.grouplens.org/datasets/movielens/ml-100k.zip&#39;
umzip ml-100k.zip
mkdir /data/datasets/ml-100k
cp ml-100k/u.data /data/datasets/ml-100k/
rm -r ml-100k ml-100k.zip
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;run-jupyter-notebook&#34;&gt;Run Jupyter notebook&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;docker run -it --rm -v $PWD:/app -v /data/datasets/ml-100k:/datasets -w /app -p 8888:8888 tfrec:latest bash
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;jupyter notebook --ip 0.0.0.0 --no-browser --allow-root ./notebooks/Part1.ipynb
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;train-and-tune-the-model&#34;&gt;Train and tune the model&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;cd wals_ml_engine
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;docker run -it --rm -v $PWD:/app -v /data/datasets/ml-100k:/datasets -w /app tfrec:latest python -m trainer.task --job-dir=/app --train-file=/datasets/u.data --data-type=ratings --delimiter=&#39;\t&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Install miniconda&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ yay -S miniconda3
$ echo &amp;quot;export PATH=/opt/miniconda3/bin/:$PATH&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
$ echo &amp;quot;[ -f /opt/miniconda3/etc/profile.d/conda.sh ] &amp;amp;&amp;amp; source /opt/miniconda3/etc/profile.d/conda.sh&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
$ source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Install the Python packages and TensorFlow.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ conda create -y -n tfrec                     # -y:  Do not ask for confirmation, -n: Name of environment.
$ conda install -y -n tfrec --file conda.txt   # --file FILE: Read package versions from the given file
$ source activate tfrec
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;$ conda deactivate
$ conda remove -n tfrec --all
$ conda create -y -n tfrec python=3.7          # with a specific version of Python
$ pip install -r requirements.txt
$ pip install tensorflow==1.15
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;api-and-predict&#34;&gt;API and Predict&lt;/h2&gt;
&lt;p&gt;ensure that the application bind to &lt;code&gt;0.0.0.0&lt;/code&gt; and not &lt;code&gt;127.0.0.1&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -it --rm -v $PWD:/app -v /data/datasets/ml-100k:/datasets -w /app tfrec:latest python -m trainer.task --job-dir=/app --train-file=/datasets/u.data --data-type=ratings --delimiter=&#39;\t&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;deploy-the-recommendation-system&#34;&gt;Deploy the Recommendation System&lt;/h2&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/solutions/machine-learning/recommendation-system-tensorflow-overview&#34;&gt;Building a Recommendation System in TensorFlow&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://developers.google.com/machine-learning/recommendation&#34;&gt;&lt;strong&gt;Recommendation Systems&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://aihub.cloud.google.com/p/products%2F88c7d41c-bc75-4e36-a966-50a0aa38fa2a&#34;&gt;Recommender System with Matrix Factorization&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.gcp.expert/recommendation-system-tensorflow-overview/&#34;&gt;如何在 TensorFlow 內建立推薦系統：總覽&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/19711823&#34;&gt;有哪些好用的开源推荐系统？&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/tensorflow/models/tree/08bb9eb5ad79e6bceffc71aeea6af809cc78694b/official/recommendation&#34;&gt;Recommendation Model&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/57902387/matrix-factorization-in-tensorflow-2-0-using-wals-method&#34;&gt;Matrix Factorization in tensorflow 2.0 using WALS Method&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;reviewing &lt;a href=&#34;https://github.com/tensorflow/models/tree/08bb9eb5ad79e6bceffc71aeea6af809cc78694b/official/recommendation&#34;&gt;https://github.com/tensorflow/models/tree/08bb9eb5ad79e6bceffc71aeea6af809cc78694b/official/recommendation&lt;/a&gt; for how to get started&lt;/p&gt;
&lt;p&gt;I was able to dig around and find a very similar approach in the tutorials
&lt;a href=&#34;https://developers.google.com/machine-learning/recommendation/dnn/softmax&#34;&gt;https://developers.google.com/machine-learning/recommendation/dnn/softmax&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(props to whoever put those tutorials together was helpful getting another look at the approach and tradeoffs)&lt;/p&gt;
&lt;p&gt;note for anyone else looking for example apps I bumped into a couple by Nvidia
&lt;a href=&#34;https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Recommendation/NCF&#34;&gt;https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Recommendation/NCF&lt;/a&gt;
&lt;a href=&#34;https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Recommendation/NCF&#34;&gt;https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Recommendation/NCF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;cool overview for intel&amp;rsquo;s analytics zoo (office depot) across models MF, ncf, wide &amp;amp; deep, and session recommender
&lt;a href=&#34;https://software.intel.com/en-us/articles/real-time-product-recommendations-for-office-depot-using-apache-spark-and-analytics-zoo-on&#34;&gt;https://software.intel.com/en-us/articles/real-time-product-recommendations-for-office-depot-using-apache-spark-and-analytics-zoo-on&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;it looks like Google&amp;rsquo;s official example leverages apache spark&amp;rsquo;s als model
&lt;a href=&#34;https://cloud.google.com/solutions/recommendations-using-machine-learning-on-compute-engine&#34;&gt;https://cloud.google.com/solutions/recommendations-using-machine-learning-on-compute-engine&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>data lakes</title>
      <link>http://www.yezheng.pro/post/specialization/big-data/data-lakes/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/big-data/data-lakes/</guid>
      
        <description>&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://delta.io/&#34;&gt;Delta Lake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html&#34;&gt;What is a Lakehouse?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>edX Analytics Pipeline</title>
      <link>http://www.yezheng.pro/post/specialization/big-data/edx-analytics-pipeline/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/big-data/edx-analytics-pipeline/</guid>
      
        <description>&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://edx.readthedocs.io/projects/edx-installing-configuring-and-running/en/latest/insights/install_insights.html&#34;&gt;edX Insights&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://edx-analytics-pipeline-reference.readthedocs.io/en/latest/index.html&#34;&gt;edX Analytics Pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/edx/edx-analytics-pipeline&#34;&gt;edx-analytics-pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spotify/luigi&#34;&gt;luigi&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Machine Learning Models for Predictions in Cloud Dataflow Pipelines</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/ml-model-predictions-in-dataflow-pipelines/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/ml-model-predictions-in-dataflow-pipelines/</guid>
      
        <description>&lt;p&gt;This solution describes and compares the different design approaches for calling a machine learning model during a Dataflow pipeline, and examines the tradeoffs involved in choosing one approach or another. We present the results of a series of experiments that we ran to explore different approaches and illustrate these tradeoffs, both in batch and stream processing pipelines. This solution is designed for people who integrate trained models into data processing pipelines, rather than for data scientists who want to build machine learning models.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;As the person responsible for integrating this ML model into the Dataflow pipeline, you might wonder what the various approaches are, and which one suits best system requirements. Several considerations need your attention, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Throughput&lt;/li&gt;
&lt;li&gt;Latency&lt;/li&gt;
&lt;li&gt;Cost&lt;/li&gt;
&lt;li&gt;Implementation&lt;/li&gt;
&lt;li&gt;Maintenance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s not always easy to balance these considerations, but this solution can help you navigate the decision-making process based on your priorities. The solution compares three approaches for making predictions with a TensorFlow-trained machine learning (ML) model in batch and stream data pipelines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using a deployed model as a REST/HTTP API for streaming pipelines.&lt;/li&gt;
&lt;li&gt;Using AI Platform (AI Platform) batch prediction jobs for batch pipelines.&lt;/li&gt;
&lt;li&gt;Using Dataflow direct-model prediction for both batch and streaming pipelines.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All the experiments use an existing trained model, called the Natality dataset, which predicts baby weights based on various inputs. Because the goal of this solution is not to build a model, it doesn&amp;rsquo;t discuss how the model was built or trained. See the &lt;a href=&#34;https://cloud.google.com/solutions/comparing-ml-model-predictions-using-cloud-dataflow-pipelines#heading=h.eskc9ld7ie95&#34;&gt;Next Steps&lt;/a&gt; section for more details about the Natality dataset.&lt;/p&gt;
&lt;h2 id=&#34;platform&#34;&gt;Platform&lt;/h2&gt;
&lt;p&gt;There are various ways to run a data pipeline and call a trained ML model. But the functional requirements are always the same:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Ingesting&lt;/em&gt; data from a bounded (batch) or unbounded (streaming) source. Examples of sources from which to ingest data include sensor data, website interactions, and financial transactions.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Transforming and enriching&lt;/em&gt; the input data by calling ML models for predictions. An example is parsing a JSON file to extract relevant fields to predict a maintenance date, make a product recommendation, or detect fraud.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Storing&lt;/em&gt; the transformed data and predictions for analytics or for backup, or to pass to a queuing system to trigger a new event or additional pipelines. Examples include detecting potential fraud in real time or storing maintenance schedule information in a store that&amp;rsquo;s accessible from a dashboard.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When you transform and enrich data with predictions in a batch ETL process, you aim for maximizing throughputs in order to reduce the overall amount of time needed for the whole data batch. On the other hand, when you process streaming data for online prediction, you aim for minimizing latency in order to receive each prediction in (near) real time. Thus, calling the model might become a bottleneck.&lt;/p&gt;
&lt;h3 id=&#34;core-components&#34;&gt;Core components&lt;/h3&gt;
&lt;p&gt;The batch and streaming experiments in this solution use three main technologies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://beam.apache.org/&#34;&gt;Apache Beam&lt;/a&gt; running on Dataflow to process the data.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;TensorFlow&lt;/a&gt; to implement and train the ML model.&lt;/li&gt;
&lt;li&gt;For some experiments, &lt;a href=&#34;https://cloud.google.com/ml-engine&#34;&gt;AI Platform&lt;/a&gt; as a hosting platform for the trained ML models to perform batch and online predictions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We chose &lt;strong&gt;Apache Beam running on Dataflow&lt;/strong&gt; to run data pipelines in this solution because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apache Beam is an open-source unified programming model that runs both streaming and batch data processing jobs.&lt;/li&gt;
&lt;li&gt;Dataflow is a Google Cloud product that can run Apache Beam jobs without a server.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;TensorFlow&lt;/strong&gt; is an open-source mathematical library by Google that is used as a machine learning framework. TensorFlow enables building, training, and serving models on a single machine or in distributed environments. Models are portable to various devices and can also leverage available &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_processing_unit&#34;&gt;CPU&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Graphics_processing_unit&#34;&gt;GPU&lt;/a&gt;, or &lt;a href=&#34;https://en.wikipedia.org/wiki/Tensor_processing_unit&#34;&gt;TPU&lt;/a&gt; resources for training and serving.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI Platform&lt;/strong&gt; is a serverless platform that can train, tune (using the hyper-parameters tuning functionality), and serve TensorFlow models at scale with minimum management required by DevOps. AI Platform supports deploying trained models as REST APIs for online predictions, as well as submitting batch prediction jobs. AI Platform is one of several options that can serve your model as a microservice.&lt;/p&gt;
&lt;p&gt;The approaches detailed in this solution use Dataflow for the data processing pipeline and AI Platform to host the models as HTTP endpoints. However, these approaches could be replaced with other technologies. The performance comparisons between HTTP and a direct TensorFlow model would not drastically change.&lt;/p&gt;
&lt;h3 id=&#34;processing-batch-and-streaming-data&#34;&gt;Processing batch and streaming data&lt;/h3&gt;
&lt;p&gt;The experiments in this solution include both batch and streaming use cases. Each experiment leverages different Google Cloud products for input and output because unbounded and bounded sources have different operational requirements.&lt;/p&gt;
&lt;h4 id=&#34;batch-processing-a-bounded-dataset&#34;&gt;Batch-processing a bounded dataset&lt;/h4&gt;
&lt;p&gt;Figure 1 shows that in typical batch processing pipelines, raw input data is stored in object storage, such as &lt;a href=&#34;https://cloud.google.com/storage&#34;&gt;Cloud Storage&lt;/a&gt;. Structured data storage formats include comma-separated values (CSV), optimized row columnar (ORC), Parquet, or Avro. These formats are often used when data comes from databases or logs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-1-batch-processing.svg&#34; alt=&#34;Architecture of typical batch processing pipelines&#34;&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Batch-processing architecture&lt;/p&gt;
&lt;p&gt;Some analytical platforms such as &lt;a href=&#34;https://cloud.google.com/bigquery&#34;&gt;BigQuery&lt;/a&gt; provide storage in addition to query capabilities. BigQuery uses &lt;a href=&#34;https://cloud.google.com/blog/big-data/2016/04/inside-capacitor-bigquerys-next-generation-columnar-storage-format&#34;&gt;Capacitor&lt;/a&gt; for storage. Apache Beam on Dataflow can read from and write to both BigQuery and Cloud Storage, in addition to other storage options in batch processing pipelines.&lt;/p&gt;
&lt;h4 id=&#34;stream-processing-an-unbounded-datastream&#34;&gt;Stream-processing an unbounded datastream&lt;/h4&gt;
&lt;p&gt;For streaming, the inputs to a data processing pipeline are usually a messaging system, as shown in Figure 2. Technologies such as &lt;a href=&#34;https://cloud.google.com/pubsub&#34;&gt;Pub/Sub&lt;/a&gt; or Kafka are typically used to ingest individual data points in JSON, CSV, or protobuf format.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-2-stream-processing.svg&#34; alt=&#34;Architecture of typical stream processing pipelines&#34;&gt;&lt;strong&gt;Figure 2.&lt;/strong&gt; Stream-processing architecture&lt;/p&gt;
&lt;p&gt;Data points can be processed individually, or as groups in micro-batches by using &lt;a href=&#34;https://beam.apache.org/documentation/programming-guide/#windowing&#34;&gt;windowing&lt;/a&gt; functions to perform temporal event processing. The processed data might go to several destinations, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;BigQuery for ad hoc analytics, through the streaming APIs.&lt;/li&gt;
&lt;li&gt;Cloud Bigtable for serving real-time information.&lt;/li&gt;
&lt;li&gt;Pub/Sub topic for triggering subsequent processes/pipelines.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can find a complete list of source connectors (input) and sink connectors (output) for both bounded and unbounded data source sinks on the &lt;a href=&#34;https://beam.apache.org/documentation/io/built-in/&#34;&gt;Apache Beam I/O page&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;invoking-a-tensorflow-model&#34;&gt;Invoking a TensorFlow model&lt;/h3&gt;
&lt;p&gt;A TensorFlow-trained model can be invoked in three ways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Through an HTTP endpoint for &lt;strong&gt;online&lt;/strong&gt; prediction.&lt;/li&gt;
&lt;li&gt;Directly, by using the saved model file for &lt;strong&gt;batch&lt;/strong&gt; and &lt;strong&gt;online&lt;/strong&gt; predictions.&lt;/li&gt;
&lt;li&gt;Through an AI Platform batch prediction job for &lt;strong&gt;batch&lt;/strong&gt; prediction.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;http-endpoints-for-online-prediction&#34;&gt;HTTP endpoints for online prediction&lt;/h4&gt;
&lt;p&gt;TensorFlow models are deployed as HTTP endpoints to be invoked and give predictions in real time, either through a stream data processing pipeline or through client apps.&lt;/p&gt;
&lt;p&gt;You can deploy a TensorFlow model as an HTTP endpoint for online predictions by using &lt;a href=&#34;https://github.com/tensorflow/serving&#34;&gt;TensorFlow Serving&lt;/a&gt; or any other hosting service, such as &lt;a href=&#34;https://www.seldon.io/&#34;&gt;Seldon&lt;/a&gt;. As shown in Figure 3, you can choose one of the following options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Deploy the model yourself on one or more Compute Engine instances.&lt;/li&gt;
&lt;li&gt;Use a &lt;a href=&#34;https://github.com/tensorflow/serving/tree/master/tensorflow_serving/tools/docker&#34;&gt;Docker image&lt;/a&gt; on &lt;a href=&#34;https://cloud.google.com/compute/docs/containers/deploying-containers&#34;&gt;Compute Engine&lt;/a&gt; or &lt;a href=&#34;https://cloud.google.com/kubernetes-engine&#34;&gt;Google Kubernetes Engine&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Leverage &lt;a href=&#34;https://github.com/kubeflow/kubeflow&#34;&gt;Kubeflow&lt;/a&gt; to facilitate deployment on &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; or Google Kubernetes Engine.&lt;/li&gt;
&lt;li&gt;Use App Engine with Endpoints to host the model in a web app.&lt;/li&gt;
&lt;li&gt;Use &lt;a href=&#34;https://cloud.google.com/ml-engine&#34;&gt;AI Platform&lt;/a&gt;, the fully managed ML training and serving service on Google Cloud.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-3-different-models-for-http-endpoints.svg&#34; alt=&#34;Options in Dataflow for serving a model as an HTTP endpoint&#34;&gt;&lt;strong&gt;Figure 3.&lt;/strong&gt; Different options in Dataflow for serving a model as an HTTP endpoint&lt;/p&gt;
&lt;p&gt;AI Platform is a fully managed service, so it is easier to implement than the other options. Therefore, in our experiments we use it as the option for serving the model as an HTTP endpoint. We can then focus on the performance of a direct-model versus an HTTP endpoint in AI Platform, rather than comparing the different HTTP model-serving options.&lt;/p&gt;
&lt;h4 id=&#34;serving-online-predictions-with-ai-platform-prediction&#34;&gt;Serving online predictions with AI Platform Prediction&lt;/h4&gt;
&lt;p&gt;Two tasks are required in order to serve online predictions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Deploying a model.&lt;/li&gt;
&lt;li&gt;Interacting with the deployed model for inference (that is, making predictions).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models&#34;&gt;Deploying a model&lt;/a&gt; as an HTTP endpoint using AI Platform Prediction requires the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Make sure that the trained model files are available on Cloud Storage.&lt;/li&gt;
&lt;li&gt;Create a model by using the &lt;code&gt;gcloud ml-engine models create&lt;/code&gt; command.&lt;/li&gt;
&lt;li&gt;Deploy a model version by using the &lt;code&gt;gcloud ml-engine versions create&lt;/code&gt; command, with the model files on Cloud Storage.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can deploy a model by using commands like the following:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/scripts/deploy-cmle.sh&#34;&gt;blogs/tf_dataflow_serving/scripts/deploy-cmle.sh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/scripts/deploy-cmle.sh&#34;&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;PROJECT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[PROJECT_ID]&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# change to your project name&lt;/span&gt;
REGION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[REGION]&amp;#34;&lt;/span&gt;
BUCKET&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[BUCKET]&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# change to your bucket name&lt;/span&gt;
MODEL_NAME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;babyweight_estimator&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# change to your estimator name&lt;/span&gt;
MODEL_VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# change to your model version&lt;/span&gt;
MODEL_BINARIES&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;gs://&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;BUCKET&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/models/&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;MODEL_NAME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# upload the local SavedModel to GCS&lt;/span&gt;
gsutil -m cp -r model/trained/v1/* gs://&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;BUCKET&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/models/&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;MODEL_NAME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# set the current project&lt;/span&gt;
gcloud config set project &lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;PROJECT&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# list model files on GCS&lt;/span&gt;
gsutil ls &lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;MODEL_BINARIES&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# deploy model to GCP&lt;/span&gt;
gcloud ml-engine models create &lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;MODEL_NAME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt; --regions&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;REGION&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# deploy model version&lt;/span&gt;
gcloud ml-engine versions create &lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;MODEL_VERSION&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt; --model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;MODEL_NAME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt; --origin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;MODEL_BINARIES&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt; --runtime-version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1.4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The code creates an AI Platform Prediction model called babyweight_estimator in the Google Cloud project, with model version v1.&lt;/p&gt;
&lt;p&gt;After the model is deployed, you can invoke it. The following Python code shows a way to invoke a model version in AI Platform Prediction as a REST API:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/model/inference.py&#34;&gt;blogs/tf_dataflow_serving/model/inference.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/model/inference.py&#34;&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;cmle_api &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;init_api&lt;/span&gt;():

    &lt;span style=&#34;color:#66d9ef&#34;&gt;global&lt;/span&gt; cmle_api

    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; cmle_api &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; None:
        cmle_api &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; discovery&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;build(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ml&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;v1&amp;#39;&lt;/span&gt;,
                              discoveryServiceUrl&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json&amp;#39;&lt;/span&gt;,
                              cache_discovery&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;estimate_cmle&lt;/span&gt;(instances):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Calls the babyweight estimator API on CMLE to get predictions
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Args:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       instances: list of json objects
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        int - estimated baby weight
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    init_api()

    request_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;instances&amp;#39;&lt;/span&gt;: instances}

    model_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;projects/{}/models/{}/versions/{}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(PROJECT, CMLE_MODEL_NAME, CMLE_MODEL_VERSION)
    response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cmle_api&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;projects()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(body&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;request_data, name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model_url)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;execute()
    values &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;predictions&amp;#34;&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; response[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;predictions&amp;#39;&lt;/span&gt;]]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; values
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you have a large dataset available in something like BigQuery or Cloud Storage and you want to maximize the throughput of the overall process, serving your ML model as an HTTP endpoint is not recommended for batch prediction. Doing this generates one HTTP request for each data point, which results in a huge volume of HTTP requests. The following section presents better options for batch prediction.&lt;/p&gt;
&lt;h4 id=&#34;direct-model-for-batch-and-online-predictions&#34;&gt;Direct-model for batch and online predictions&lt;/h4&gt;
&lt;p&gt;The direct-model prediction technique leverages a local TensorFlow &lt;code&gt;SavedModel&lt;/code&gt; on the Dataflow instances. The saved model is a copy of the output files created after you have finished building and training the TensorFlow model. The TensorFlow &lt;code&gt;SavedModel&lt;/code&gt; can be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Part of the pipeline source code that is submitted as a Dataflow job.&lt;/li&gt;
&lt;li&gt;Downloaded from Cloud Storage, as shown in Figure 4.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-4-direct-model-prediction.png&#34; alt=&#34;Direct-model prediction in Dataflow&#34;&gt;&lt;strong&gt;Figure 4.&lt;/strong&gt; Direct-model prediction in Dataflow&lt;/p&gt;
&lt;p&gt;In this solution, we use a &lt;code&gt;SavedModel&lt;/code&gt; that is part of the &lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/blogs/tf_dataflow_serving/model&#34;&gt;source code&lt;/a&gt; on GitHub. To load a model on the instances, you do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When you create the Dataflow job, specify the pipeline dependencies to be loaded, including the model file. The following Python code shows the &lt;code&gt;setup.py&lt;/code&gt; file that includes the model files to be submitted with the Dataflow job.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/setup.py&#34;&gt;blogs/tf_dataflow_serving/setup.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/setup.py&#34;&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; setuptools
   
requirements &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
   
setuptools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;setup(
    name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;TF-DATAFLOW-DEMO&amp;#39;&lt;/span&gt;,
    version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;v1&amp;#39;&lt;/span&gt;,
    install_requires&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;requirements,
    packages&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;setuptools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_packages(),
    package_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;model&amp;#39;&lt;/span&gt;: [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;trained/*&amp;#39;&lt;/span&gt;,
                            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;trained/v1/*&amp;#39;&lt;/span&gt;,
                            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;trained/v1/variables/*&amp;#39;&lt;/span&gt;]
                  },
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Call the local model files during the pipeline. This produces the prediction for the given instances. The following Python code shows how to do this.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/model/inference.py&#34;&gt;blogs/tf_dataflow_serving/model/inference.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/model/inference.py&#34;&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;predictor_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None
   
   
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;init_predictor&lt;/span&gt;():
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34; Loads the TensorFlow saved model to the predictor object
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;   
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        predictor_fn
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
   
    &lt;span style=&#34;color:#66d9ef&#34;&gt;global&lt;/span&gt; predictor_fn
   
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; predictor_fn &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; None:
   
        logging&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;info(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Initialising predictor...&amp;#34;&lt;/span&gt;)
        dir_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dirname(os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;realpath(__file__))
        export_dir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(dir_path, SAVED_MODEL_DIR)
   
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exists(export_dir):
            predictor_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;contrib&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predictor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_saved_model(
                export_dir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;export_dir,
                signature_def_key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;predict&amp;#34;&lt;/span&gt;
            )
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            logging&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;error(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Model not found! - Invalid model path: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(export_dir))
   
   
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;estimate_local&lt;/span&gt;(instances):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Calls the local babyweight estimator to get predictions
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;   
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Args:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       instances: list of json objects
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        int - estimated baby weight
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
   
    init_predictor()
   
    inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict((k, [v]) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; instances[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;items())
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,len(instances)):
        instance &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; instances[i]
   
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; instance&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;items():
            inputs[k] &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; [v]
   
    values &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; predictor_fn(inputs)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;predictions&amp;#39;&lt;/span&gt;]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; [value&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item() &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; value &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;See the &lt;a href=&#34;https://beam.apache.org/documentation/sdks/python-pipeline-dependencies/#multiple-file-dependencies&#34;&gt;Apache Beam Multiple File Dependencies&lt;/a&gt; page for more details.&lt;/p&gt;
&lt;h4 id=&#34;ai-platform-batch-prediction-job&#34;&gt;AI Platform batch prediction job&lt;/h4&gt;
&lt;p&gt;Besides deploying the model as an HTTP endpoint, AI Platform lets you run a &lt;a href=&#34;https://cloud.google.com/ml-engine/docs/tensorflow/batch-predict&#34;&gt;batch prediction job&lt;/a&gt; by using a deployed model version or a TensorFlow &lt;code&gt;SavedModel&lt;/code&gt; in Cloud Storage.&lt;/p&gt;
&lt;p&gt;An AI Platform batch prediction job takes the Cloud Storage location of the input data files as a parameter. It uses the model to get predictions for that data, and then stores the prediction results in another Cloud Storage output location that is also given as a parameter. The following example shows &lt;code&gt;gcloud&lt;/code&gt; commands that submit an AI Platform batch prediction job.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/scripts/predict-batch-cmle.sh&#34;&gt;blogs/tf_dataflow_serving/scripts/predict-batch-cmle.sh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/scripts/predict-batch-cmle.sh&#34;&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;BUCKET&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;BUCKET&amp;gt;&amp;#39;&lt;/span&gt;
DATA_FORMAT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TEXT&amp;#34;&lt;/span&gt;
INPUT_PATHS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;gs://&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;BUCKET&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/data/babyweight/experiments/outputs/data-prep-*
OUTPUT_PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;gs://&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;BUCKET&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/data/babyweight/experiments/outputs/cmle-estimates
MODEL_NAME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;babyweight_estimator&amp;#39;&lt;/span&gt;
VERSION_NAME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;v1&amp;#39;&lt;/span&gt;
REGION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;REGION&amp;gt;&amp;#39;&lt;/span&gt;
now&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;date +&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%Y%m%d_%H%M%S&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;
JOB_NAME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch_predict_&lt;/span&gt;$MODEL_NAME$now&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
MAX_WORKER_COUNT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;20&amp;#34;&lt;/span&gt;

gcloud ml-engine jobs submit prediction $JOB_NAME &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    --model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$MODEL_NAME &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    --input-paths&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$INPUT_PATHS &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    --output-path&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$OUTPUT_PATH &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    --region&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$REGION &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    --data-format&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$DATA_FORMAT &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    --max-worker-count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$MAX_WORKER_COUNT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;point-by-point-versus-micro-batching-for-online-prediction&#34;&gt;Point-by-point versus micro-batching for online prediction&lt;/h4&gt;
&lt;p&gt;In real-time prediction pipelines, whether you are serving the model as an HTTP endpoint or using the model directly from the workers, you have two options to get predictions for incoming data points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Individual point&lt;/strong&gt;. The obvious option is to send each data point to the model individually and get a prediction.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Micro-batches&lt;/strong&gt;. A more optimized option is to use a windowing function to create micro-batches, grouping data points within a specific time period, such as every 5 seconds. The micro-batch is then sent to the model to get predictions for all the instances at at time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following Python code shows how to create time-based micro-batches using a windowing function in an Apache Beam pipeline.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/pipelines/stream_process.py&#34;&gt;blogs/tf_dataflow_serving/pipelines/stream_process.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/pipelines/stream_process.py&#34;&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;run_pipeline_with_micro_batches&lt;/span&gt;(inference_type, project,
                                    pubsub_topic, pubsub_subscription,
                                    bq_dataset, bq_table,
                                    window_size, runner, args&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):

    prepare_steaming_source(project, pubsub_topic, pubsub_subscription)
    prepare_steaming_sink(project, bq_dataset, bq_table)
    pubsub_subscription_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;projects/{}/subscriptions/{}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(project, pubsub_subscription)
    options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; beam&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pipeline&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;PipelineOptions(flags&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[], &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;args)

    pipeline &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; beam&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Pipeline(runner, options&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;options)
    (
            pipeline
            &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Read from PubSub&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; beam&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ReadStringsFromPubSub(subscription&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pubsub_subscription_url, id_label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;source_id&amp;#34;&lt;/span&gt;)
            &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Micro-batch - Window Size: {} Seconds&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(window_size) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; beam&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;WindowInto(FixedWindows(size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;window_size))
            &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Estimate Targets - {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(inference_type) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; beam&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;FlatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; messages: estimate(messages, inference_type))
            &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Write to BigQuery&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; beam&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;WriteToBigQuery(project&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;project,
                                                             dataset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bq_dataset,
                                                             table&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bq_table
                                                             )
    )

    pipeline&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The micro-batching approach uses models deployed as HTTP endpoints, which dramatically reduces the number of HTTP requests and reduces latency. Even when the micro-batching technique used with the direct model, sending the model a tensor with N instances for prediction is more efficient than sending a tensor with a length of 1 because of the vectorized operations.&lt;/p&gt;
&lt;h2 id=&#34;batch-experiments&#34;&gt;Batch experiments&lt;/h2&gt;
&lt;p&gt;In the batch experiments, we want to estimate baby weights in the Natality dataset in BigQuery by using a TensorFlow regression model. We then want to save the prediction results in Cloud Storage as CSV files by using a Dataflow batch pipeline. The following section describes different experiments we tried to accomplish this task.&lt;/p&gt;
&lt;h3 id=&#34;approach-1-dataflow-with-direct-model-prediction&#34;&gt;Approach 1: Dataflow with direct-model prediction&lt;/h3&gt;
&lt;p&gt;In this approach, Dataflow workers host the TensorFlow &lt;code&gt;SavedModel&lt;/code&gt;, which is called directly for prediction during the batch processing pipeline for each record. Figure 5 shows the high-level architecture of this approach.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-5-batch-approach-1-dataflow-with-direct-model.png&#34; alt=&#34;Batch Approach 1: Dataflow with direct model prediction&#34;&gt;&lt;strong&gt;Figure 5.&lt;/strong&gt; Batch Approach 1: Dataflow with direct model prediction&lt;/p&gt;
&lt;p&gt;The Dataflow pipeline performs the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read data from BigQuery.&lt;/li&gt;
&lt;li&gt;Prepare BigQuery record for prediction.&lt;/li&gt;
&lt;li&gt;Call the local TensorFlow &lt;code&gt;SavedModel&lt;/code&gt; to get a prediction for each record.&lt;/li&gt;
&lt;li&gt;Convert the result (input record and estimated baby weight) to a CSV file.&lt;/li&gt;
&lt;li&gt;Write the CSV file to Cloud Storage.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this approach, there are no calls to remote services, such as a deployed model on AI Platform as an HTTP endpoint. The prediction is done locally within each Dataflow worker by using the TensorFlow &lt;code&gt;SavedModel&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;approach-2-dataflow-with-ai-platform-batch-prediction&#34;&gt;Approach 2: Dataflow with AI Platform batch prediction&lt;/h3&gt;
&lt;p&gt;In this approach, the TensorFlow &lt;code&gt;SavedModel&lt;/code&gt; is stored in Cloud Storage and used by AI Platform for prediction. However, instead of making an API call to the deployed model for each record as with the previous approach, the data is prepared for prediction and submitted as a batch.&lt;/p&gt;
&lt;p&gt;This approach has two phases:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Dataflow prepares the data from BigQuery for prediction, and then stores the data in Cloud Storage.&lt;/li&gt;
&lt;li&gt;The AI Platform batch prediction job is submitted with the prepared data, and the prediction results are stored in Cloud Storage.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Figure 6 shows the overall architecture of this two-phased approach.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-6-batch-approach-2-dataflow-with-cloud-ml.png&#34; alt=&#34;Batch Approach 2: Dataflow with AI Platform batch prediction&#34;&gt;&lt;strong&gt;Figure 6.&lt;/strong&gt; Batch Approach 2: Dataflow with AI Platform batch prediction&lt;/p&gt;
&lt;p&gt;The workflow steps, including the Dataflow pipeline, are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read data from BigQuery.&lt;/li&gt;
&lt;li&gt;Prepare BigQuery record for prediction.&lt;/li&gt;
&lt;li&gt;Write JSON data to Cloud Storage. The &lt;code&gt;serving_fn&lt;/code&gt; function in the model expects JSON instances as input.&lt;/li&gt;
&lt;li&gt;Submit an AI Platform batch prediction job with the prepared data in Cloud Storage. This job writes the prediction results to Cloud Storage as well.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Dataflow job prepares the data for prediction rather than submitting the AI Platform prediction job. In other words, the data preparation task and the batch prediction task are not tightly coupled. Cloud Functions, Airflow, or any scheduler can orchestrate the workflow by executing the Dataflow job and then submitting the AI Platform job for batch prediction.&lt;/p&gt;
&lt;p&gt;AI Platform batch prediction is recommended for both performance and ease of use if your data meets the following criteria:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your data is available in Cloud Storage, in the format expected for prediction, from a previous data ingestion process.&lt;/li&gt;
&lt;li&gt;You don&amp;rsquo;t have control of the first phase of the workflow, such as the Dataflow pipeline that prepares the data in Cloud Storage for prediction.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;experiment-configurations&#34;&gt;Experiment configurations&lt;/h3&gt;
&lt;p&gt;We used the following configurations in three experiments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data sizes: &lt;code&gt;10K&lt;/code&gt;, &lt;code&gt;100K&lt;/code&gt;, &lt;code&gt;1M&lt;/code&gt;, and &lt;code&gt;10M&lt;/code&gt; rows&lt;/li&gt;
&lt;li&gt;Cloud Storage class: &lt;code&gt;Regional Storage&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Cloud Storage location: &lt;code&gt;europe-west1-b&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Dataflow region: &lt;code&gt;europe-west1-b&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Dataflow worker machine type: &lt;code&gt;n1-standard-1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Dataflow Autoscaling for batch data up to 1 million records&lt;/li&gt;
&lt;li&gt;Dataflow &lt;code&gt;num_worker&lt;/code&gt;: &lt;code&gt;20&lt;/code&gt; for batch data up to 10 million records&lt;/li&gt;
&lt;li&gt;AI Platform batch prediction &lt;code&gt;max-worker-count&lt;/code&gt; setting: &lt;code&gt;20&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Cloud Storage location and the Dataflow region should be the same. This solution uses the &lt;code&gt;europe-west1-b&lt;/code&gt; region as an arbitrary value.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;The following table summarizes the results (timings) of performing the batch predictions and direct-model predictions with different sizes of datasets.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Batch data size&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Metric&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Dataflow then AI Platform batch prediction&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Dataflow with direct-model prediction&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;10K rows&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Running time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;15 min 30 sec  (Dataflow: 7 min 47 sec + AI Platform: 7 min 43 sec)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;8 min 24 sec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Total vCPU time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.301 hr  (Dataflow: 0.151 hr + AI Platform: 0.15 hr)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.173 hr&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;100K rows&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Running time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;16 min 37 sec  (Dataflow: 8 min 39 sec + AI Platform: 7 min 58 sec)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;10 min 31 sec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Total vCPU time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.334 hr  (Dataflow: 0.184 hr + AI Platform: 0.15 hr)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.243 hr&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;1M rows&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Running time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;21 min 11 sec (Dataflow: 11 min 07 sec + AI Platform: 10 min 04 sec)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;17 min 12 sec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Total vCPU time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.446 hr  (Dataflow: 0.256 hr + AI Platform: 0.19 hr)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1.115 hr&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;10M rows&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Running time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;33 min 08 sec (Dataflow: 12 min 15 sec + AI Platform: 20 min 53 sec)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;25 min 02 sec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Total vCPU time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;5.251 hr  (Dataflow: 3.581 hr + AI Platform: 1.67 hr)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7.878 hr&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Figure 7 shows a graph of these results.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-7-barchart-batch-results.svg&#34; alt=&#34;Graph showing timings for 3 approaches for 4 different dataset sizes&#34;&gt;&lt;strong&gt;Figure 7.&lt;/strong&gt; Graph showing timings for 3 approaches for 4 different dataset sizes&lt;/p&gt;
&lt;p&gt;As the results show, the AI Platform batch prediction job on its own takes less time to produce predictions for the input data, given that the data is already in Cloud Storage in the format used for prediction. However, when the batch prediction job is combined with a preprocessing step (extracting and preparing the data from BigQuery to Cloud Storage for prediction) and with a post-processing step (storing the data back to BigQuery), the direct-model approach produces better end-to-end execution time. In addition, the performance of the direct-model prediction approach can be further optimized using micro-batching (which we discuss later for the streaming experiments).&lt;/p&gt;
&lt;h2 id=&#34;stream-experiments&#34;&gt;Stream experiments&lt;/h2&gt;
&lt;p&gt;In the streaming experiments, the Dataflow pipeline reads data points from a Pub/Sub topic and writes the data to BigQuery by using the streaming APIs. The Dataflow streaming pipeline processes the data and gets predictions using the TensorFlow baby-weight estimation model.&lt;/p&gt;
&lt;p&gt;The topic receives data from a stream simulator that generates data points, which are the instances to estimate the baby weight for, at a predefined rate of events per second. This simulates a real-world example of an unbounded data source. The following Python code simulates the data stream sent to a Pub/Sub topic.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/simulate_stream.py&#34;&gt;blogs/tf_dataflow_serving/simulate_stream.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/tf_dataflow_serving/simulate_stream.py&#34;&gt;View on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;client &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pubsub&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Client(project&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;PARAMS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;project_id)
topic &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; client&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;topic(PARAMS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pubsub_topic)
&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; topic&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exists():
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Topic does not exist. Please run a stream pipeline first to create the topic.&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Simulation aborted.&amp;#39;&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(PARAMS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stream_sample_size):

    message &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; send_message(topic, index)

    &lt;span style=&#34;color:#75715e&#34;&gt;# for debugging&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; PARAMS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show_message:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Message {} was sent: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(index&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, message)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;

    time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sleep(sleep_time_per_msg)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;approach-1-dataflow-with-ai-platform-online-prediction&#34;&gt;Approach 1: Dataflow with AI Platform online prediction&lt;/h3&gt;
&lt;p&gt;In this approach, the TensorFlow model is deployed and hosted in AI Platform as a REST API. The Dataflow streaming pipeline calls the API for each message consumed from Pub/Sub get predictions. The high-level architecture of this approach is shown in Figure 8.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-8-stream-approach-1-dataflow-with-cloud-ml-online.png&#34; alt=&#34;Stream Approach 1: Dataflow with AI Platform online prediction&#34;&gt;&lt;strong&gt;Figure 8.&lt;/strong&gt; Stream Approach 1: Dataflow with AI Platform online prediction. The HTTP request might include a single data point or a group of data points in a micro-batch.&lt;/p&gt;
&lt;p&gt;In this approach, the Dataflow pipeline performs the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read messages from a Pub/Sub topic.&lt;/li&gt;
&lt;li&gt;Send an HTTP request to the AI Platform model&amp;rsquo;s API to get predictions for each message.&lt;/li&gt;
&lt;li&gt;Write results to BigQuery by using streaming APIs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Micro-batching is a better approach. That is, instead of sending an HTTP request to the model&amp;rsquo;s REST API for each message that is read from Pub/Sub, Dataflow groups messages received during a 1-second window. It then sends this group of messages as a micro-batch in a single HTTP request to the model&amp;rsquo;s API. In this approach, the Dataflow pipeline performs the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read messages from Pub/Sub topic.&lt;/li&gt;
&lt;li&gt;Apply a 1-second windowing operation to create a micro-batch of messages.&lt;/li&gt;
&lt;li&gt;Send an HTTP request with the micro-batch to the AI Platform model&amp;rsquo;s API to get predictions for the messages.&lt;/li&gt;
&lt;li&gt;Write results to BigQuery by using streaming APIs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The rationale behind this approach is that it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Reduces the number of calls to the remote service, such as the AI Platform model.&lt;/li&gt;
&lt;li&gt;Reduces the average latency of serving each message.&lt;/li&gt;
&lt;li&gt;Reduces the overall processing time of the pipeline.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this experiment, the time window was set to 1 second. However, the micro-batch size, which is the number of messages sent as a batch to AI Platform mode, varies. The micro-batch size depends on the message generation frequency—the number of messages per second.&lt;/p&gt;
&lt;p&gt;The following section describes experiments with three different frequencies: 50, 100, and 500 messages per second. That is, the micro-batch size is 50, 100, and 500.&lt;/p&gt;
&lt;h3 id=&#34;approach-2-dataflow-with-direct-model-prediction&#34;&gt;Approach 2: Dataflow with direct-model prediction&lt;/h3&gt;
&lt;p&gt;This approach is similar to the approach that was used in the batch experiments. The TensorFlow &lt;code&gt;SavedModel&lt;/code&gt; is hosted on Dataflow workers and is called for prediction during the stream processing pipeline for each record. Figure 9 shows the high-level architecture of this approach.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-9-stream-approach-2-dataflow-with-direct-model.png&#34; alt=&#34;Stream approach 2: Dataflow with direct-model prediction&#34;&gt;&lt;strong&gt;Figure 9.&lt;/strong&gt; Stream approach 2: Dataflow with direct-model prediction&lt;/p&gt;
&lt;p&gt;In this approach, the Dataflow pipeline performs the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read messages from Pub/Sub topic.&lt;/li&gt;
&lt;li&gt;Call the local TensorFlow &lt;code&gt;SavedModel&lt;/code&gt; to get predictions for each record.&lt;/li&gt;
&lt;li&gt;Write results to BigQuery by using streaming APIs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The micro-batching technique can also be used in the stream pipeline with the direct-model prediction approach. Instead of sending a tensor of one data instance to the model, we can send a tensor of N data instances, where N is equal to the messages received within the Dataflow window to the model. This technique uses the vectorized operations of the TensorFlow model and gets several predictions in parallel.&lt;/p&gt;
&lt;h3 id=&#34;experiment-configurations-1&#34;&gt;Experiment configurations&lt;/h3&gt;
&lt;p&gt;We used the following configurations for these experiments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stream data size: &lt;code&gt;10K records (messages)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Simulated messages per second (MPS): &lt;code&gt;50&lt;/code&gt;, &lt;code&gt;100&lt;/code&gt;, and &lt;code&gt;500&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Window size (in micro-batch experiments): &lt;code&gt;1 second&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Dataflow region: &lt;code&gt;europe-west1-b&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Dataflow worker machine type: &lt;code&gt;n1-standard-1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Dataflow &lt;code&gt;num_worker&lt;/code&gt;: &lt;code&gt;5&lt;/code&gt; (no auto-scaling)&lt;/li&gt;
&lt;li&gt;AI Platform model API nodes: &lt;code&gt;3 (manualScale)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;results-1&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;The following table summarizes the results of performing the streaming experiments with different volumes of data (messages per second). &lt;em&gt;Messages frequency&lt;/em&gt; refers to the number of messages sent per second, and &lt;em&gt;simulation time&lt;/em&gt; refers to the time to send all the messages.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Stream messages frequency&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Metric&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Dataflow with AI Platform online prediction&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Dataflow with direct-model prediction&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Single message&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Micro-batching&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Single message&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Micro-batching&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;50 msg per sec&lt;/strong&gt;  (Simulation time: 3 min 20 sec)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Total time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;9 min 34 sec&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7 min 44 sec&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3 min 43 sec&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3 min 22 sec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;100 msg per sec&lt;/strong&gt;  (Simulation time**:** 1 min 40 sec)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Total time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;6 min 03 sec&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4 min 34 sec&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 min 51 sec&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 min 41 sec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;500 msg per sec&lt;/strong&gt;  (Simulation time**:** 20 sec)&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Total time&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;a href=&#34;https://cloud.google.com/ml-engine/docs/tensorflow/quotas&#34;&gt;NA - Default AI Platform Online Prediction Quota&lt;/a&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2 min 47 sec&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 min 23 sec&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;48 sec&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Figure 10 shows a graph of these results.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.google.com/solutions/images/comparing-ml-model-predictions-using-cloud-dataflow-fig-10-barchart-streaming-results.svg&#34; alt=&#34;Graph showing timings for different approaches and frequencies&#34;&gt;&lt;strong&gt;Figure 10.&lt;/strong&gt; Graph showing timings for different approaches and frequencies&lt;/p&gt;
&lt;p&gt;As shown in the results, the micro-batching technique improves the execution performance in both AI Platform online prediction and in direct-model prediction. In addition, using direct-model with streaming pipeline shows 2 times to 4 times the performance improvement compared to calling an external REST/HTTP API for online prediction.&lt;/p&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;According to the described approaches and experiment results, we recommend the following approaches.&lt;/p&gt;
&lt;h3 id=&#34;batch-processing&#34;&gt;Batch processing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If you are building your batch data processing pipeline, and you want prediction as part of the pipeline, use the direct-model approach for the best performance.&lt;/li&gt;
&lt;li&gt;Improve the performance of the direct-model approach by creating micro-batches of the data points before calling the local model for prediction to make use of the parallelization of the vectorized operations.&lt;/li&gt;
&lt;li&gt;If your data is populated to Cloud Storage in the format expected for prediction, use AI Platform batch prediction for the best performance.&lt;/li&gt;
&lt;li&gt;Use AI Platform if you want to use the power of GPUs for batch prediction.&lt;/li&gt;
&lt;li&gt;Do not use AI Platform online prediction for batch prediction.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;stream-processing&#34;&gt;Stream processing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use direct-model in the streaming pipeline for best performance and reduced average latency. Predictions are performed locally, with no HTTP calls to remote services.&lt;/li&gt;
&lt;li&gt;Decouple your model from your data processing pipelines for better maintainability of models used in online predictions. The best approach is to serve your model as an independent microservice by using AI Platform or any other web hosting service.&lt;/li&gt;
&lt;li&gt;Deploy your model as an independent web service to allow multiple data processing pipelines and online apps to consume the model service as an endpoint. In addition, changes to the model are transparent to the apps and pipelines that consume it.&lt;/li&gt;
&lt;li&gt;Deploy multiple instances of the service with load balancing to improve the scalability and the availability of the model web service. With AI Platform, you only need to specify the number of nodes (&lt;code&gt;manualScaling&lt;/code&gt;) or &lt;code&gt;minNodes&lt;/code&gt; (&lt;code&gt;autoScaling&lt;/code&gt;) in the yaml configuration file when you deploy a model version.&lt;/li&gt;
&lt;li&gt;If you deploy your model in a separate microservice, there are extra costs, depending on the underlying serving infrastructure. See the pricing &lt;a href=&#34;https://cloud.google.com/ml-engine/docs/tensorflow/pricing-faq&#34;&gt;FAQ&lt;/a&gt; for AI Platform online prediction.&lt;/li&gt;
&lt;li&gt;Use micro-batching in your streaming data processing pipeline for better performance with both the direct-model and HTTP-model service. Micro-batching reduces the number of HTTP requests to the model service, and uses the vectorized operations of the TensorFlow model to get predictions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Learn how to build and train the baby-weight model in the &lt;a href=&#34;https://cloud.google.com/solutions/machine-learning/ml-on-structured-data-analysis-prep-1#explore_the_public_natality_dataset&#34;&gt;Machine Learning with Structured Data&lt;/a&gt; solution.&lt;/li&gt;
&lt;li&gt;Have a look at the &lt;a href=&#34;https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/blogs/tf_dataflow_serving&#34;&gt;companion repository&lt;/a&gt; on GitHub.&lt;/li&gt;
&lt;li&gt;Try out other Google Cloud features for yourself. Have a look at our &lt;a href=&#34;https://cloud.google.com/docs/tutorials&#34;&gt;tutorials&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/solutions/comparing-ml-model-predictions-using-cloud-dataflow-pipelines&#34;&gt;Comparing Machine Learning Models for Predictions in Cloud Dataflow Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>recommendations</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/recommendation-system/product-overview/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/recommendation-system/product-overview/</guid>
      
        <description>&lt;h2 id=&#34;implementing-recommendations&#34;&gt;Implementing Recommendations&lt;/h2&gt;
&lt;h3 id=&#34;steps&#34;&gt;Steps&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Set up a project&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Import your &lt;strong&gt;product catalog&lt;/strong&gt;
You can add items to your Recommendations AI product catalog individually by using the import Files or API.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Information of the products sold to customers. This includes the product title, description, in stock availability, pricing, and so on.&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Record &lt;strong&gt;user events&lt;/strong&gt;
User events track user actions such as clicking on a product, adding an item to a shopping cart, or purchasing an item, and so on. Recommendations AI relies on user event data in order to generate personalized recommendations. User events need to be ingested in real time to accurately reflect the behavior of your users.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;End user behavior on your website. This includes users searching for, viewing, or purchasing a specific item, your website showing users a list of products, and so on.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;p&gt;Determine your &lt;strong&gt;recommendation types&lt;/strong&gt; and &lt;strong&gt;placements&lt;/strong&gt;
Reviewing the available recommendation types, optimization objectives, and other model tuning options to determine the best options for your business objectives. The location of the recommendation panel and the objective for that panel impact model tuning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Import historical user events
Your models need sufficient training data before they can provide accurate predictions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create your model
After you have met the data requirements, create your model to initiate model training and tuning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create your placements and preview your recommendations
After your model has been activated, you can create your placements and &lt;strong&gt;preview&lt;/strong&gt; the recommendations from your model to &lt;strong&gt;ensure&lt;/strong&gt; your setup is functioning as expected.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set up an A/B experiment (Optional)
You can compare the performance of your website with Recommendations AI recommendations to a &lt;strong&gt;baseline&lt;/strong&gt; version of your website without Recommendations AI recommendations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Evaluate your model
You can associate recommendations and user events and Recommendations AI provides reporting of metrics to help you determine how incorporating the recommendations is affecting your business, then view recommendation metrics for your project in the Dashboard.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can upload and manage product catalog information and user event logs for your websites. Recommendations AI uses this information to train and update recommendation models.&lt;/p&gt;
&lt;h2 id=&#34;recommendation-model-types&#34;&gt;Recommendation model types&lt;/h2&gt;
&lt;p&gt;When you request recommendations from Recommendations AI, you provide the &lt;code&gt;placement&lt;/code&gt; value, which determines which model is used to return your recommendations.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Model type&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Optimization objective&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;placement&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;User event types&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Minimum data requirement&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Data collection window&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Recommended for you&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Click-through rate&lt;/td&gt;
&lt;td&gt;home_page&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;detail-page-view&lt;/code&gt; &lt;code&gt;add-to-cart&lt;/code&gt; &lt;code&gt;purchase-complete&lt;/code&gt; &lt;code&gt;home-page-view&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 week, with an average of 10 &lt;code&gt;detail-page-view&lt;/code&gt; events per joined catalog item.OR60 days with at least one joined &lt;code&gt;detail-page-view&lt;/code&gt; event.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3 months&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Recommended for you&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Conversion rate&lt;/td&gt;
&lt;td&gt;home_page&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;detail-page-view&lt;/code&gt; &lt;code&gt;add-to-cart&lt;/code&gt; &lt;code&gt;purchase-complete&lt;/code&gt; &lt;code&gt;home-page-view&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 week, with an average of 10 &lt;code&gt;add-to-cart&lt;/code&gt; events per joined catalog item.OR60 days with at least one joined &lt;code&gt;add-to-cart&lt;/code&gt; event.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3 months&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Others you may like&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Click-through rate&lt;/td&gt;
&lt;td&gt;product_detail&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;detail-page-view&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 week, with an average of 10 &lt;code&gt;detail-page-view&lt;/code&gt; events per joined catalog item.OR60 days with at least one joined &lt;code&gt;detail-page-view&lt;/code&gt; event.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3 months&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Others you may like&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Conversion rate&lt;/td&gt;
&lt;td&gt;product_detail&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;add-to-cart&lt;/code&gt; &lt;code&gt;detail-page-view&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 week, with an average of 10 &lt;code&gt;add-to-cart&lt;/code&gt; events per joined catalog item.OR60 days with at least one joined &lt;code&gt;add-to-cart&lt;/code&gt; event.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3 months&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Frequently bought together&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;revenue per order&lt;/td&gt;
&lt;td&gt;shopping_cart&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;code&gt;purchase-complete&lt;/code&gt; &lt;code&gt;detail-page-view&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;An average of 10 &lt;code&gt;purchase-complete&lt;/code&gt; events per joined catalog item.OR90 days of &lt;code&gt;purchase-complete&lt;/code&gt; events.&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;12 months&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;user-events&#34;&gt;User events&lt;/h2&gt;
&lt;h3 id=&#34;event-type-priority&#34;&gt;Event type priority&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Priority&lt;/th&gt;
&lt;th&gt;User Events&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Required for initial live experiment&lt;/td&gt;
&lt;td&gt;add-to-cart, detail-page-view, home-page-view, purchase-complete&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Important for improving model quality over time&lt;/td&gt;
&lt;td&gt;checkout-start, category-page-view, remove-from-cart, search, shopping-cart-page-view&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nice to have&lt;/td&gt;
&lt;td&gt;add-to-list, page-visit, refund, remove-from-list&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;user-event-type-examples-and-schemas&#34;&gt;User event type examples and schemas&lt;/h3&gt;
&lt;p&gt;Hadoop/Bigquery/Snowflake/Redshift&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/recommendations-ai/docs/setting-up&#34;&gt;recommendations-ai&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Deploying machine learning models in production</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/deploy/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/deploy/</guid>
      
        <description>&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/329372124/answer/743251971&#34;&gt;训练好的深度学习模型是怎么部署的？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/151406969&#34;&gt;PyTorch模型的加速及部署&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ahkarami/Deep-Learning-in-Production&#34;&gt;ahkarami/Deep-Learning-in-Production&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html&#34;&gt;Accelerating Inference In TF-TRT User Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorrt&#34;&gt;tensorflow/tensorrt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/deeplearning/tensorrt/api/index.html&#34;&gt;Tensorrt API Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow&#34;&gt;Containers: nvidia:tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.databricks.com/applications/machine-learning/model-inference/resnet-model-inference-tensorrt.html&#34;&gt;Model inference using TensorFlow and TensorRT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.tensorflow.org/2018/04/speed-up-tensorflow-inference-on-gpus-tensorRT.html&#34;&gt;Speed up TensorFlow Inference on GPUs with TensorRT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/vinhngx/tensorrt/blob/vinhn-tf20-notebook/tftrt/examples/image-classification/TFv2-TF-TRT-inference-from-Keras-saved-model.ipynb&#34;&gt;TF20-TF-TRT-inference-from-Keras-saved-model.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Developing Lightweight Microservices Using Kubernetes</title>
      <link>http://www.yezheng.pro/post/specialization/web-application/spring/microservice-with-kubernetes/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/web-application/spring/microservice-with-kubernetes/</guid>
      
        <description>&lt;h2 id=&#34;introduction-to-kubernetes&#34;&gt;Introduction to Kubernetes&lt;/h2&gt;
&lt;h2 id=&#34;deploying-our-microservices-in-kubernetes&#34;&gt;Deploying Our Microservices in Kubernetes&lt;/h2&gt;
&lt;h2 id=&#34;implementing-kubernetes-features-as-an-alternative&#34;&gt;Implementing Kubernetes Features as an Alternative&lt;/h2&gt;
&lt;h2 id=&#34;using-a-service-mesh-to-improve-observability-and-management&#34;&gt;Using a Service Mesh to Improve Observability and Management&lt;/h2&gt;
&lt;h2 id=&#34;centralized-logging-with-the-efk-stack&#34;&gt;Centralized Logging with the EFK Stack&lt;/h2&gt;
&lt;h2 id=&#34;monitoring-microservices&#34;&gt;Monitoring Microservices&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>Getting Started with Microservice Development Using Spring Boot</title>
      <link>http://www.yezheng.pro/post/specialization/web-application/spring/microservice-with-spring-boot/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/web-application/spring/microservice-with-spring-boot/</guid>
      
        <description>&lt;h2 id=&#34;introduction-to-microservices&#34;&gt;Introduction to Microservices&lt;/h2&gt;
&lt;h3 id=&#34;benefits&#34;&gt;Benefits&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Each component in the platform can be &lt;strong&gt;delivered and upgraded separately&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Each component in the platform can also be &lt;strong&gt;scaled&lt;/strong&gt; out to multiple servers &lt;strong&gt;independently&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Many small components that use synchronous communication can cause &lt;em&gt;a&lt;/em&gt; &lt;em&gt;chain of failure&lt;/em&gt; problem, especially under high load.&lt;/li&gt;
&lt;li&gt;Keeping the configuration consistent and up to date in all the instances&lt;/li&gt;
&lt;li&gt;Monitoring the state of the platform in terms of latency issues and hardware usage was more complicated&lt;/li&gt;
&lt;li&gt;Collecting log files and correlating related log events from the components was also difficult.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;microservice-must-fulfill-certain-criteria&#34;&gt;microservice must fulfill certain criteria&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;It must conform to a shared-nothing architecture; that is, microservices &lt;strong&gt;don&amp;rsquo;t share data in databases&lt;/strong&gt; with each other!&lt;/li&gt;
&lt;li&gt;It must &lt;strong&gt;only communicate through well-defined interfaces&lt;/strong&gt;, for example, using synchronous services or preferably by sending messages to each other using APIs and message formats that are stable, well-documented, and evolve by following a defined versioning strategy.&lt;/li&gt;
&lt;li&gt;It must be deployed as separate runtime processes. Each instance of a microservice runs in a &lt;strong&gt;separate runtime process&lt;/strong&gt;, for example, a Docker container.&lt;/li&gt;
&lt;li&gt;Microservice instances are &lt;strong&gt;stateless&lt;/strong&gt; so that incoming requests to a microservice can be handled by any of its instances.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-big-should-a-microservice-be&#34;&gt;How big should a microservice be?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Small enough to fit in the head of a developer&lt;/li&gt;
&lt;li&gt;Big enough to not jeopardize performance (that is, latency) and/or data consistency (SQL foreign keys between data that&amp;rsquo;s stored in different microservices are no longer something you can take for granted)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;design-patterns-for-microservices&#34;&gt;Design patterns for microservices&lt;/h3&gt;
&lt;h4 id=&#34;service-discovery&#34;&gt;Service discovery&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;Microservices instances are typically assigned dynamically allocated IP addresses, how can clients find microservices and their instances?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;a &lt;strong&gt;service discovery&lt;/strong&gt; service keeps track of currently available microservices and the IP addresses of its instances.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;p&gt;Automatically register/unregister microservices&lt;/p&gt;
&lt;p&gt;The request will be routed to one of the microservices available instances.&lt;/p&gt;
&lt;p&gt;Requests to a microservice must be load-balanced over the available instances.&lt;/p&gt;
&lt;p&gt;We must be able to detect instances that are not currently healthy; that is, requests will not be routed to them.&lt;/p&gt;
&lt;p&gt;This design pattern can be implemented using two different strategies: &lt;strong&gt;Client-side routing&lt;/strong&gt; or &lt;strong&gt;Server-side routing&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;edge-server&#34;&gt;Edge server&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;It is in many cases desirable to expose some of the microservices to the outside and hide the remaining microservices from external access. The exposed microservices must be protected against requests from malicious clients.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;all incoming requests will go through an &lt;strong&gt;Edge Server&lt;/strong&gt;, Implementation notes: An edge server typically behaves like a reverse proxy and can be integrated with a discovery service to provide dynamic load balancing capabilities.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;p&gt;Hide internal services that should not be exposed outside their context; that is, only route requests to microservices that are configured to allow external requests.&lt;/p&gt;
&lt;p&gt;Expose external services and protect them from malicious requests; that is, use standard protocols and best practices such as OAuth, OIDC, JWT tokens, and API keys to ensure that the clients are trustworthy.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reactive-microservices&#34;&gt;Reactive microservices&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;we are used to implementing  &lt;strong&gt;synchronous&lt;/strong&gt; communication using &lt;strong&gt;blocking I/O&lt;/strong&gt;, for example, a RESTful JSON API over HTTP. a server might run out of available threads in the operating system, causing problems ranging from longer response times to crashing servers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;overusing&lt;/strong&gt; blocking I/O can make a system of microservices prone to errors which is also known as a &lt;strong&gt;chain of failures&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;Use non-blocking I/O to ensure that no threads are allocated while waiting for processing to occur in another service, that is, a database or another microservice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;p&gt;Whenever feasible, use an &lt;strong&gt;asynchronous programming&lt;/strong&gt; model; that is, send messages without waiting for the receiver to process them.&lt;/p&gt;
&lt;p&gt;If a synchronous programming model is preferred, ensure that reactive frameworks are used that can execute &lt;strong&gt;synchronous requests using non-blocking I/O&lt;/strong&gt;, that is, without allocating a thread while waiting for a response. This will make the microservices easier to scale in order to handle an increased workload.&lt;/p&gt;
&lt;p&gt;Microservices must also be designed to be resilient, that is, &lt;strong&gt;capable of producing a response, even if a service that it depends on fails&lt;/strong&gt;. Once the failing service is operational again, its clients must be able to resume using it, which is known as self-healing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;central-configuration&#34;&gt;Central configuration&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;How do I get a complete picture of the configuration that is in place for all the running microservice instances?&lt;/p&gt;
&lt;p&gt;How do I update the configuration and make sure that all the affected microservice instances are updated correctly?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;a configuration server to store the configuration of all the microservices.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;p&gt;Make it possible to store configuration information for a group of microservices in one place, with different settings for different environments (for example, dev, test, qa, and prod).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;centralized-log-analysis&#34;&gt;Centralized log analysis&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;How do I find out if any of the microservice instances get into trouble and start writing error messages to their log files?&lt;/p&gt;
&lt;p&gt;If end users start to report problems, how can I find related log messages; that is, how can I identify which microservice instance is the root cause of the problem?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;Add a new component that can manage &lt;strong&gt;centralized logging&lt;/strong&gt; and is capable of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecting new microservice instances and collecting log events from them&lt;/li&gt;
&lt;li&gt;Interpreting and storing log events in a structured and searchable way in a central database&lt;/li&gt;
&lt;li&gt;Providing APIs and graphical tools for querying and analyzing log events&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;distributed-tracing&#34;&gt;Distributed tracing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;If end users start to file support cases regarding a specific failure, how can we identify the microservice that caused the problem, that is, the root cause?&lt;/p&gt;
&lt;p&gt;If one support case mentions problems related to a specific entity, for example, a specific order number, how can we find log messages related to processing this specific order&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;To track the processing between cooperating microservices, we need to ensure that all related requests and messages are marked with a common correlation ID and that the correlation ID is part of all log events. Based on a correlation ID, we can use the centralized logging service to find all related log events.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;p&gt;Assign unique correlation IDs to all incoming or new requests and events in a well-known place, such as a header with a recognized name.&lt;/p&gt;
&lt;p&gt;When a microservice makes an outgoing request or sends a message, it must add the correlation ID to the request and message.&lt;/p&gt;
&lt;p&gt;All log events must include the correlation ID in a predefined format so that the centralized logging service can extract the correlation ID from the log event and make it searchable.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;circuit-breaker&#34;&gt;Circuit Breaker&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;A system landscape of microservices that uses &lt;strong&gt;synchronous&lt;/strong&gt; intercommunication can be exposed to a &lt;em&gt;&lt;strong&gt;chain of failure&lt;/strong&gt;&lt;/em&gt;. If one microservice stops responding, its clients might get into problems as well and stop responding to requests from their clients. The problem can propagate recursively throughout a system landscape.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;Add a Circuit Breaker that prevents new outgoing requests from a caller if it detects a problem with the service it calls.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open the circuit and fail fast (without waiting for a timeout) if problems with the service are detected.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Probe&lt;/strong&gt; (探针) for failure correction (also known as a &lt;strong&gt;half-open circuit&lt;/strong&gt;); that is, allow a single request to go through on a regular basis to &lt;strong&gt;see if&lt;/strong&gt; the service operates normally again.&lt;/li&gt;
&lt;li&gt;Close the circuit if the probe detects that the service operates normally again. This capability is very important since it makes the system landscape resilient to these kinds of problems; that is, it &lt;strong&gt;self-heals&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;all &lt;strong&gt;synchronous&lt;/strong&gt; communication within the system landscape of microservices &lt;strong&gt;goes through Circuit Breakers&lt;/strong&gt;. All the Circuit Breakers are closed; that is, they allow traffic, except for one Circuit Breaker detected problems in the service the requests go to.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;control-loop&#34;&gt;Control loop&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;In a system landscape with a large number of microservice instances spread out over a number of servers, it is very difficult to manually detect and correct problems such as crashed or hung microservice instances.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;Add a new component, a &lt;strong&gt;control loop&lt;/strong&gt;, to the system landscape; this constantly observes the actual state of the system landscape; compares it with the desired state, as specified by the operators; and, if required, takes action.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static.packt-cdn.com/products/9781789613476/graphics/4716aa50-5154-4e6a-b6d2-32ae7728d640.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;p&gt;Implementation notes: In the world of containers, a &lt;em&gt;container orchestrator&lt;/em&gt; such as &lt;strong&gt;Kubernetes&lt;/strong&gt; is typically used to implement this pattern.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;centralized-monitoring-and-alarms&#34;&gt;Centralized monitoring and alarms&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The problem&lt;/p&gt;
&lt;p&gt;If observed response times and/or the usage of hardware resources become unacceptably high, it can be very hard to discover the root cause of the problem.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A solution&lt;/p&gt;
&lt;p&gt;Add a new component, a &lt;strong&gt;monitor service&lt;/strong&gt;, which is capable of collecting metrics about hardware resource usage for each microservice instance level.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Requirements for the solution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It must be able to collect metrics from all the servers that are used by the system landscape, which includes auto-scaling servers.&lt;/li&gt;
&lt;li&gt;It must be able to detect new microservice instances as they are launched on the available servers and start to collect metrics from them.&lt;/li&gt;
&lt;li&gt;It must be able to provide APIs and graphical tools for querying and analyzing the collected metrics.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use &lt;strong&gt;Grafana&lt;/strong&gt; visualizes metrics from &lt;strong&gt;Prometheus&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software-enablers&#34;&gt;Software enablers&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Design Pattern&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Spring Boot&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Spring Cloud&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Istio&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Service discovery&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Netflix Eureka and Netflix Ribbon&lt;/td&gt;
&lt;td&gt;Kubernetes kube-proxy and service resources&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Edge server&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Spring Cloud and Spring Security OAuth&lt;/td&gt;
&lt;td&gt;Kubernetes Ingress controller&lt;/td&gt;
&lt;td&gt;Istio ingress gateway&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Reactive microservices&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Spring Reactor and Spring WebFlux&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Central configuration&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Spring Config Server&lt;/td&gt;
&lt;td&gt;Kubernetes ConfigMaps and Secrets&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Centralized log analysis&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Elasticsearch, Fluentd, and Kibana  &lt;strong&gt;Note&lt;/strong&gt;: Actually not part of Kubernetes  but can easily be deployed and configured together with Kubernetes&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Distributed tracing&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Spring Cloud Sleuth and Zipkin&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Jaeger&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Circuit Breaker&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Resilience4j&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Outlier detection&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Control loop&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Kubernetes controller manager&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Centralized monitoring and alarms&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Grafana and Prometheus&lt;!-- raw HTML omitted --&gt; &lt;strong&gt;Note:&lt;/strong&gt; Actually not part of Kubernetes&lt;/td&gt;
&lt;td&gt;Kiali, Grafana, and Prometheus&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Please note that Spring Cloud, Kubernetes, and Istio can be used to implement some design patterns, such as service discovery, edge server, and central configuration. We will discuss the pros and cons of using these alternatives later in this book.&lt;/p&gt;
&lt;h3 id=&#34;other-important-considerations&#34;&gt;Other important considerations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Importance of Dev/Ops&lt;/strong&gt;: microservice architecture enables shorter delivery times and allows the &lt;em&gt;continuous delivery&lt;/em&gt; of new versions.  the teams also need to &lt;strong&gt;automate the delivery chain&lt;/strong&gt;, that is, the steps for building, testing, packaging, and deploying the microservices to the various deployment environments. This is known as setting up a &lt;em&gt;delivery pipeline&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Decomposing a monolithic application into microservices&lt;/strong&gt;: One of the most difficult and expensive decisions is how to decompose a monolithic application into a set of cooperating microservices. If this is done in the wrong way, you will end up with problems such as the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slow delivery&lt;/li&gt;
&lt;li&gt;Slow performance&lt;/li&gt;
&lt;li&gt;Inconsistent data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A good approach to finding proper boundaries for microservices is to apply &lt;strong&gt;Domain-Driven Design&lt;/strong&gt; and its &lt;strong&gt;Bounded Context&lt;/strong&gt; concept. According to Eric Evans, a &lt;em&gt;Bounded Context&lt;/em&gt; is &amp;ldquo;&lt;em&gt;A description of a boundary (typically a subsystem, or the work of a particular team) within which a particular model is defined and applicable.&amp;quot;&lt;/em&gt; This means that the microservice defined by a Bounded Context will have a well-defined model of its own data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Importance of API design&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the description in terms of the naming and data types used.&lt;/li&gt;
&lt;li&gt;It is of great importance that APIs are allowed to evolve in a controlled manner. This typically requires applying a proper versioning schema for the APIs, allowing clients of the API to migrate to new major versions at their own pace.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Migration paths from on-premise to the cloud&lt;/strong&gt;: An appealing migration approach can be to &lt;strong&gt;first move&lt;/strong&gt; the workload into Kubernetes on-premise (as microservices or not) &lt;strong&gt;and then redeploy&lt;/strong&gt; it on a &lt;em&gt;Kubernetes as a Service&lt;/em&gt; offering provided by a preferred cloud provider.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Good design principles for microservices, the 12-factor app&lt;/strong&gt;: The 12-factor app (&lt;a href=&#34;https://12factor.net/&#34;&gt;https://12factor.net&lt;/a&gt;) is a set of design principles for building software that can be deployed in the cloud.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction-to-spring-boot&#34;&gt;Introduction to Spring Boot&lt;/h2&gt;
&lt;p&gt;We will develop microservices that contain business logic based on plain Spring Beans and REST APIs using Spring WebFlux, the Swagger/OpenAPI-based documentation of the REST APIs, and SpringFox and data persistence, while using Spring Data to store data in both SQL and NoSQL databases&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;plain Spring Beans, Spring WebFlux,  Swagger, SpringFox, Spring Data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;create reactive microservices in this chapter, including both non-blocking synchronous REST APIs and message-based asynchronous services&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;use &lt;strong&gt;Spring WebFlux&lt;/strong&gt; to develop non-blocking synchronous REST APIs and &lt;strong&gt;Spring Cloud Stream&lt;/strong&gt; to develop message-based asynchronous services.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learning-about-spring-boot&#34;&gt;Learning about Spring Boot&lt;/h3&gt;
&lt;p&gt;Spring Boot does that by applying a number of &lt;strong&gt;conventions&lt;/strong&gt; by default, minimizing the need for configuration. Whenever required, each convention can be overridden by writing some configuration, case by case.  Configuration, when required, is in my opinion written best using Java and &lt;strong&gt;annotations&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A fat &lt;strong&gt;JAR&lt;/strong&gt; file contains not only the classes and resource files of the application itself, but also all the .jar files the application depends on. This means that the fat JAR file is the only JAR file required to run the application.&lt;/p&gt;
&lt;p&gt;Starting a fat JAR requires no separately installed Java EE web server, such as Apache Tomcat. Instead, it can be started with a simple command such as java -jar app.jar, making it a perfect choice for running in a Docker container!&lt;/p&gt;
&lt;h4 id=&#34;component-scanning&#34;&gt;Component scanning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Let&amp;rsquo;s assume we have the following Spring &lt;strong&gt;component in the package of the application class&lt;/strong&gt; (or in one of its sub-packages):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Component
public class MyComponentImpl implements MyComponent { ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Another component in the application can get the component automatically injected, also known as &lt;strong&gt;auto-wiring&lt;/strong&gt;, using the &lt;strong&gt;&lt;code&gt;@Autowired&lt;/code&gt;&lt;/strong&gt; annotation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class AnotherComponent {
  
  private final MyComponent myComponent;
  
  @Autowired
  public AnotherComponent(MyComponent myComponent) {
    this.myComponent = myComponent;
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I prefer using constructor injection (over field and setter injection) to keep the state in my components immutable. The immutable state is important if you want to be able to run the component in a multithreaded runtime environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we want to use components that are &lt;strong&gt;declared in a package outside the applications package&lt;/strong&gt;, for example, a utility component shared by multiple Spring Boot applications, we can complement the @SpringBootApplication annotation in the application class with a &lt;strong&gt;&lt;code&gt;@ComponentScan&lt;/code&gt;&lt;/strong&gt; annotation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package se.magnus.myapp;
  
@SpringBootApplication
@ComponentScan({&amp;quot;se.magnus.myapp&amp;quot;,&amp;quot;se.magnus.utils&amp;quot;})
public class MyApplication {
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can now auto-wire components from the se.magnus.util package in the application code, for example, a utility component, as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package se.magnus.utils;
  
@Component
public class MyUtility { ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This utility component can be auto-wired in an application component like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package se.magnus.myapp.services;
  
public class AnotherComponent {
  
 private final MyUtility myUtility;
  
 @Autowired
 public AnotherComponent(MyUtility myUtility) {
   this.myUtility = myUtility;
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;java-based-configuration&#34;&gt;Java-based configuration&lt;/h4&gt;
&lt;p&gt;If we want to override Spring Boot&amp;rsquo;s default configuration or if we want to add our own configuration, we can simply annotate a class with &lt;strong&gt;&lt;code&gt;@Configuration&lt;/code&gt;&lt;/strong&gt;. for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Configuration
public class SubscriberApplication {

  @Bean
  public Filter logFilter() {
    CommonsRequestLoggingFilter filter = new 
        CommonsRequestLoggingFilter();
    filter.setIncludeQueryString(true);
    filter.setIncludePayload(true);
    filter.setMaxPayloadLength(5120);
    return filter;
  }
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;reactive-non-blocking-synchronous-rest-services-with-spring-webflux&#34;&gt;Reactive non-blocking synchronous REST services with Spring WebFlux.&lt;/h3&gt;
&lt;p&gt;Spring Framework uses &lt;strong&gt;Project Reactor&lt;/strong&gt; as the base implementation of its reactive support, and also comes with a new web framework, Spring WebFlux, which supports the development of reactive, that is, non-blocking, HTTP clients and services.&lt;/p&gt;
&lt;p&gt;Spring WebFlux supports running on a servlet container, but also supports reactive non-servlet-based embedded web servers such as &lt;strong&gt;Netty&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The Spring WebFlux starter dependency will be added to the build.gradle file. It looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;implementation(&#39;org.springframework.boot:spring-boot-starter-webflux&#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When the microservice is started up, Spring Boot will detect Spring WebFlux on the classpath and configure it,  then start up an embedded web server, Netty is used by default,&lt;/p&gt;
&lt;p&gt;If we want to switch from Netty to Tomcat as our embedded web server, we can override the default configuration by excluding Netty from the starter dependency and add the starter dependency for Tomcat:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;implementation(&#39;org.springframework.boot:spring-boot-starter-webflux&#39;) 
{
 exclude group: &#39;org.springframework.boot&#39;, module: &#39;spring-boot-
 starter-reactor-netty&#39;
}
implementation(&#39;org.springframework.boot:spring-boot-starter-tomcat&#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Spring Boot application property files can either be a .properties file or a YAML file. By default, they are named application.properties and application.yml, respectively. Avoid port collisions with other microservices running on the same server, add the following line to the application.yml file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server.port: 7001
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Sample RestController&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@RestController
public class MyRestService {

  @GetMapping(value = &amp;quot;/my-resource&amp;quot;, produces = &amp;quot;application/json&amp;quot;)
  List&amp;lt;Resource&amp;gt; listResources() {
    ...
  }
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;swagger-and-openapi-based-documentation-with-springfox&#34;&gt;Swagger and OpenAPI-based documentation with SpringFox&lt;/h3&gt;
&lt;p&gt;SpringFox is an open-source project, separate from the Spring Framework, that can create Swagger-based API documentation at runtime. It does so by examining the application at startup, for example, inspecting WebFlux and Swagger-based annotations.&lt;/p&gt;
&lt;h3 id=&#34;persistent-data-with-spring-data&#34;&gt;Persistent data with Spring Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Spring Data&lt;/strong&gt; comes with a common programming model for persisting data in various types of database engine, ranging from traditional relational databases (SQL databases) to various types of NoSQL database engine, such as document databases (for example, MongoDB), key-value databases (for example, Redis), and graph databases (for example, Neo4J).&lt;/p&gt;
&lt;p&gt;The Spring Data project is divided into several subprojects and in this book we will use &lt;strong&gt;Spring Data&lt;/strong&gt; subprojects for MongoDB and &lt;strong&gt;JPA&lt;/strong&gt; that have been mapped to a MySQL database.&lt;/p&gt;
&lt;p&gt;The two core concepts of the programming model in Spring Data are &lt;strong&gt;entities&lt;/strong&gt; and &lt;strong&gt;repositories&lt;/strong&gt;. Entities and repositories generalize how data is stored and accessed from the various types of database.&lt;/p&gt;
&lt;h4 id=&#34;entity&#34;&gt;Entity&lt;/h4&gt;
&lt;p&gt;Entity classes are, in general, annotated with a mix of generic Spring Data annotations and annotations that are specific to each database technology.&lt;/p&gt;
&lt;p&gt;For example, an entity that will be stored in a relational database can be annotated with JPA annotations such as the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.IdClass;
import javax.persistence.Table;

@Entity
@IdClass(ReviewEntityPK.class)
@Table(name = &amp;quot;review&amp;quot;)
public class ReviewEntity {
 @Id private int productId;
 @Id private int reviewId;
 private String author;
 private String subject;
 private String content;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If an entity is to be stored in a MongoDB database, annotations from the Spring Data MongoDB subproject can be used together with generic Spring Data annotations. For example, consider the following code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import org.springframework.data.annotation.Id;
import org.springframework.data.annotation.Version;
import org.springframework.data.mongodb.core.mapping.Document;

@Document
public class RecommendationEntity {

    @Id
    private String id;

    @Version
    private int version;

    private int productId;
    private int recommendationId;
    private String author;
    private int rate;
    private String content;
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;repositories&#34;&gt;Repositories&lt;/h4&gt;
&lt;p&gt;Repositories are used to store and access data from different types of database. In its most basic form, a repository can be declared as a Java interface.&lt;/p&gt;
&lt;p&gt;Spring Data also comes with some base Java interfaces, for example, CrudRepository, to make the definition of a repository even simpler.&lt;/p&gt;
&lt;p&gt;To specify a repository for handling the JPA entity, ReviewEntity, we only need to declare the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import org.springframework.data.repository.CrudRepository;

public interface ReviewRepository extends CrudRepository&amp;lt;ReviewEntity, ReviewEntityPK&amp;gt; {
    Collection&amp;lt;ReviewEntity&amp;gt; findByProductId(int productId);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this example we use a class, ReviewEntityPK, to describe a composite primary key. It looks as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class ReviewEntityPK implements Serializable {
    public int productId;
    public int reviewId;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We have also added an extra method, findByProductId, which allows us to look up Review entities based on productId&lt;/p&gt;
&lt;p&gt;If we want to use the repository, we can simply inject it and then start to use it, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private final ReviewRepository repository;

@Autowired
public ReviewService(ReviewRepository repository) {
 this.repository = repository;
}

public void someMethod() {
  repository.save(entity);
  repository.delete(entity);
  repository.findByProductId(productId);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Spring Data also provides a reactive base interface, ReactiveCrudRepository, which enables &lt;strong&gt;reactive repositories&lt;/strong&gt;. The methods in this interface do not return objects or collections of objects; instead, they return &lt;strong&gt;Mono&lt;/strong&gt; and &lt;strong&gt;Flux&lt;/strong&gt; objects.&lt;/p&gt;
&lt;p&gt;The reactive-based interface can only be used by Spring Data subprojects that support reactive database drivers; that is, they are based on non-blocking I/O. The Spring Data MongoDB subproject supports reactive repositories, while Spring Data JPA does not.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import org.springframework.data.repository.reactive.ReactiveCrudRepository;
import reactor.core.publisher.Flux;

public interface RecommendationRepository extends ReactiveCrudRepository&amp;lt;RecommendationEntity, String&amp;gt; {
    Flux&amp;lt;RecommendationEntity&amp;gt; findByProductId(int productId);
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;message-based-asynchronous-services-with-spring-cloud-stream&#34;&gt;Message-based asynchronous services with Spring Cloud Stream&lt;/h3&gt;
&lt;p&gt;Spring Cloud Stream provides a streaming abstraction over messaging, based on the publish-and-subscribe integration pattern. Spring Cloud Stream currently comes with support for Apache Kafka and RabbitMQ out of the box. A number of separate projects exist that provide integration with other popular messaging systems. See &lt;a href=&#34;https://github.com/spring-cloud?q=binder&#34;&gt;https://github.com/spring-cloud?q=binder&lt;/a&gt; for more details.&lt;/p&gt;
&lt;p&gt;The core concepts in Spring Cloud Stream are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Message:&lt;/strong&gt; A data structure that&amp;rsquo;s used to describe data sent to and received from a messaging system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Publisher:&lt;/strong&gt; Sends messages to the messaging system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Subscriber&lt;/strong&gt;: Receives messages from the messaging system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Channel:&lt;/strong&gt; Used to communicate with the messaging system. Publishers use output channels and subscribers use input channels.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Binder:&lt;/strong&gt; A binder provides the actual integration with a specific messaging system, similar to what a JDBC driver does for a specific type of database.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;examples&#34;&gt;examples&lt;/h6&gt;
&lt;p&gt;Let&amp;rsquo;s assume that we have a simple message class such as the following (constructors, getters, and setters have been left out for improved readability):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class MyMessage {
  private String attribute1 = null;
  private String attribute2 = null;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Spring Cloud Stream comes with default input and output &lt;strong&gt;channels&lt;/strong&gt;, &lt;strong&gt;Sink&lt;/strong&gt; and &lt;strong&gt;Source&lt;/strong&gt;, so we don&amp;rsquo;t need to create our own to get started. To publish a message, we can use the following source code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import org.springframework.cloud.stream.messaging.Source;

@EnableBinding(Source.class)
public class MyPublisher {

 @Autowired private Source mysource;

 public String processMessage(MyMessage message) {
   mysource.output().send(MessageBuilder.withPayload(message).build());
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To receive messages, we can use the following code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import org.springframework.cloud.stream.messaging.Sink;

@EnableBinding(Sink.class)
public class MySubscriber {

 @StreamListener(target = Sink.INPUT)
 public void receive(MyMessage message) {
 LOG.info(&amp;quot;Received: {}&amp;quot;,message);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To bind to RabbitMQ, we will use a dedicated starter dependency in the build file, build.gradle:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;implementation(&#39;org.springframework.cloud:spring-cloud-starter-stream-rabbit&#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For the subscriber to receive messages from the publisher, we need to configure &lt;strong&gt;the input and output channel&lt;/strong&gt; to use the same destination. If we use YAML to describe our configuration, it might look like the following for the publisher:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spring.cloud.stream:
  default.contentType: application/json
  bindings.output.destination: mydestination
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The configuration for the subscriber is as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spring.cloud.stream:
  default.contentType: application/json
  bindings.input.destination: mydestination
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;learning-about-docker&#34;&gt;Learning about Docker&lt;/h3&gt;
&lt;p&gt;For example, we can write scripts in order to automate end-to-end tests of our microservice landscape. A test script can start up the microservice landscape, run tests using the exposed services, and tear down the landscape. This type of automated test script is very useful.&lt;/p&gt;
&lt;p&gt;A build server can run these types of test in its continuous integration and deployment process whenever a developer pushes code to the source repository.&lt;/p&gt;
&lt;p&gt;The following Dockerfile is all that is required to run the microservice as a Docker container&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM openjdk:12.0.2

MAINTAINER Magnus Larsson &amp;lt;magnus.larsson.ml@gmail.com&amp;gt;

EXPOSE 8080
ADD ./build/libs/*.jar app.jar
ENTRYPOINT [&amp;quot;java&amp;quot;,&amp;quot;-jar&amp;quot;,&amp;quot;/app.jar&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If we want to start and stop many containers with one command, Docker Compose is the perfect tool. Docker Compose uses a YAML file to describe the containers to be managed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;product&lt;/span&gt;:
 &lt;span style=&#34;color:#f92672&#34;&gt;build&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;microservices/product-service&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;recommendation&lt;/span&gt;:
 &lt;span style=&#34;color:#f92672&#34;&gt;build&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;microservices/recommendation-service&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;review&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;build&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;microservices/review-service&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;composite&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;build&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;microservices/product-composite-service&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;8080:8080&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;creating-a-set-of-cooperating-microservices&#34;&gt;Creating a Set of Cooperating Microservices&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter03&#34;&gt;https://github.com/PacktPublishing/Hands-On-Microservices-with-Spring-Boot-and-Spring-Cloud/tree/master/Chapter03&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;introducing-the-microservice-landscape&#34;&gt;Introducing the microservice landscape&lt;/h3&gt;
&lt;p&gt;the microservice-based system demo landscape&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://static.packt-cdn.com/products/9781789613476/graphics/cf74f5f6-c0f7-471c-8eae-a2566ecee996.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;It consists of three core microservices, the &lt;strong&gt;Product&lt;/strong&gt;, &lt;strong&gt;Review&lt;/strong&gt;, and &lt;strong&gt;Recommendation&lt;/strong&gt; services, all of which deal with one type of resource, and a composite microservice called the &lt;strong&gt;Product Composite&lt;/strong&gt; service, which aggregates information from the three core services.&lt;/p&gt;
&lt;p&gt;At this stage, we don&amp;rsquo;t have any service discovery mechanism in place, we will use hardcoded port numbers for each microservice.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Product composite service: 7000&lt;/li&gt;
&lt;li&gt;Product service: 7001&lt;/li&gt;
&lt;li&gt;Review service: 7002&lt;/li&gt;
&lt;li&gt;Recommendation service: 7003&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Information handled by microservices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Product service&lt;/p&gt;
&lt;p&gt;The product service manages product information and describes each product with the following attributes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Product ID&lt;/li&gt;
&lt;li&gt;Name&lt;/li&gt;
&lt;li&gt;Weight&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Review service&lt;/p&gt;
&lt;p&gt;The review service manages product reviews and stores the following information about each review:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Product ID&lt;/li&gt;
&lt;li&gt;Review ID&lt;/li&gt;
&lt;li&gt;Author&lt;/li&gt;
&lt;li&gt;Subject&lt;/li&gt;
&lt;li&gt;Content&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Recommendation service&lt;/p&gt;
&lt;p&gt;The recommendation service manages product recommendations and stores the following information about each recommendation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Product ID&lt;/li&gt;
&lt;li&gt;Recommendation ID&lt;/li&gt;
&lt;li&gt;Author&lt;/li&gt;
&lt;li&gt;Rate&lt;/li&gt;
&lt;li&gt;Content&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Product composite service&lt;/p&gt;
&lt;p&gt;The product composite service aggregates information from the three core services and presents information about a product as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Product information, as described in the product service&lt;/li&gt;
&lt;li&gt;A list of product reviews for the specified product, as described in the review service&lt;/li&gt;
&lt;li&gt;A list of product recommendations for the specified product, as described in the recommendation service&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Infrastructure-related information&lt;/p&gt;
&lt;p&gt;Once we start to run our microservices as containers that are managed by the infrastructure (first Docker and later on Kubernetes), it will be of interest to track which container actually responded to our requests. To simplify this tracking, we have also added a serviceAddress attribute to all our responses, formatted as hostname/ip-address:port.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;generating-skeleton-microservices&#34;&gt;Generating skeleton microservices&lt;/h3&gt;
&lt;h4 id=&#34;using-spring-initializr-to-generate-skeleton-code&#34;&gt;Using Spring Initializr to generate skeleton code&lt;/h4&gt;
&lt;p&gt;To create skeleton code for our microservices, we need to run the following command for product-service:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spring init \
--boot-version=2.1.0.RC1 \
--build=gradle \
--java-version=1.8 \
--packaging=jar \
--name=product-service \
--package-name=se.magnus.microservices.core.product \
--groupId=se.magnus.microservices.core.product \
--dependencies=actuator,webflux \
--version=1.0.0-SNAPSHOT \
product-service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Spring Boot Actuator enables a number of valuable endpoints for management and monitoring. We will see them in action later on. Spring WebFlux will be used here to create our RESTful APIs.&lt;/p&gt;
&lt;p&gt;We can build each microservice separately with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd microservices/product-composite-service; ./gradlew build; cd -; \
cd microservices/product-service;           ./gradlew build; cd -; \
cd microservices/recommendation-service;    ./gradlew build; cd -; \
cd microservices/review-service;            ./gradlew build; cd -; 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;setting-up-multi-project-builds-in-gradle&#34;&gt;Setting up multi-project builds in Gradle&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;create the settings.gradle file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; settings.gradle
include &#39;:microservices:product-service&#39;
include &#39;:microservices:review-service&#39;
include &#39;:microservices:recommendation-service&#39;
include &#39;:microservices:product-composite-service&#39;
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;copy the Gradle executable files that were generated from one of the projects so that we can reuse them for the multi-project builds:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cp -r microservices/product-service/gradle .
cp microservices/product-service/gradlew .
cp microservices/product-service/gradlew.bat .
cp microservices/product-service/.gitignore .
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;no longer need the generated Gradle executable files in each project&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find microservices -depth -name &amp;quot;gradle&amp;quot; -exec rm -rfv &amp;quot;{}&amp;quot; \; 
find microservices -depth -name &amp;quot;gradlew*&amp;quot; -exec rm -fv &amp;quot;{}&amp;quot; \; 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;build all the microservices with one command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./gradlew build
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;adding-restful-apis&#34;&gt;Adding RESTful APIs&lt;/h3&gt;
&lt;h4 id=&#34;adding-an-api-and-a-util-project&#34;&gt;Adding an API and a util project&lt;/h4&gt;
&lt;p&gt;add two projects (api and util) that will contain code that is shared by the microservice projects&lt;/p&gt;
&lt;p&gt;It is debatable whether it is good practice to store API definitions for a group of microservices in a common API module. To me, it is a good choice for microservices that are part of the same delivery organization, that is, whose releases are governed by one and the same organization (compare to a &lt;em&gt;Bounded Context&lt;/em&gt; in &lt;em&gt;Domain-Driven Design&lt;/em&gt;, where our microservices are placed in one and the same bounded context).&lt;/p&gt;
&lt;h6 id=&#34;the-api-project&#34;&gt;The api project&lt;/h6&gt;
&lt;h6 id=&#34;the-util-project&#34;&gt;The util project&lt;/h6&gt;
&lt;h4 id=&#34;implementing-the-restful-apis&#34;&gt;Implementing the RESTful APIs&lt;/h4&gt;
&lt;h3 id=&#34;adding-a-composite-microservice&#34;&gt;Adding a composite microservice&lt;/h3&gt;
&lt;h3 id=&#34;adding-error-handling&#34;&gt;Adding error handling&lt;/h3&gt;
&lt;h3 id=&#34;testing-the-apis-manually&#34;&gt;Testing the APIs manually&lt;/h3&gt;
&lt;h3 id=&#34;adding-automated-tests-of-microservices-in-isolation&#34;&gt;Adding automated tests of microservices in isolation&lt;/h3&gt;
&lt;h3 id=&#34;adding-semi-automated-tests-to-a-microservice-landscape&#34;&gt;Adding semi-automated tests to a microservice landscape&lt;/h3&gt;
&lt;h2 id=&#34;deploying-our-microservices-using-docker&#34;&gt;Deploying Our Microservices Using Docker&lt;/h2&gt;
&lt;h2 id=&#34;adding-api-description-using-openapiswagger&#34;&gt;Adding API Description Using OpenAPI/Swagger&lt;/h2&gt;
&lt;h2 id=&#34;adding-persistence&#34;&gt;Adding Persistence&lt;/h2&gt;
&lt;h2 id=&#34;developing-reactive-microservices&#34;&gt;Developing Reactive Microservices&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>Leveraging Spring Cloud to Manage Microservices</title>
      <link>http://www.yezheng.pro/post/specialization/web-application/spring/microservice-with-spring-cloud/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/web-application/spring/microservice-with-spring-cloud/</guid>
      
        <description>&lt;h2 id=&#34;introduction-to-spring-cloud&#34;&gt;Introduction to Spring Cloud&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Design pattern&lt;/th&gt;
&lt;th&gt;Current component&lt;/th&gt;
&lt;th&gt;Replaced by Software component&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Service discovery&lt;/td&gt;
&lt;td&gt;Netflix Eureka &amp;amp; Netflix Ribbon&lt;/td&gt;
&lt;td&gt;Netflix Eureka and Spring Cloud load balancer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Edge server&lt;/td&gt;
&lt;td&gt;Netflix Zuul&lt;/td&gt;
&lt;td&gt;Spring Cloud Gateway and Spring Security OAuth&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Centralized configuration&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Spring Cloud Configuration Server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Circuit breaker&lt;/td&gt;
&lt;td&gt;Netflix Hystrix&lt;/td&gt;
&lt;td&gt;Resilience4j&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Distributed tracing&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Spring Cloud Sleuth and Zipkin&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;adding-service-discovery-using-netflix-eureka-and-ribbon&#34;&gt;Adding Service Discovery Using Netflix Eureka and Ribbon&lt;/h2&gt;
&lt;h2 id=&#34;using-spring-cloud-gateway-to-hide-microservices-behind-an-edge-server&#34;&gt;Using Spring Cloud Gateway to Hide Microservices Behind an Edge Server&lt;/h2&gt;
&lt;h2 id=&#34;securing-access-to-apis&#34;&gt;Securing Access to APIs&lt;/h2&gt;
&lt;h2 id=&#34;centralized-configuration&#34;&gt;Centralized Configuration&lt;/h2&gt;
&lt;h2 id=&#34;improving-resilience-using-resilience4j&#34;&gt;Improving Resilience Using Resilience4j&lt;/h2&gt;
&lt;h2 id=&#34;understanding-distributed-tracing&#34;&gt;Understanding Distributed Tracing&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>Link custom domain to Github pages</title>
      <link>http://www.yezheng.pro/post/any-path/blog/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/any-path/blog/</guid>
      
        <description>&lt;h3 id=&#34;register-domain-name&#34;&gt;Register Domain Name&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.namesilo.com/&#34;&gt;Namesilo&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;use-a-custom-domain&#34;&gt;Use a Custom Domain&lt;/h3&gt;
&lt;p&gt;If you’d like to use a custom domain for your GitHub Pages site, create a file &lt;code&gt;static/CNAME&lt;/code&gt;. Your custom domain name should be the only contents inside &lt;code&gt;CNAME&lt;/code&gt;. Since it’s inside &lt;code&gt;static&lt;/code&gt;, the published site will contain the CNAME file at the root of the published site, which is a requirements of GitHub Pages.&lt;/p&gt;
&lt;h3 id=&#34;dns-service-provider&#34;&gt;DNS service provider&lt;/h3&gt;
&lt;h4 id=&#34;create-cloudflare-account&#34;&gt;Create Cloudflare account&lt;/h4&gt;
&lt;h4 id=&#34;enter-your-domain-name&#34;&gt;Enter your domain name&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;yezheng.pro
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;review-your-dns-records&#34;&gt;Review your DNS records&lt;/h4&gt;
&lt;p&gt;Add more DNS records for yezheng.pro&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Content&lt;/th&gt;
&lt;th&gt;TTL&lt;/th&gt;
&lt;th&gt;Proxy status&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;yezheng.pro&lt;/td&gt;
&lt;td&gt;192.30.252.154&lt;/td&gt;
&lt;td&gt;Auto&lt;/td&gt;
&lt;td&gt;Proxied&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;yezheng.pro&lt;/td&gt;
&lt;td&gt;192.30.252.153&lt;/td&gt;
&lt;td&gt;Auto&lt;/td&gt;
&lt;td&gt;Proxied&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CNAME&lt;/td&gt;
&lt;td&gt;www&lt;/td&gt;
&lt;td&gt;csyezheng.github.io&lt;/td&gt;
&lt;td&gt;Auto&lt;/td&gt;
&lt;td&gt;Proxied&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;change-your-nameservers&#34;&gt;Change your nameservers&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Log in to your registrar account&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Determine your registrar via &lt;a href=&#34;https://whois.icann.org/en/lookup?name=yezheng.pro&#34;&gt;WHOIS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Remove these nameservers:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ns3.dnsowl.comns1.dnsowl.comns2.dnsowl.com
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Replace with Cloudflare&amp;rsquo;s nameservers&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Nameserver 1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;isabel.ns.cloudflare.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nameserver 2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;phil.ns.cloudflare.com
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>read open source</title>
      <link>http://www.yezheng.pro/post/master-path/read-open-source/</link>
      <pubDate>Sun, 15 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/master-path/read-open-source/</guid>
      
        <description>&lt;h5 id=&#34;awesome-project-lists-using-ginhttpsgithubcomgin-gonicgin-web-framework&#34;&gt;Awesome project lists using &lt;a href=&#34;https://github.com/gin-gonic/gin&#34;&gt;Gin&lt;/a&gt; web framework:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/appleboy/gorush&#34;&gt;gorush&lt;/a&gt;: A push notification server written in Go.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fnproject/fn&#34;&gt;fnproject&lt;/a&gt;: The container native, cloud agnostic serverless platform.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/photoprism/photoprism&#34;&gt;photoprism&lt;/a&gt;: Personal photo management powered by Go and Google TensorFlow.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/devopsfaith/krakend&#34;&gt;krakend&lt;/a&gt;: Ultra performant API Gateway with middlewares.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/thoas/picfit&#34;&gt;picfit&lt;/a&gt;: An image resizing server written in Go.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gotify/server&#34;&gt;gotify&lt;/a&gt;: A simple server for sending and receiving messages in real-time per web socket.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ovh/cds&#34;&gt;cds&lt;/a&gt;: Enterprise-Grade Continuous Delivery &amp;amp; DevOps Automation Open Source Platform.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;awesome-project-lists-using-spring-boot-web-framework&#34;&gt;Awesome project lists using spring boot web framework:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;ctripcorp / apollo Apollo（阿波罗）是携程框架部门研发的分布式配置中心&lt;/li&gt;
&lt;li&gt;sqshq / piggymetrics  a tutorial project demonstrates Microservice Architecture with Spring Boot, Spring Cloud and Docker&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/edx/edx-platform/tree/master/common/djangoapps/track&#34;&gt;https://github.com/edx/edx-platform/tree/master/common/djangoapps/track&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/edx/event-tracking&#34;&gt;https://github.com/edx/event-tracking&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>flink</title>
      <link>http://www.yezheng.pro/post/specialization/big-data/flink/</link>
      <pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/big-data/flink/</guid>
      
        <description>&lt;p&gt;&lt;a href=&#34;https://github.com/apache/flink/tree/master/flink-runtime-web&#34;&gt;Apache Flink Web Dashboard&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Cloud Computing</title>
      <link>http://www.yezheng.pro/post/specialization/cloud-computing/15-319/</link>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/cloud-computing/15-319/</guid>
      
        <description>&lt;h2 id=&#34;introduction-and-course-logistics&#34;&gt;Introduction and Course Logistics&lt;/h2&gt;
&lt;h2 id=&#34;data-analytics&#34;&gt;Data Analytics&lt;/h2&gt;
&lt;h2 id=&#34;big-data-analytics&#34;&gt;Big Data Analytics&lt;/h2&gt;
&lt;h2 id=&#34;elasticity-and-auto-scaling&#34;&gt;Elasticity and Auto Scaling&lt;/h2&gt;
&lt;h2 id=&#34;containers-and-kubernetes&#34;&gt;Containers and Kubernetes&lt;/h2&gt;
&lt;h2 id=&#34;serverless-computing-and-functions-as-a-service&#34;&gt;Serverless Computing and Functions-as-a-Service&lt;/h2&gt;
&lt;h2 id=&#34;flat-files-and-databases--team-project&#34;&gt;Flat Files and Databases &amp;amp; Team Project&lt;/h2&gt;
&lt;h2 id=&#34;social-network-heterogenous-storage-and-dbaas--team-project&#34;&gt;Social Network, Heterogenous Storage and DBaaS &amp;amp; Team Project&lt;/h2&gt;
&lt;h2 id=&#34;replication-and-consistency-and-team-project-phase-1&#34;&gt;Replication and Consistency and Team Project Phase 1&lt;/h2&gt;
&lt;h2 id=&#34;team-project-phase-1&#34;&gt;Team Project Phase 1&lt;/h2&gt;
&lt;h2 id=&#34;iterative-batch-processing-in-spark-and-team-project-phase-2&#34;&gt;Iterative Batch Processing in Spark and Team Project Phase 2&lt;/h2&gt;
&lt;h2 id=&#34;team-project-phase-2-and-live-test&#34;&gt;Team Project Phase 2 and Live Test&lt;/h2&gt;
&lt;h2 id=&#34;machine-learning-on-the-cloud-and-team-project-phase-3&#34;&gt;Machine Learning on the Cloud and Team Project Phase 3&lt;/h2&gt;
&lt;h2 id=&#34;team-project-phase-3-and-live-test&#34;&gt;Team Project Phase 3 and Live Test&lt;/h2&gt;
&lt;h2 id=&#34;stream-processing-with-kafka--samza&#34;&gt;Stream Processing with Kafka &amp;amp; Samza&lt;/h2&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~msakr/15619-s20/recitations.html&#34;&gt;https://www.cs.cmu.edu/~msakr/15619-s20/recitations.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>Introduction to Cloud Infrastructure Technologies</title>
      <link>http://www.yezheng.pro/post/specialization/cloud-computing/infrastructure/introduction-to-cloud-infrastructure-technologies/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/cloud-computing/infrastructure/introduction-to-cloud-infrastructure-technologies/</guid>
      
        <description>&lt;h2 id=&#34;chapter-1-virtualization&#34;&gt;Chapter 1. Virtualization&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-cloud-computing-and-technologies&#34;&gt;Introduction to Cloud Computing and Technologies&lt;/h4&gt;
&lt;p&gt;Historically, the word &lt;strong&gt;cloud&lt;/strong&gt; was used as a metaphor for Internet. Later on, it was used to depict the Internet in computer network diagrams. To find out more about the origin of the cloud, you can take a look at the details provided on &lt;a href=&#34;https://en.wikipedia.org/wiki/Cloud_computing#Origin_of_the_term&#34;&gt;Wikipedia&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cloud computing&lt;/strong&gt; can be referred as the allocation of resources on the cloud. According to &lt;a href=&#34;http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf&#34;&gt;NIST (National Institute of Standard and Technology)&lt;/a&gt;, the formal definition of cloud computing is the following:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;em&gt;Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g. networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction&lt;/em&gt;&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Cloud computing providers offer different kinds of services built on top of basic provisioning and releasing of resources. Most of these services fall into one of the following categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Infrastructure as a Service (IaaS)&lt;/li&gt;
&lt;li&gt;Platform as a Service (PaaS)&lt;/li&gt;
&lt;li&gt;Software as a Service (SaaS).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will cover these categories and others throughout the course. Most providers use some form of web interface, on top of which we can build the desired stack. Cloud providers use a pay-as-you-go model, in which we pay for the resources we have used in a given duration.&lt;/p&gt;
&lt;h4 id=&#34;key-features-of-cloud-computing&#34;&gt;Key Features of Cloud Computing&lt;/h4&gt;
&lt;p&gt;Cloud computing provides key features such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Speed and Agility&lt;/strong&gt;
The required resources are just one click away, which saves time and provides agility. We can also easily scale up or down, depending on our need.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cost&lt;/strong&gt;
It reduces the up-front cost to set up the infrastructure, and allows us to focus on applications and business. Cloud providers have features to estimate the cost, which helps us plan better.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Easy Access to Resources&lt;/strong&gt;
As users, we can access our infrastructure from any place and device, as long as we can connect to the provider.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maintenance&lt;/strong&gt;
All the maintenance work for the resources is done by the provider. As end users, we do not have to worry about this aspect.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-tenancy&lt;/strong&gt;
Multiple users can use the same pool of resources.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reliability&lt;/strong&gt;
Resources can be hosted in different data center locations, to provide increased reliability.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;cloud-deployment-models&#34;&gt;Cloud Deployment Models&lt;/h4&gt;
&lt;p&gt;Generally, a cloud is deployed in the following models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Private Cloud&lt;/strong&gt;
It is designated and operated solely for one organization. It can be hosted internally or externally and managed by internal teams or a third party. We can build a private cloud using a software stack like &lt;a href=&#34;https://www.openstack.org/&#34;&gt;OpenStack&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Public Cloud&lt;/strong&gt;
It is open to the public and anybody can use it after swiping the credit card. Amazon Web Services and Google Compute Engine are examples of public clouds.&lt;/li&gt;
&lt;li&gt;**Hybrid Cloud
**Public and private clouds are bound together to offer the hybrid cloud. Among other things, a hybrid cloud can be used to:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Store sensitive information on a private cloud, while offering public services based on that information from a public cloud.&lt;/li&gt;
&lt;li&gt;Meet the temporary resources needed from the public cloud. These temporary resources cannot be met from a private cloud.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://courses.edx.org/assets/courseware/v1/6f3bd09c6693af43ba9fe43d0ab1bb58/asset-v1:LinuxFoundationX+LFS151.x+2T2018+type@asset+block/Cloud_computing_types.svg&#34; alt=&#34;Cloud Computing Types&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cloud Computing Types&lt;/strong&gt;
(by Sam Johnston, licensed under &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/3.0/&#34;&gt;CC BY-SA 3.0&lt;/a&gt;, retrieved from &lt;a href=&#34;https://upload.wikimedia.org/wikipedia/commons/8/87/Cloud_computing_types.svg&#34;&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id=&#34;virtualization&#34;&gt;Virtualization&lt;/h4&gt;
&lt;p&gt;According to &lt;a href=&#34;https://en.wikipedia.org/wiki/Virtualization&#34;&gt;Wikipedia&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;In computing, virtualization refers to the act of creating a virtual (rather than actual) version of something, including virtual computer hardware platforms, operating systems, storage devices, and computer resources&amp;rdquo;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Virtualization can be offered on different hardware and software layers, like Central Processing Unit (CPU), disk, memory, filesystems, etc. In this chapter, we will look at some examples of creating virtual machines (VMs) after emulating the different kinds of hardware to install a guest OS on them.&lt;/p&gt;
&lt;p&gt;Virtual machines are created on top of a &lt;strong&gt;hypervisor&lt;/strong&gt;, which runs on top of the host machine&amp;rsquo;s operating system. With hypervisors, we emulate hardware like CPU, disk, network, memory, etc., and install guest machines on it. We can create multiple guest machines with different operating systems on a hypervisor. For example, we can take a Linux machine running on bare metal and, after setting up the hypervisor, we can create multiple guest machines with Linux and Windows operating systems. Some examples of hypervisors are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;KVM&lt;/li&gt;
&lt;li&gt;Xen&lt;/li&gt;
&lt;li&gt;VMWare&lt;/li&gt;
&lt;li&gt;VirtualBox&lt;/li&gt;
&lt;li&gt;Hyper-V.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can find support for hardware virtualization in all recent CPUs, as it is important to share the host system&amp;rsquo;s processor resources with multiple guest operating systems in a safe and efficient way. Most of the recent CPUs will also support &lt;a href=&#34;https://en.wikipedia.org/wiki/Virtualization#Nested_virtualization&#34;&gt;nested virtualization&lt;/a&gt;, which enables us to have a VM inside a VM.&lt;/p&gt;
&lt;p&gt;Next, let&amp;rsquo;s take a look at a few examples on how to create VMs on top of different hypervisors.&lt;/p&gt;
&lt;h4 id=&#34;learning-objectives&#34;&gt;Learning Objectives&lt;/h4&gt;
&lt;p&gt;By the end of this chapter, you should be able to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Describe the different types of virtualization.&lt;/li&gt;
&lt;li&gt;Explain how hypervisors can be used to create virtual machines.&lt;/li&gt;
&lt;li&gt;Create and configure virtual machines automatically, using KVM, VirtualBox and Vagrant.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kvm&#34;&gt;KVM&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-kvm&#34;&gt;Introduction to KVM&lt;/h4&gt;
&lt;p&gt;According to &lt;a href=&#34;http://www.linux-kvm.org/&#34;&gt;linux-kvm.org&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;&lt;strong&gt;KVM&lt;/strong&gt; for (Kernel-based Virtual Machine) is a full virtualization solution for Linux on x86 hardware&amp;quot;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It is part of the mainline Linux kernel. It is ported for S/390, PowerPC, IA-64 and ARM as well.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://courses.edx.org/assets/courseware/v1/5708cd4d223ce4a5313bdeccbc638cc1/asset-v1:LinuxFoundationX+LFS151.x+2T2018+type@asset+block/Kernel-based_Virtual_Machine.svg&#34; alt=&#34;A High-Level Overview of the KVM/QEMU Virtualization Environment&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A High-Level Overview of the KVM/QEMU Virtualization Environment&lt;/strong&gt;
(by V4711, licensed under &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;CC BY-SA 4.0&lt;/a&gt;, retrieved from &lt;a href=&#34;https://upload.wikimedia.org/wikipedia/commons/4/40/Kernel-based_Virtual_Machine.svg&#34;&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id=&#34;features&#34;&gt;Features&lt;/h4&gt;
&lt;p&gt;KVM is an open source software. It supports &lt;a href=&#34;http://www.linux-kvm.org/page/Guest_Support_Status&#34;&gt;various guest OSes&lt;/a&gt;, like Linux, Windows, Solaris, etc.&lt;/p&gt;
&lt;p&gt;KVM does not perform any emulation itself, but it exposes the &lt;em&gt;&lt;strong&gt;*/dev/kvm*&lt;/strong&gt;&lt;/em&gt; interface, by which an external userspace host can do emulation. &lt;a href=&#34;https://en.wikipedia.org/wiki/QEMU&#34;&gt;QEMU&lt;/a&gt; is one such host.&lt;/p&gt;
&lt;p&gt;KVM supports &lt;a href=&#34;https://www.linux-kvm.org/page/Nested_Guests&#34;&gt;nested guests&lt;/a&gt;, which allow us to run virtual machines within virtual machines. It also supports &lt;a href=&#34;https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/&#34;&gt;overcommitting&lt;/a&gt;, so that we can allocate more virtualized resources (CPUs or memory) than the available resources on the system. To do overcommitting for a VM, KVM dynamically swaps resources from another guest that is not using them.&lt;/p&gt;
&lt;h4 id=&#34;demo-creating-a-virtual-machine-instance-on-the-kvm-hypervisor&#34;&gt;Demo: Creating a Virtual Machine Instance on the KVM Hypervisor&lt;/h4&gt;
&lt;p&gt;Video&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-using-kvm&#34;&gt;Benefits of Using KVM&lt;/h4&gt;
&lt;p&gt;Some of the benefits of using KVM are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It is an open source solution, and, as such, free to customize.&lt;/li&gt;
&lt;li&gt;Using KVM is efficient from a financial perspective as well, due to the lower costs associated with it.&lt;/li&gt;
&lt;li&gt;It is highly scalable.&lt;/li&gt;
&lt;li&gt;KVM employs advanced security features, utilizing SELinux. It provides MAC (Mandatory Access Control) security between Virtual Machines. KVM has received awards for meeting common government and military security standards and for allowing open virtualization for homeland security projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;virtualbox&#34;&gt;VirtualBox&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-virtualbox&#34;&gt;Introduction to VirtualBox&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://www.virtualbox.org/&#34;&gt;VirtualBox&lt;/a&gt; is an x86 and AMD64/Intel64 virtualization product from Oracle, which runs on Windows, Linux, Macintosh, and Solaris hosts and supports &lt;a href=&#34;https://www.virtualbox.org/wiki/Guest_OSes&#34;&gt;guest OSes&lt;/a&gt; from Windows, Linux families, and others, like Solaris, FreeBSD, DOS, etc.&lt;/p&gt;
&lt;p&gt;It is an easy-to-use multi-platform hypervisor. It is not part of the mainline kernel. So, to use it on Linux, we have to compile and insert the respective kernel module.&lt;/p&gt;
&lt;p&gt;VirtualBox is distributed under the &lt;a href=&#34;https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html&#34;&gt;GNU General Public License (GPL) version 2&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;demo-creating-a-virtual-machine-instance-on-virtualbox&#34;&gt;Demo: Creating a Virtual Machine Instance on VirtualBox&lt;/h4&gt;
&lt;p&gt;video&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-using-virtualbox&#34;&gt;Benefits of Using VirtualBox&lt;/h4&gt;
&lt;p&gt;Some of the benefits of using VirtualBox are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It is an open source solution.&lt;/li&gt;
&lt;li&gt;It is free to use.&lt;/li&gt;
&lt;li&gt;It runs on Linux, Windows, OS X, and Solaris.&lt;/li&gt;
&lt;li&gt;It provides two virtualization choices: software-based virtualization and hardware-assisted virtualization.&lt;/li&gt;
&lt;li&gt;It is an easy-to-use multi-platform hypervisor.&lt;/li&gt;
&lt;li&gt;It provides the ability to run virtualized applications side-by-side with normal desktop applications.&lt;/li&gt;
&lt;li&gt;It provides teleportation - live migration.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vagrant&#34;&gt;Vagrant&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-vagrant&#34;&gt;Introduction to Vagrant&lt;/h4&gt;
&lt;p&gt;Using virtual machines in a development environment has numerous benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Reproducible environment&lt;/li&gt;
&lt;li&gt;Management of multiple projects in their restricted environment&lt;/li&gt;
&lt;li&gt;Sharing the environment with other teammates&lt;/li&gt;
&lt;li&gt;Keeping the development and deployment environments in sync&lt;/li&gt;
&lt;li&gt;Running the same VM on different OSes, with a hypervisor like VirtualBox.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Configuring and sharing one VM is easy, but, when we have to deal with multiple VMs for the same project, doing everything manually can be tiresome. &lt;a href=&#34;https://www.vagrantup.com/&#34;&gt;Vagrant&lt;/a&gt; by HashiCorp helps us automate the setup of one or more VMs by providing an end-to-end lifecycle using the &lt;strong&gt;vagrant&lt;/strong&gt; command line. Vagrant is a cross-platform tool. It can be installed on Linux, Mac OSX, and Windows. We have to use different providers, depending on the OS. It has recently added support for Docker, which can help us manage Docker containers.&lt;/p&gt;
&lt;h4 id=&#34;managing-virtual-machines-with-vagrant&#34;&gt;Managing Virtual Machines with Vagrant&lt;/h4&gt;
&lt;p&gt;Next, let&amp;rsquo;s see how Vagrant helps us manage virtual machines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;**Vagrantfile
**It is a text file with the Ruby syntax, which has all the information about configuring and provisioning a set of machines. It has details like the machine type, image, networking, provider-specific information, provisioner details, etc. We provide a sample Vagrantfile below:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;*# -*- mode: ruby -*-
*&lt;/strong&gt;&lt;/em&gt;****# vi: set ft=ruby :&lt;/p&gt;
&lt;p&gt;****&lt;em&gt;&lt;strong&gt;*Vagrant.configure(2) do |config|
*&lt;/strong&gt;&lt;/em&gt;  &lt;em&gt;&lt;strong&gt;*# Every Vagrant development environment requires a box. You can search for
*&lt;/strong&gt;&lt;/em&gt;  &lt;em&gt;&lt;strong&gt;*# boxes at &lt;a href=&#34;https://atlas.hashicorp.com/search&#34;&gt;https://atlas.hashicorp.com/search&lt;/a&gt;.
*&lt;/strong&gt;&lt;/em&gt;  &lt;em&gt;&lt;strong&gt;*config.vm.box*&lt;/strong&gt;&lt;/em&gt; ****= &amp;ldquo;centos/7&amp;rdquo;&lt;/p&gt;
&lt;p&gt;****  ****# Create a private network, which allows host-only access to the machine
****
**# using a specific IP.**
**config.vm.network &amp;ldquo;private_network&amp;rdquo;, ip: &amp;ldquo;192.168.33.10&amp;rdquo;**&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;# config.vm.synced_folder &amp;ldquo;../data&amp;rdquo;, &amp;ldquo;/vagrant_data&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;config.vm.provider &amp;ldquo;virtualbox&amp;rdquo; do |vb|&lt;/strong&gt;
&lt;strong&gt;# Customize the amount of memory on the VM:&lt;/strong&gt;
&lt;strong&gt;vb.memory = &amp;ldquo;1024&amp;rdquo;&lt;/strong&gt;
&lt;strong&gt;end&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;config.vm.provision &amp;ldquo;shell&amp;rdquo;, inline: &amp;laquo;-SHELL&lt;/strong&gt;
&lt;strong&gt;yum install vim -y&lt;/strong&gt;
&lt;strong&gt;SHELL&lt;/strong&gt;
&lt;strong&gt;end&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;&lt;strong&gt;*vagrant*&lt;/strong&gt;&lt;/em&gt; command reads the configuration given in the configuration file and does different operations, like &lt;strong&gt;up&lt;/strong&gt;, &lt;strong&gt;ssh&lt;/strong&gt;, &lt;strong&gt;destroy&lt;/strong&gt;, etc. The &lt;em&gt;&lt;strong&gt;*vagrant*&lt;/strong&gt;&lt;/em&gt; command also has sub-commands like &lt;em&gt;&lt;strong&gt;*box*&lt;/strong&gt;&lt;/em&gt; to manage Box images, &lt;strong&gt;rdp&lt;/strong&gt; to connect to VMs using Remote Desktop Protocol (RDP), etc. A detailed list of commands is available at its &lt;a href=&#34;https://www.vagrantup.com/docs/cli/&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;**Boxes
**We need to provide an image in the Vagrantfile, which we can use to instantiate machines. In the example above, we have used &lt;strong&gt;centos/7&lt;/strong&gt; as the base image. If the image is not available locally, then it can be downloaded from a central repository like &lt;a href=&#34;https://atlas.hashicorp.com/&#34;&gt;Atlas&lt;/a&gt;, which is the image repository provided by HashiCorp. We can version these images and use them depending on our need, by updating the Vagrantfile accordingly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;**Vagrant Providers
**&lt;a href=&#34;https://www.vagrantup.com/docs/providers/&#34;&gt;Providers&lt;/a&gt; are the underlying engine/hypervisor used to provision a machine. By default, Vagrant supports VirtualBox, Hyper-V and Docker. We also have custom providers, like KVM, AWS, etc. VirtualBox is the default provider.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;**Synced Folders
**With the &lt;em&gt;Synced Folder&lt;/em&gt; feature, we can sync a directory on the host system with a VM, which helps the user manage shared files/directories easily. For example, in the above example, if we un-comment the line below from Vagrantfile, then the &lt;strong&gt;../data&lt;/strong&gt; folder from the current working directory of the host system would be shared with the &lt;em&gt;&lt;strong&gt;*/vagrant_data*&lt;/strong&gt;&lt;/em&gt; file on the VM.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;*# config.vm.synced_folder &amp;ldquo;../data&amp;rdquo;, &amp;ldquo;vagrant_data&amp;rdquo;*&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Provisioning&lt;/strong&gt;
&lt;a href=&#34;https://www.vagrantup.com/docs/provisioning/&#34;&gt;Provisioners&lt;/a&gt; allow us to automatically install software, make configuration changes, etc. after the machine is booted. It is a part of the &lt;em&gt;&lt;strong&gt;*vagrant up*&lt;/strong&gt;&lt;/em&gt; process. There are many types of provisioners available, such as File, Shell, Ansible, Puppet, Chef, Docker, etc. In the example below, we used Shell as the provisioner to install the &lt;em&gt;&lt;strong&gt;*vim*&lt;/strong&gt;&lt;/em&gt; package.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;config.vm.provision &amp;ldquo;shell&amp;rdquo;, inline: &amp;laquo;-SHELL&lt;/strong&gt;
&lt;strong&gt;yum install vim -y&lt;/strong&gt;
&lt;strong&gt;SHELL&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Plugins&lt;/strong&gt;
We can use &lt;a href=&#34;https://www.vagrantup.com/docs/plugins/&#34;&gt;plugins&lt;/a&gt; to extend the functionality of Vagrant.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;demo-automating-the-creation-and-deletion-of-vms-with-vagrant&#34;&gt;Demo: Automating the Creation and Deletion of VMs with Vagrant&lt;/h4&gt;
&lt;p&gt;video&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-using-vagrant&#34;&gt;Benefits of Using Vagrant&lt;/h4&gt;
&lt;p&gt;Some of the benefits of using Vagrant are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It automates the setup of one or more VMs, which results in saved time and lower operational costs.&lt;/li&gt;
&lt;li&gt;It is a cross-platform tool.&lt;/li&gt;
&lt;li&gt;It provides support for Docker, thus helping us manage Docker containers.&lt;/li&gt;
&lt;li&gt;It is easy to install.&lt;/li&gt;
&lt;li&gt;It is very useful in multi-developer teams.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;chapter-2-infrastructure-as-a-service-iaas&#34;&gt;Chapter 2. Infrastructure as a Service (IaaS)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-1&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Infrastructure as a Service&lt;/strong&gt; (&lt;strong&gt;IaaS&lt;/strong&gt;) is a form of cloud computing which provides on-demand physical and virtual computing resources, storage, network, firewall, load balancers, etc. To provide virtual computing resources, IaaS uses some form of hypervisor, like Xen, KVM, VMware ESX/ESXi, Hyper-V, etc.&lt;/p&gt;
&lt;p&gt;Infrastructure as a Service is the backbone of all cloud services, providing the compute resources. After getting the compute resources, we provide other services on top of that.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Example:&lt;/em&gt;
Let&amp;rsquo;s say that you want to have a set of ten Linux systems with 4GB RAM each, and two Windows systems with 8GB each to deploy your software. You can go to any of the IaaS providers and request these systems. Generally, a IaaS provider creates the respective VMs in the background, puts them in the same internal network, and shares the credentials with you, thus allowing you to access them. Other than VMs, some IaaS providers offer bare metal machines for provisioning.&lt;/p&gt;
&lt;p&gt;In this chapter, we will take a closer look at some of the IaaS providers and their features. We will also provide a demo video for each one of them.&lt;/p&gt;
&lt;h4 id=&#34;learning-objectives-1&#34;&gt;Learning Objectives&lt;/h4&gt;
&lt;p&gt;By the end of this chapter, you should be able to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Explain the concept of Infrastructure as a Service (IaaS).&lt;/li&gt;
&lt;li&gt;Distinguish between different IaaS providers.&lt;/li&gt;
&lt;li&gt;Provision a virtual machine on top of different IaaS providers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;amazon-ec2&#34;&gt;Amazon EC2&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-amazon-ec2&#34;&gt;Introduction to Amazon EC2&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt;Amazo&lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt;n&lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt; &lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt;Web&lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt; Ser&lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/&#34;&gt;vices&lt;/a&gt; (&lt;strong&gt;AWS&lt;/strong&gt;) is one of the leaders in providing different cloud services. With &lt;a href=&#34;https://aws.amazon.com/ec2/&#34;&gt;Am&lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/ec2/&#34;&gt;azon&lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/ec2/&#34;&gt; Elastic&lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/ec2/&#34;&gt; &lt;/a&gt;&lt;a href=&#34;https://aws.amazon.com/ec2/&#34;&gt;Compute&lt;/a&gt;, Amazon provides the IaaS infrastructure, on which most of the other services are built. We can manage compute resources from the Amazon EC2 web interface and can scale up or down, depending on the need. AWS also &lt;a href=&#34;https://aws.amazon.com/cli/&#34;&gt;offers a command line&lt;/a&gt; to manage the instances from the command line.&lt;/p&gt;
&lt;p&gt;Amazon EC2 uses XEN and KVM hypervisors to provision compute resources.&lt;/p&gt;
&lt;h4 id=&#34;features-and-tools&#34;&gt;Features and Tools&lt;/h4&gt;
&lt;p&gt;Amazon EC2 offers compute instances for different resources, which we can choose from depending on our need. Some examples of instances offered are the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;*t2.nano*&lt;/strong&gt;&lt;/em&gt;: 512 MiB of memory, 1 vCPU, 3 CPU Credits/hour, EBS-only, 32-bit or 64-bit platform&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;*c4.large*&lt;/strong&gt;&lt;/em&gt;: 3.75 GiB of memory, 2 vCPUs, 64-bit platform&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;*d2.8xlarge*&lt;/strong&gt;&lt;/em&gt;: 244 GiB of memory, 36 vCPUs, 24 x 2000 GB of HDD-based instance storage, 64-bit platform, 10 Gigabit Ethernet.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Amazon EC2 provides some preconfigured images, called Amazon Machine Images (AMIs). These images can be used to quickly start instances. We can also create our own custom AMIs to boot our instances.&lt;/p&gt;
&lt;p&gt;One important aspect to note is that Amazon supports configuring security and network access to our instances.&lt;/p&gt;
&lt;p&gt;With Amazon Elastic Block Store (EBS) we can attach/detach persistent storage to our instances.&lt;/p&gt;
&lt;p&gt;EC2 supports the provisioning of dedicated hosts, which means we can get an entire physical machine for our use.&lt;/p&gt;
&lt;p&gt;Amazon EC2 has many other features, allowing you to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Create an Elastic IP for remapping the Static IP address automatically&lt;/li&gt;
&lt;li&gt;Provision a Virtual Private Cloud for isolation. Amazon Virtual Private Cloud provides secure and robust networking for Amazon EC2 instances&lt;/li&gt;
&lt;li&gt;Use CloudWatch for monitoring resources and applications&lt;/li&gt;
&lt;li&gt;Use Auto Scaling to dynamically resize your resources, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;demo-creating-and-destroying-an-instance-using-amazon-ec2-compute-service&#34;&gt;Demo: Creating and Destroying an Instance using Amazon EC2 Compute Service&lt;/h4&gt;
&lt;p&gt;video&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-using-amazon-ec2&#34;&gt;Benefits of Using Amazon EC2&lt;/h4&gt;
&lt;p&gt;Some of the benefits of using Amazon EC2 are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It is an easy-to-use IaaS solution.&lt;/li&gt;
&lt;li&gt;It is flexible and scalable.&lt;/li&gt;
&lt;li&gt;It provides a secure and robust functionality for your compute resources.&lt;/li&gt;
&lt;li&gt;It enables automation.&lt;/li&gt;
&lt;li&gt;It is cost-effective: you only pay for the time and resources you use.&lt;/li&gt;
&lt;li&gt;It is designed to work in conjunction with other AWS components.&lt;/li&gt;
&lt;li&gt;It promises 99.99% uptime.&lt;/li&gt;
&lt;li&gt;It provides specialized instances for workloads, such as floating point operations, high graphics capability, high input/output (I/O), High Performance Computing (HPC), etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;azure-virtual-machine&#34;&gt;Azure Virtual Machine&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-azure-virtual-machine&#34;&gt;Introduction to Azure Virtual Machine&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/&#34;&gt;Azure&lt;/a&gt; is Microsoft&amp;rsquo;s cloud offering, which has products in different domains, such as compute, web and mobile, data and storage, Internet of Things, and many others. Through &lt;strong&gt;Azure Virtual Machine&lt;/strong&gt;, Microsoft provides compute provisioning and management:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;We can manage Virtual Machines from Azure&amp;rsquo;s web interface.&lt;/li&gt;
&lt;li&gt;Azure also provides a &lt;a href=&#34;https://github.com/azure/azure-xplat-cli&#34;&gt;command line utility&lt;/a&gt; to manage resources and applications on the Azure cloud.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;features-and-tools-1&#34;&gt;Features and Tools&lt;/h4&gt;
&lt;p&gt;Azure lets you choose between different tiers, based on the usage and the operating systems or the predefined application virtual machines (SharePoint, Oracle, etc.). To learn more, please take a look at the &lt;a href=&#34;https://azure.microsoft.com/en-in/pricing/details/virtual-machines/linux/&#34;&gt;Linux Virtual Machines Pricing&lt;/a&gt; web page. You can choose to pay as you go or get better pricing by reserving instances for one or three years.&lt;/p&gt;
&lt;p&gt;Using Resource Manager templates, we can define the template for the virtual machine deployment.&lt;/p&gt;
&lt;p&gt;Azure offers other features as well, like making seamless hybrid connections, faster I/O in certain types of tiers, backups, etc.&lt;/p&gt;
&lt;h4 id=&#34;demo-creating-a-virtual-machine-instance-on-microsoft-azure&#34;&gt;Demo: Creating a Virtual Machine Instance on Microsoft Azure&lt;/h4&gt;
&lt;p&gt;video&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-using-azure-virtual-machine&#34;&gt;Benefits of Using Azure Virtual Machine&lt;/h4&gt;
&lt;p&gt;Some of the benefits of using Azure virtual machine are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It is an easy-to-use IaaS solution.&lt;/li&gt;
&lt;li&gt;It is flexible and scalable.&lt;/li&gt;
&lt;li&gt;It provides a secure and robust functionality for your compute resources.&lt;/li&gt;
&lt;li&gt;It enables automation.&lt;/li&gt;
&lt;li&gt;It is cost-effective: you only pay for the time and resources you use.&lt;/li&gt;
&lt;li&gt;It is designed to work in conjunction with other Azure services.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;digitalocean&#34;&gt;DigitalOcean&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-digitalocean&#34;&gt;Introduction to DigitalOcean&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;DigitalOcean&lt;/a&gt; helps you create a simple cloud quickly, in as little as 55 seconds. All of the VMs are created on top of the KVM hypervisor and have SSD (Solid-State Drive) as the primary disk.&lt;/p&gt;
&lt;h4 id=&#34;features-and-tools-2&#34;&gt;Features and Tools&lt;/h4&gt;
&lt;p&gt;Based on your need, DigitalOcean offers &lt;a href=&#34;https://www.digitalocean.com/pricing/&#34;&gt;different plans&lt;/a&gt;. Some examples of plan offerings are listed below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;2GB Memory, 2 Core Processor, 60 GB SSD Disk, 3 TB transfer&lt;/li&gt;
&lt;li&gt;48GB Memory, 12 Core Processor, 960 GB SSD Disk, 8 TB transfer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DigitalOcean provides other features, like Floating IPs, Shared Private Networking, Load Balancers, Team Accounts, etc.&lt;/p&gt;
&lt;h4 id=&#34;demo-creating-a-virtual-machine-on-digitalocean&#34;&gt;Demo: Creating a Virtual Machine on DigitalOcean&lt;/h4&gt;
&lt;p&gt;video&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-using-digitalocean&#34;&gt;Benefits of Using DigitalOcean&lt;/h4&gt;
&lt;p&gt;Some of the benefits of using DigitalOcean are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It allows you to configure a cloud in as little as 55 seconds.&lt;/li&gt;
&lt;li&gt;It is flexible and scalable.&lt;/li&gt;
&lt;li&gt;It provides a high level of security by using KVM virtualized droplets.&lt;/li&gt;
&lt;li&gt;It enables automation.&lt;/li&gt;
&lt;li&gt;It is cost-effective: you only pay for the time and resources you use.&lt;/li&gt;
&lt;li&gt;It is focused on providing a simple, user-friendly experience.&lt;/li&gt;
&lt;li&gt;It uses high-performance Solid State Disks.&lt;/li&gt;
&lt;li&gt;It offers a one-click installation of a multitude of application stacks like LAMP, LEMP, MEAN, and Docker.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;google-compute-engine&#34;&gt;Google Compute Engine&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-google-compute-engine&#34;&gt;Introduction to Google Compute Engine&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/&#34;&gt;Google Cloud Platform&lt;/a&gt; is Google&amp;rsquo;s Cloud offering, which has many products in different domains, like compute, storage, networking, big data, and others. &lt;a href=&#34;https://cloud.google.com/compute/&#34;&gt;Google Compute Engine&lt;/a&gt; provides the compute service. We can manage the instances through GUI, APIs or &lt;a href=&#34;https://cloud.google.com/sdk/gcloud/&#34;&gt;command line&lt;/a&gt;. Access to the individual VM&amp;rsquo;s console is also available.&lt;/p&gt;
&lt;h4 id=&#34;features-and-tools-3&#34;&gt;Features and Tools&lt;/h4&gt;
&lt;p&gt;GCE supports different &lt;a href=&#34;https://cloud.google.com/compute/docs/machine-types&#34;&gt;machine types&lt;/a&gt;, which we can choose from depending on our need. They are categorized in the following types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Standard machine types&lt;/li&gt;
&lt;li&gt;High-CPU machine types&lt;/li&gt;
&lt;li&gt;High-memory machine types&lt;/li&gt;
&lt;li&gt;Shared-core machine types&lt;/li&gt;
&lt;li&gt;We can also configure custom machine types.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GCE has other features as well, like Persistent Disk, Local SSD, Global Load Balancing, Compliance and Security, Automatic Discount, etc.&lt;/p&gt;
&lt;h4 id=&#34;demo-creating-and-destroying-an-instance-on-google-compute-engine&#34;&gt;Demo: Creating and Destroying an Instance on Google Compute Engine&lt;/h4&gt;
&lt;p&gt;video&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-using-google-compute-engine&#34;&gt;Benefits of Using Google Compute Engine&lt;/h4&gt;
&lt;p&gt;Some of the benefits of using Google Compute Engine are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It is flexible and allows you to scale your applications easily.&lt;/li&gt;
&lt;li&gt;Fast boot time.&lt;/li&gt;
&lt;li&gt;It is very secure, encrypting all data stored.&lt;/li&gt;
&lt;li&gt;It enables automation.&lt;/li&gt;
&lt;li&gt;It is cost-effective: you only pay for the time and resources you use.&lt;/li&gt;
&lt;li&gt;It supports custom machine types.&lt;/li&gt;
&lt;li&gt;It supports Virtual Private Cloud, Load Balancers, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;openstack&#34;&gt;OpenStack&lt;/h3&gt;
&lt;h4 id=&#34;introduction-to-openstack&#34;&gt;Introduction to OpenStack&lt;/h4&gt;
&lt;p&gt;Earlier in this chapter, we have seen examples for consuming the services of different cloud providers to provision our infrastructure. What if we want to become a cloud provider and offer cloud computing services?&lt;/p&gt;
&lt;p&gt;With &lt;a href=&#34;https://www.openstack.org/&#34;&gt;OpenStack&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; we can offer a cloud computing platform for public and private clouds. OpenStack was started as a joint project between &lt;a href=&#34;https://www.rackspace.com/&#34;&gt;Rackspace&lt;/a&gt; and &lt;a href=&#34;http://www.nasa.gov/&#34;&gt;NASA&lt;/a&gt; in 2010. In 2012, a non-profit corporate entity, called the OpenStack Foundation, was formed and it is managing it since then. It is now supported by more than 500 organizations. OpenStack is an open source software platform, which is released under an &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Other than providing a IaaS solution, OpenStack has evolved over time to provide other services, like Database, Storage, etc.&lt;/p&gt;
&lt;h4 id=&#34;componentsfeatures&#34;&gt;Components/Features&lt;/h4&gt;
&lt;p&gt;Due to the modular nature of OpenStack, anyone can add additional components to get specific features or functionality. Some of the major OpenStack components are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/keystone/&#34;&gt;Keystone&lt;/a&gt;
Provides Identity, Token, Catalog, and Policy services to projects.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/nova/&#34;&gt;Nova&lt;/a&gt;
Provides on-demand compute resources.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/horizon/&#34;&gt;Horizon&lt;/a&gt;
Provides the Dashboard, which is a web-based user interface to manage the OpenStack service.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/neutron/&#34;&gt;Neutron&lt;/a&gt;
Implements the network as a service and provides network capabilities to different OpenStack components.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/glance/&#34;&gt;Glance&lt;/a&gt;
Provides a service where users can upload and discover data assets, like images and metadata.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/swift/&#34;&gt;Swift&lt;/a&gt;
Provides a highly available, distributed, eventually consistent object/blob store.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/cinder/&#34;&gt;Cinder&lt;/a&gt;
Provides block storage as a service.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/heat/&#34;&gt;Heat&lt;/a&gt;
Provides a service to orchestrate composite cloud applications, using a declarative template format through an OpenStack-native REST API.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.openstack.org/developer/ceilometer/&#34;&gt;Ceilometer&lt;/a&gt;
It is part of the Telemetry project and provides data collection services for billing and other purposes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of the OpenStack components is also modular by design. For example, with Nova we can select an underneath hypervisor depending on the requirement, which can be either libvirt (qemu/KVM), Hyper-V, VMware, XenServer, Xen via libvirt.&lt;/p&gt;
&lt;h4 id=&#34;demo-deploying-an-instance-with-openstack&#34;&gt;Demo: Deploying an Instance with OpenStack&lt;/h4&gt;
&lt;p&gt;video&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-using-openstack&#34;&gt;Benefits of Using OpenStack&lt;/h4&gt;
&lt;p&gt;Some of the benefits of using OpenStack are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;It is an open source solution.&lt;/li&gt;
&lt;li&gt;It is a cloud computing platform for public and private clouds.&lt;/li&gt;
&lt;li&gt;It offers a flexible, customizable, vendor-neutral environment.&lt;/li&gt;
&lt;li&gt;It provides a high level of security.&lt;/li&gt;
&lt;li&gt;It facilitates automation throughout the stages of the cloud lifecycle.&lt;/li&gt;
&lt;li&gt;By reducing system management overhead and avoiding vendor lock-in, it can be cost-effective.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;chapter-3-platform-as-a-service-paas&#34;&gt;Chapter 3. Platform as a Service (PaaS)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-2&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h4 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Platform as a Service&lt;/strong&gt; (&lt;strong&gt;PaaS&lt;/strong&gt;) is a class of cloud computing services which allows its users to develop, run, and manage applications without worrying about the underlying infrastructure. With PaaS, users can simply focus on building their applications, which is a great help to developers.&lt;/p&gt;
&lt;p&gt;We can either use PaaS services offered by different cloud computing providers like Amazon, Google, Azure, etc., or deploy it on-premise, using software like OpenShift Origin.&lt;/p&gt;
&lt;p&gt;PaaS can be deployed on top of IaaS, or, independently on VMs, bare metal, and containers.&lt;/p&gt;
&lt;p&gt;In this chapter, we will take a closer look at some of the PaaS providers and their features. We will also provide a demo video for each one of them.&lt;/p&gt;
&lt;h3 id=&#34;cloud-foundry&#34;&gt;Cloud Foundry&lt;/h3&gt;
&lt;h3 id=&#34;openshift&#34;&gt;Openshift&lt;/h3&gt;
&lt;h3 id=&#34;the-heroku-platform&#34;&gt;The Heroku Platform&lt;/h3&gt;
&lt;h2 id=&#34;chapter-4-containers&#34;&gt;Chapter 4. Containers&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-3&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;containers&#34;&gt;Containers&lt;/h3&gt;
&lt;h3 id=&#34;project-moby&#34;&gt;Project Moby&lt;/h3&gt;
&lt;h2 id=&#34;chapter-5-containers-micro-oses-for-containers&#34;&gt;Chapter 5. Containers: Micro OSes for Containers&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-4&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;atomic-host-and-red-hat-coreos&#34;&gt;Atomic Host and Red Hat CoreOS&lt;/h3&gt;
&lt;h3 id=&#34;vmware-photon&#34;&gt;VMWare Photon&lt;/h3&gt;
&lt;h3 id=&#34;rancheros&#34;&gt;RancherOS&lt;/h3&gt;
&lt;h2 id=&#34;chapter-6-containers-container-orchestration&#34;&gt;Chapter 6. Containers: Container Orchestration&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-5&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;docker-swarm&#34;&gt;Docker Swarm&lt;/h3&gt;
&lt;h3 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h3&gt;
&lt;h3 id=&#34;deploying-containers-with-mesos&#34;&gt;Deploying Containers with Mesos&lt;/h3&gt;
&lt;h3 id=&#34;nomad-by-hashicorp&#34;&gt;Nomad by HashiCorp&lt;/h3&gt;
&lt;h3 id=&#34;kubernetes-hosted-solutions&#34;&gt;Kubernetes Hosted Solutions&lt;/h3&gt;
&lt;h3 id=&#34;amazon-ecs&#34;&gt;Amazon ECS&lt;/h3&gt;
&lt;h2 id=&#34;chapter-7-unikernels&#34;&gt;Chapter 7. Unikernels&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-6&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;unikernels&#34;&gt;Unikernels&lt;/h3&gt;
&lt;h2 id=&#34;chapter-8-microservices&#34;&gt;Chapter 8. Microservices&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-7&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;microservices&#34;&gt;Microservices&lt;/h3&gt;
&lt;h2 id=&#34;chapter-9-software-defined-networking-and-networking-for-containers&#34;&gt;Chapter 9. Software-Defined Networking and Networking for Containers&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-8&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;software-defined-networking-sdn&#34;&gt;Software-Defined Networking (SDN)&lt;/h3&gt;
&lt;h3 id=&#34;networking-for-containers&#34;&gt;Networking for Containers&lt;/h3&gt;
&lt;h3 id=&#34;docker-single-host-networking&#34;&gt;Docker Single-Host Networking&lt;/h3&gt;
&lt;h3 id=&#34;docker-multi-host-networking&#34;&gt;Docker Multi-Host Networking&lt;/h3&gt;
&lt;h3 id=&#34;docker-network-driver-plugins&#34;&gt;Docker Network Driver Plugins&lt;/h3&gt;
&lt;h3 id=&#34;kubernetes-networking&#34;&gt;Kubernetes Networking&lt;/h3&gt;
&lt;h3 id=&#34;cloud-foundry-container-to-container-networking&#34;&gt;Cloud Foundry: Container to Container Networking&lt;/h3&gt;
&lt;h2 id=&#34;chapter-10-software-defined-storage-and-storage-management-for-containers&#34;&gt;Chapter 10. Software-Defined Storage and Storage Management for Containers&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-9&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;ceph&#34;&gt;Ceph&lt;/h3&gt;
&lt;h3 id=&#34;glusterfs&#34;&gt;GlusterFS&lt;/h3&gt;
&lt;h3 id=&#34;storage-management-for-containers&#34;&gt;Storage Management for Containers&lt;/h3&gt;
&lt;h3 id=&#34;volume-plugins-for-docker&#34;&gt;Volume Plugins for Docker&lt;/h3&gt;
&lt;h3 id=&#34;volume-management-in-kubernetes&#34;&gt;Volume Management in Kubernetes&lt;/h3&gt;
&lt;h3 id=&#34;container-storage-interface-csi&#34;&gt;Container Storage Interface (CSI)&lt;/h3&gt;
&lt;h3 id=&#34;cloud-foundry-volume-service&#34;&gt;Cloud Foundry Volume Service&lt;/h3&gt;
&lt;h2 id=&#34;chapter-11-devops-and-cicd&#34;&gt;Chapter 11. DevOps and CI/CD&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-10&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;cicd-jenkins&#34;&gt;CI/CD: Jenkins&lt;/h3&gt;
&lt;h3 id=&#34;cicd-travis-ci&#34;&gt;CI/CD: Travis CI&lt;/h3&gt;
&lt;h3 id=&#34;cicd-shippable&#34;&gt;CI/CD Shippable&lt;/h3&gt;
&lt;h3 id=&#34;cicd-concourse&#34;&gt;CI/CD: Concourse&lt;/h3&gt;
&lt;h3 id=&#34;cloud-native-cicd&#34;&gt;Cloud Native CI/CD&lt;/h3&gt;
&lt;h2 id=&#34;chapter-12-tools-for-cloud-infrastructure-i-configuration-management&#34;&gt;Chapter 12. Tools for Cloud Infrastructure I (Configuration Management)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-11&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;ansible&#34;&gt;Ansible&lt;/h3&gt;
&lt;h3 id=&#34;puppet&#34;&gt;Puppet&lt;/h3&gt;
&lt;h3 id=&#34;chef&#34;&gt;Chef&lt;/h3&gt;
&lt;h3 id=&#34;salt-open&#34;&gt;Salt Open&lt;/h3&gt;
&lt;h2 id=&#34;chapter-13-tools-for-cloud-infrastructure-ii-build--release&#34;&gt;Chapter 13. Tools for Cloud Infrastructure II (Build &amp;amp; Release)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-12&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;terraform&#34;&gt;Terraform&lt;/h3&gt;
&lt;h3 id=&#34;bosh&#34;&gt;BOSH&lt;/h3&gt;
&lt;h2 id=&#34;chapter-14-tools-for-cloud-infrastructure-iii-key-value-pair-store&#34;&gt;Chapter 14. Tools for Cloud Infrastructure III (Key-Value Pair Store)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-13&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;etcd&#34;&gt;etcd&lt;/h3&gt;
&lt;h3 id=&#34;consul&#34;&gt;Consul&lt;/h3&gt;
&lt;h2 id=&#34;chapter-15-tools-for-cloud-infrastructure-iv-image-building&#34;&gt;Chapter 15. Tools for Cloud Infrastructure IV (Image Building)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-14&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;building-docker-images&#34;&gt;Building Docker Images&lt;/h3&gt;
&lt;h3 id=&#34;packer&#34;&gt;Packer&lt;/h3&gt;
&lt;h2 id=&#34;chapter-16-tools-for-cloud-infrastructure-v-debugging-logging-and-monitoring-for-containerized-applications&#34;&gt;Chapter 16. Tools for Cloud Infrastructure V (Debugging, Logging, and Monitoring for Containerized Applications)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-15&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;sysdig&#34;&gt;Sysdig&lt;/h3&gt;
&lt;h3 id=&#34;cadvisor-and-heapster&#34;&gt;cAdvisor and Heapster&lt;/h3&gt;
&lt;h3 id=&#34;fluentd&#34;&gt;Fluentd&lt;/h3&gt;
&lt;h3 id=&#34;datadog&#34;&gt;Datadog&lt;/h3&gt;
&lt;h3 id=&#34;prometheus&#34;&gt;Prometheus&lt;/h3&gt;
&lt;h2 id=&#34;chapter-17-service-mash&#34;&gt;Chapter 17. Service Mash&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-16&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;features-and-implementation-of-service-mash&#34;&gt;Features and Implementation of Service Mash&lt;/h3&gt;
&lt;h3 id=&#34;envoy&#34;&gt;Envoy&lt;/h3&gt;
&lt;h3 id=&#34;istio&#34;&gt;Istio&lt;/h3&gt;
&lt;h3 id=&#34;linkerd&#34;&gt;Linkerd&lt;/h3&gt;
&lt;h2 id=&#34;chapter-18-internet-of-things-iot&#34;&gt;Chapter 18. Internet of Things (IoT)&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-17&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;internet-of-things&#34;&gt;Internet of Things&lt;/h3&gt;
&lt;h2 id=&#34;chapter-19-serverless-computing&#34;&gt;Chapter 19. Serverless Computing&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-18&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;serverless-computing&#34;&gt;Serverless Computing&lt;/h3&gt;
&lt;h3 id=&#34;aws-lambda&#34;&gt;AWS Lambda&lt;/h3&gt;
&lt;h3 id=&#34;google-cloud-functions&#34;&gt;Google Cloud Functions&lt;/h3&gt;
&lt;h3 id=&#34;azure-functions&#34;&gt;Azure Functions&lt;/h3&gt;
&lt;h3 id=&#34;serverless-and-containers&#34;&gt;Serverless and Containers&lt;/h3&gt;
&lt;h2 id=&#34;chapter-20-opentracing&#34;&gt;Chapter 20. OpenTracing&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-19&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;opentracing&#34;&gt;OpenTracing&lt;/h3&gt;
&lt;h3 id=&#34;jaeger&#34;&gt;Jaeger&lt;/h3&gt;
&lt;h2 id=&#34;chapter-21-how-to-be-successful-in-the-cloud&#34;&gt;Chapter 21. How to Be Successful in the Cloud&lt;/h2&gt;
&lt;h3 id=&#34;introduction-and-learning-objectives-20&#34;&gt;Introduction and Learning Objectives&lt;/h3&gt;
&lt;h3 id=&#34;developing-skills&#34;&gt;Developing Skills&lt;/h3&gt;
&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;
</description>
      
    </item>
    
    <item>
      <title>The Java 3rd Library</title>
      <link>http://www.yezheng.pro/post/engineering-fundamentals/java/the-java-3rd-party-library/</link>
      <pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/engineering-fundamentals/java/the-java-3rd-party-library/</guid>
      
        <description>&lt;p&gt;import org.alibaba.fastjson.JSONArray;
import org.alibaba.fastjson.JSONObject;
import com.amazonaws.Request;
import com.amazonaws.utils.StringUtils;
import com.atomikos.datasource.xa.StringUtils;&lt;/p&gt;
&lt;p&gt;import com.fasterxml.jackson.core.JsonParseException;
import com.fasterxml.jackson.annotation.JsonFormat;
import com.fasterxml.jackson.core.io.JsonStringEncoder;
import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.JavaType;
import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.JsonMappingException;
import com.fasterxml.jackson.databind.ObjectMapper;&lt;/p&gt;
&lt;p&gt;import com.google.common.cache.CacheBuilder;
import com.google.common.cache.CacheLoader;
import com.google.common.cache.LoadingCache;&lt;/p&gt;
&lt;p&gt;import com.google.gson.Gson;&lt;/p&gt;
&lt;p&gt;import com.ibm.db2.jcc.am.re;&lt;/p&gt;
&lt;p&gt;import com.jayway.restassured.RestAssured;
import com.jayway.restassured.path.json.JsonPath;
import com.jayway.restassured.config.RestAssuredconfig;
import com.jayway.restassured.response.Response;
import com.jayway.restassured.response.ValidatableResponse;
import com.jayway.restassured.specification.RequestSpecification;&lt;/p&gt;
&lt;p&gt;import freemarker.template.Template;
import freemarker.template.TemplateException;&lt;/p&gt;
&lt;p&gt;import groovy.json.internal.JsonFastParser;
import groovy.json.internal.ValueMap;&lt;/p&gt;
&lt;p&gt;import org.apache.ws.security.WSSecurityException;
import org.apache.ws.security.util.Base64;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;net.sf.json
&lt;ul&gt;
&lt;li&gt;JSONArray&lt;/li&gt;
&lt;li&gt;JSONNull&lt;/li&gt;
&lt;li&gt;JSONObject&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;org.activiti.engine
&lt;a href=&#34;https://blog.csdn.net/fanxiangru999/article/details/79381966?utm_medium=distribute.wap_relevant.none-task-blog-baidulandingword-1&#34;&gt;https://blog.csdn.net/fanxiangru999/article/details/79381966?utm_medium=distribute.wap_relevant.none-task-blog-baidulandingword-1&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;commons
&lt;ul&gt;
&lt;li&gt;beanutils
&lt;ul&gt;
&lt;li&gt;BeanUtils;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;collection
&lt;ul&gt;
&lt;li&gt;CollectionUtils&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;collections
&lt;ul&gt;
&lt;li&gt;CollectionUtils&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;httpclient
&lt;ul&gt;
&lt;li&gt;DefaultHttpMethodRetryHandler&lt;/li&gt;
&lt;li&gt;HttpClient;&lt;/li&gt;
&lt;li&gt;HttpException&lt;/li&gt;
&lt;li&gt;HttpMethod;&lt;/li&gt;
&lt;li&gt;HttpStatus;&lt;/li&gt;
&lt;li&gt;NameValuePair;&lt;/li&gt;
&lt;li&gt;UsernamePasswordCredentials&lt;/li&gt;
&lt;li&gt;URIException;&lt;/li&gt;
&lt;li&gt;methods
&lt;ul&gt;
&lt;li&gt;GetMethod;&lt;/li&gt;
&lt;li&gt;PostMethod;&lt;/li&gt;
&lt;li&gt;PutMehod&lt;/li&gt;
&lt;li&gt;RequestEntity&lt;/li&gt;
&lt;li&gt;StringRequestEntity;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;.HttpConnectionManagerParams;&lt;/li&gt;
&lt;li&gt;params.
&lt;ul&gt;
&lt;li&gt;HttpMethodParams;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;io
&lt;ul&gt;
&lt;li&gt;FileUtils&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lang
&lt;ul&gt;
&lt;li&gt;ClassUtils;&lt;/li&gt;
&lt;li&gt;StringUtils;&lt;/li&gt;
&lt;li&gt;EqualsBuilder&lt;/li&gt;
&lt;li&gt;HashCodeBuilder&lt;/li&gt;
&lt;li&gt;time
&lt;ul&gt;
&lt;li&gt;DateUtils&lt;/li&gt;
&lt;li&gt;StopWatch&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;lang3
&lt;ul&gt;
&lt;li&gt;BooleanUtils&lt;/li&gt;
&lt;li&gt;StringUtils&lt;/li&gt;
&lt;li&gt;time
&lt;ul&gt;
&lt;li&gt;DateFormatUtils&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;org.apache.http.client.HttpClient使用方法
一.org.apache.commons&lt;/p&gt;
&lt;p&gt;import org.springframework.beans.factory.DisposableBean;
import org.springframework.beans.factory.InitializingBean;&lt;/p&gt;
&lt;p&gt;import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Propagation;
import org.springframework.transaction.annotation.Transactional;&lt;/p&gt;
&lt;p&gt;import org.springframework.transaction.PlatformTransactionManager;
import org.springframework.transaction.TransactionDefinition;
import org.springframework.transaction.TransactionStatus;
import org.springframework.transaction.annotation.Propagation;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.transaction.support.DefaultTransactionDefinition;&lt;/p&gt;
&lt;p&gt;import org.springframework.core.io.Resource;
import org.springframework.core.io.support.PathMatchingResourcePatternResolver;
import org.springframework.core.io.support.ResourcePatternResolver;&lt;/p&gt;
&lt;p&gt;import org.springframework.util.ClassUtils;&lt;/p&gt;
&lt;p&gt;import org.springframework.util.Assert;
import org.springframework.util.CollectionUtils;
import org.springframework.util.ReflectionUtils;
import org.springframework.util.StringUtils;&lt;/p&gt;
&lt;p&gt;import org.apache.ibatis.annotations.Param;
session.Configuration
Session.SqlsessionFactory&lt;/p&gt;
&lt;p&gt;org.apache.http
org.apache.commons.dbcp2
org.apache.commons.collections&lt;/p&gt;
&lt;p&gt;fastjson
mysql-connector-java
liquibase-core
liquibase-maven-plugin
commons.dbcp
commons.collections
commons-lang3
import org.apache.commons.lang.StringUtils;
jedis&lt;/p&gt;
&lt;p&gt;junit
dbunit
spring-test-dbunit
spring-test
spring-boot-starter-test&lt;/p&gt;
&lt;p&gt;disruptor&lt;/p&gt;
&lt;p&gt;cxf-spring-boot-starter-jaxrs
cxf-spring-boot-starter-jaxws
cxf-rt-rs-service-description-swagger
swagger-ui&lt;/p&gt;
&lt;p&gt;aaa&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>The Java Standard Library</title>
      <link>http://www.yezheng.pro/post/engineering-fundamentals/java/the-java-standard-library/</link>
      <pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/engineering-fundamentals/java/the-java-standard-library/</guid>
      
        <description>&lt;h2 id=&#34;collections&#34;&gt;Collections&lt;/h2&gt;
&lt;h3 id=&#34;interfaces&#34;&gt;Interfaces&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://docs.oracle.com/javase/tutorial/figures/collections/colls-coreInterfaces.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note that all the core collection interfaces are generic. For example, this is the declaration of the &lt;code&gt;Collection&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public interface Collection&amp;lt;E&amp;gt;...
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;the-collection-interface&#34;&gt;The Collection Interface&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;String&amp;gt;(c);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;Collection&lt;/code&gt; interface contains methods that perform basic operations, such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;int size()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolean isEmpty()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolean contains(Object element)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolean add(E element)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolean remove(Object element)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Iterator&amp;lt;E&amp;gt; iterator()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It also contains methods that operate on entire collections, such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;boolean containsAll(Collection&amp;lt;?&amp;gt; c)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolean addAll(Collection&amp;lt;? extends E&amp;gt; c)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolean removeAll(Collection&amp;lt;?&amp;gt; c)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolean retainAll(Collection&amp;lt;?&amp;gt; c)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;void clear()&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional methods for &lt;strong&gt;array&lt;/strong&gt; operations (such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Object[] toArray()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;T&amp;gt; T[] toArray(T[] a)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;obtaining sequential or parallel streams from the underlying collection.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Stream&amp;lt;E&amp;gt; stream()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Stream&amp;lt;E&amp;gt; parallelStream()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;traversing-collections&#34;&gt;Traversing Collections&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Aggregate Operations&lt;/p&gt;
&lt;p&gt;Aggregate operations are often used in conjunction with lambda expressions to make programming more expressive, using less lines of code.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;myShapesCollection.stream()
.filter(e -&amp;gt; e.getColor() == Color.RED)
.forEach(e -&amp;gt; System.out.println(e.getName()));
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;myShapesCollection.parallelStream()
.filter(e -&amp;gt; e.getColor() == Color.RED)
.forEach(e -&amp;gt; System.out.println(e.getName()));
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;String joined = elements.stream()
.map(Object::toString)
.collect(Collectors.joining(&amp;quot;, &amp;quot;));
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for-each Construct&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for (Object o : collection)
    System.out.println(o);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Iterators&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static void filter(Collection&amp;lt;?&amp;gt; c) {
    for (Iterator&amp;lt;?&amp;gt; it = c.iterator(); it.hasNext(); )
        if (!cond(it.next()))
            it.remove();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;collection-interface-bulk-operations&#34;&gt;Collection Interface Bulk Operations&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;containsAll&lt;/code&gt; — returns &lt;code&gt;true&lt;/code&gt; if the target &lt;code&gt;Collection&lt;/code&gt; contains all of the elements in the specified &lt;code&gt;Collection&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;addAll&lt;/code&gt; — adds all of the elements in the specified &lt;code&gt;Collection&lt;/code&gt; to the target &lt;code&gt;Collection&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;removeAll&lt;/code&gt; — removes from the target &lt;code&gt;Collection&lt;/code&gt; all of its elements that are also contained in the specified &lt;code&gt;Collection&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retainAll&lt;/code&gt; — removes from the target &lt;code&gt;Collection&lt;/code&gt; all its elements that are &lt;em&gt;not&lt;/em&gt; also contained in the specified &lt;code&gt;Collection&lt;/code&gt;. That is, it retains only those elements in the target &lt;code&gt;Collection&lt;/code&gt; that are also contained in the specified &lt;code&gt;Collection&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clear&lt;/code&gt; — removes all elements from the &lt;code&gt;Collection&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;c.removeAll(Collections.singleton(e));
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;c.removeAll(Collections.singleton(null));       // remove all of the null elements from a Collection
&lt;/code&gt;&lt;/pre&gt;&lt;h6 id=&#34;collection-interface-array-operations&#34;&gt;Collection Interface Array Operations&lt;/h6&gt;
&lt;p&gt;The &lt;strong&gt;&lt;code&gt;toArray&lt;/code&gt;&lt;/strong&gt; methods are provided as a bridge between collections and older APIs that expect arrays on input.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Object[] a = c.toArray();
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;var staff = new LinkedList&amp;lt;String&amp;gt;();

String[] values = staff.toArray(new String[0]);
// or 
// String[] values = staff.toArray(new String[staff.size()]);
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;the-set-interface&#34;&gt;The Set Interface&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;HashSet&lt;/p&gt;
&lt;p&gt;which stores its elements in a hash table,  it makes no guarantees concerning the order of iteration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Collection&amp;lt;Type&amp;gt; noDups = new HashSet&amp;lt;Type&amp;gt;(c);
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;c.stream()
.collect(Collectors.toSet()); // no duplicates
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TreeSet&lt;/p&gt;
&lt;p&gt;which stores its elements in a red-black tree, orders its elements based on their values.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Set&amp;lt;String&amp;gt; set = people.stream()
.map(Person::getName)
.collect(Collectors.toCollection(TreeSet::new));
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LinkedHashSet&lt;/p&gt;
&lt;p&gt;which is implemented as a hash table with a linked list running through it, orders its elements based on the insertion-order.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// preserves the order of the original collection while removing duplicate elements:
Collection&amp;lt;Type&amp;gt; noDups = new LinkedHashSet&amp;lt;Type&amp;gt;(c);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The following is a &lt;strong&gt;generic method that encapsulates&lt;/strong&gt; the preceding idiom, returning a &lt;code&gt;Set&lt;/code&gt; of the same generic type as the one passed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static &amp;lt;E&amp;gt; Set&amp;lt;E&amp;gt; removeDups(Collection&amp;lt;E&amp;gt; c) {
    return new LinkedHashSet&amp;lt;E&amp;gt;(c);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h6 id=&#34;set-interface-basic-operations&#34;&gt;Set Interface Basic Operations&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;String[] words = {&amp;quot;i&amp;quot;, &amp;quot;came&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;saw&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;left&amp;quot;};
Set&amp;lt;String&amp;gt; distinctWords = Arrays.asList(words).stream().collect(Collectors.toSet());
System.out.println(distinctWords.size()+ &amp;quot; distinct words: &amp;quot; + distinctWords);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that &lt;strong&gt;the code always refers to the &lt;code&gt;Collection&lt;/code&gt; by its interface type (&lt;code&gt;Set&lt;/code&gt;) rather than by its implementation type. This is a &lt;em&gt;strongly&lt;/em&gt; recommended programming practice&lt;/strong&gt; because it gives you the flexibility to change implementations merely by changing the constructor.&lt;/p&gt;
&lt;h6 id=&#34;set-interface-bulk-operations&#34;&gt;Set Interface Bulk Operations&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;s1.containsAll(s2)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;s1.addAll(s2)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;s1.retainAll(s2)&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;s1.removeAll(s2)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To calculate the union, intersection, or set difference of two sets &lt;em&gt;nondestructively&lt;/em&gt; (without modifying either set), &lt;strong&gt;the caller must copy one set before calling the appropriate bulk operation.&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Set&amp;lt;String&amp;gt; uniques = new HashSet&amp;lt;String&amp;gt;();
Set&amp;lt;String&amp;gt; dups    = new HashSet&amp;lt;String&amp;gt;();
String[] words = {&amp;quot;i&amp;quot;, &amp;quot;came&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;saw&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;left&amp;quot;};
  
for (String a : words) {
    if (!uniques.add(a))
        dups.add(a);
}                                     // uniques ==&amp;gt; [left, came, saw, i], dups ==&amp;gt; [i]
  
boolean isContain = uniques.containsAll(dups);         // ==&amp;gt; true    
  
Set&amp;lt;String&amp;gt; union = new HashSet&amp;lt;String&amp;gt;(dups);
union.addAll(uniques);                // union ==&amp;gt; [left, came, saw, i]
  
Set&amp;lt;String&amp;gt; intersection = new HashSet&amp;lt;String&amp;gt;(uniques);
intersection.retainAll(dups);         // intersection ==&amp;gt; [i]
  
Set&amp;lt;String&amp;gt; difference = new HashSet&amp;lt;String&amp;gt;(uniques);
difference.removeAll(dups);           // difference ==&amp;gt; [left, came, saw]
  
System.out.println(&amp;quot;is contain:    &amp;quot; + isContain);    
System.out.println(&amp;quot;union words: &amp;quot; + union);      
System.out.println(&amp;quot;intersection words:    &amp;quot; + intersection);  
System.out.println(&amp;quot;difference words: &amp;quot; + difference); 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;the-list-interface&#34;&gt;The List Interface&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Positional access&lt;/code&gt; — manipulates elements based on their numerical position in the list. This includes methods such as &lt;code&gt;get&lt;/code&gt;, &lt;code&gt;set&lt;/code&gt;, &lt;code&gt;add&lt;/code&gt;, &lt;code&gt;addAll&lt;/code&gt;, and &lt;code&gt;remove&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static &amp;lt;E&amp;gt; void swap(List&amp;lt;E&amp;gt; a, int i, int j) {
    E tmp = a.get(i);
    a.set(i, a.get(j));
    a.set(j, tmp);
}
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;public static void shuffle(List&amp;lt;?&amp;gt; list, Random rnd) {
    for (int i = list.size(); i &amp;gt; 1; i--)
        swap(list, i - 1, rnd.nextInt(i));
}
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;import java.util.*;
  
public class Shuffle {
    public static void main(String[] args) {
        List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;String&amp;gt;();
        for (String a : args)
            list.add(a);
        Collections.shuffle(list, new Random());
        System.out.println(list);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Arrays class has a static factory method called &lt;strong&gt;&lt;code&gt;asList&lt;/code&gt;&lt;/strong&gt;, which allows an array to be viewed as a List. This method does not copy the array. Changes in the &lt;code&gt;List&lt;/code&gt; write through to the array and vice versa. &lt;strong&gt;The resulting List is not a general-purpose &lt;code&gt;List&lt;/code&gt; implementation, because it doesn&amp;rsquo;t implement the (optional) &lt;code&gt;add&lt;/code&gt; and &lt;code&gt;remove&lt;/code&gt; operations: Arrays are not resizable.&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.util.*;
  
public class Shuffle {
    public static void main(String[] args) {
        List&amp;lt;String&amp;gt; list = Arrays.asList(args);
        Collections.shuffle(list);
        System.out.println(list);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Search&lt;/code&gt; — searches for a specified object in the list and returns its numerical position. Search methods include &lt;code&gt;indexOf&lt;/code&gt; and &lt;code&gt;lastIndexOf&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Iteration&lt;/code&gt; — extends &lt;code&gt;Iterator&lt;/code&gt; semantics to take advantage of the list&amp;rsquo;s sequential nature. The &lt;code&gt;listIterator&lt;/code&gt; methods provide this behavior.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for (ListIterator&amp;lt;Type&amp;gt; it = list.listIterator(list.size()); it.hasNext(); ) {
    Type t = it.next();
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;for (ListIterator&amp;lt;Type&amp;gt; it = list.listIterator(list.size()); it.hasPrevious(); ) {
    Type t = it.previous();
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;String[] words = {&amp;quot;i&amp;quot;, &amp;quot;came&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;saw&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;left&amp;quot;};
List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;String&amp;gt;();
for (String a : words) {
  list.add(a);
}
ListIterator&amp;lt;String&amp;gt; it = list.listIterator()
it.previousIndex();       // ==&amp;gt; -1
var ret = it.next();      // ret ==&amp;gt; &amp;quot;i&amp;quot;
it.previousIndex();       // ==&amp;gt; 0
var obj = it.previous();  // obj ==&amp;gt; &amp;quot;i&amp;quot;
it.previousIndex();       // ==&amp;gt; -1
it.nextIndex();            // ==&amp;gt; 0
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;String[] words = {&amp;quot;i&amp;quot;, &amp;quot;came&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;saw&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;left&amp;quot;};
List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;String&amp;gt;();
for (String a : words) {
  list.add(a);
}
public static &amp;lt;E&amp;gt; void replace(List&amp;lt;E&amp;gt; list, E val, E newVal) {
    for (ListIterator&amp;lt;E&amp;gt; it = list.listIterator(); it.hasNext(); )
        if (val == null ? it.next() == null : val.equals(it.next()))
            it.set(newVal);
}
replace(list, &amp;quot;i&amp;quot;, &amp;quot;e&amp;quot;)           // list ==&amp;gt; [e, came, e, saw, e, left]
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;public static &amp;lt;E&amp;gt; 
    void replace(List&amp;lt;E&amp;gt; list, E val, List&amp;lt;? extends E&amp;gt; newVals) {
    for (ListIterator&amp;lt;E&amp;gt; it = list.listIterator(); it.hasNext(); ){
        if (val == null ? it.next() == null : val.equals(it.next())) {
            it.remove();
            for (E e : newVals)
                it.add(e);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Range-view&lt;/code&gt; — The &lt;code&gt;sublist&lt;/code&gt; method performs arbitrary &lt;em&gt;range operations&lt;/em&gt; on the list.&lt;/p&gt;
&lt;p&gt;removes a range of elements from a &lt;code&gt;List&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;list.subList(fromIndex, toIndex).clear();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;search for an element in a range&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int i = list.subList(fromIndex, toIndex).indexOf(o);
int j = list.subList(fromIndex, toIndex).lastIndexOf(o);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;List&amp;lt;String&amp;gt; lnkLst = new LinkedList&amp;lt;String&amp;gt;();
lnkLst.add(&amp;quot;element1&amp;quot;);
Iterator&amp;lt;String&amp;gt; itr = lnkLst.iterator();
for (Iterator&amp;lt;String&amp;gt; it = lnkLst.iterator(); it.hasNext(); )
    String str = (String) itr.next();
    System.out.print(str + &amp;quot; &amp;quot;);
System.out.println();
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;var staff = new LinkedList&amp;lt;String&amp;gt;();
staff.add(&amp;quot;Amy&amp;quot;);
staff.add(&amp;quot;Bob&amp;quot;);
staff.add(&amp;quot;Carl&amp;quot;);
ListIterator&amp;lt;String&amp;gt; iter = staff.listIterator();
iter.next(); // skip past first element
iter.add(&amp;quot;Juliet&amp;quot;);      // staff ==&amp;gt; [Amy, Juliet, Bob, Carl]
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;ArrayList&amp;lt;Employee&amp;gt; staff = new ArrayList&amp;lt;Employee&amp;gt;();
staff.add(new Employee(&amp;quot;Harry Hacker&amp;quot;, . . .));
staff.ensureCapacity(100);
ArrayList&amp;lt;Employee&amp;gt; staff = new ArrayList&amp;lt;&amp;gt;(100);
staff.size()

new ArrayList&amp;lt;&amp;gt;(100) // capacity is 100
is not the same as allocating a new array as
Click here to view code image
new Employee[100] // size is 100


trimToSize
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;ArrayList&amp;lt;E&amp;gt;()    // constructs an empty array list.
ArrayList&amp;lt;E&amp;gt;(int initialCapacity)    // constructs an empty array list with the specified capacity.
boolean add(E obj)    // appends obj at the end of the array list. Always returns true.
int size()    // returns the number of elements currently stored in the array list. (Of course, this is never larger than the array list’s capacity.)
void ensureCapacity(int capacity)    // ensures that the array list has the capacity to store the given number of elements without reallocating its internal storage array.
void trimToSize()    // reduces the storage capacity of the array list to its current size.
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;ArrayList&amp;lt;String&amp;gt; staff = new ArrayList&amp;lt;String&amp;gt;();
staff.add(new String(&amp;quot;Harry Hacker&amp;quot;));
staff.ensureCapacity(100);
staff.size()                                      // ==&amp;gt; 1
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;the-queue-interface&#34;&gt;The Queue Interface&lt;/h4&gt;
&lt;h4 id=&#34;the-deque-interface&#34;&gt;The Deque Interface&lt;/h4&gt;
&lt;h4 id=&#34;the-map-interface&#34;&gt;The Map Interface&lt;/h4&gt;
&lt;h4 id=&#34;object-ordering&#34;&gt;Object Ordering&lt;/h4&gt;
&lt;h4 id=&#34;the-sortedset-interface&#34;&gt;The SortedSet Interface&lt;/h4&gt;
&lt;h4 id=&#34;the-sortedmap-interface&#34;&gt;The SortedMap Interface&lt;/h4&gt;
&lt;h3 id=&#34;aggregate-operations&#34;&gt;Aggregate Operations&lt;/h3&gt;
&lt;h3 id=&#34;algorithms&#34;&gt;Algorithms&lt;/h3&gt;
&lt;h2 id=&#34;lambda-expressions&#34;&gt;Lambda Expressions&lt;/h2&gt;
&lt;h2 id=&#34;date-time-apis&#34;&gt;Date-Time APIs&lt;/h2&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;How to package applications and &lt;strong&gt;applets&lt;/strong&gt; using JAR files, and deploy them using Java Web Start and Java Plug-in.
Preparation for Java Programming Language Certification — List of available training and tutorial resources.&lt;/p&gt;
&lt;h2 id=&#34;internationalization&#34;&gt;Internationalization&lt;/h2&gt;
&lt;h2 id=&#34;reflection&#34;&gt;Reflection&lt;/h2&gt;
&lt;h2 id=&#34;middleware-server-side-or-web-application&#34;&gt;Middleware, server-side, or web application&lt;/h2&gt;
&lt;h3 id=&#34;jdbc-database-access&#34;&gt;JDBC Database Access&lt;/h3&gt;
&lt;h3 id=&#34;concurrency&#34;&gt;Concurrency&lt;/h3&gt;
&lt;h2 id=&#34;standard-edition&#34;&gt;Standard Edition&lt;/h2&gt;
&lt;p&gt;java&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;io&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BufferedReader&lt;/li&gt;
&lt;li&gt;BufferedWriter&lt;/li&gt;
&lt;li&gt;ByteArrayInputStream&lt;/li&gt;
&lt;li&gt;ByteArrayOutputStream&lt;/li&gt;
&lt;li&gt;File&lt;/li&gt;
&lt;li&gt;FileFilter&lt;/li&gt;
&lt;li&gt;FileInputStream&lt;/li&gt;
&lt;li&gt;FileOutputStream&lt;/li&gt;
&lt;li&gt;IOException&lt;/li&gt;
&lt;li&gt;InputStream&lt;/li&gt;
&lt;li&gt;IntputStreamReader&lt;/li&gt;
&lt;li&gt;OutputStream&lt;/li&gt;
&lt;li&gt;OutputStreamWriter&lt;/li&gt;
&lt;li&gt;PrintWriter&lt;/li&gt;
&lt;li&gt;Reader&lt;/li&gt;
&lt;li&gt;Serializable&lt;/li&gt;
&lt;li&gt;StringReader&lt;/li&gt;
&lt;li&gt;StringWriter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lang&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;reflect
&lt;ul&gt;
&lt;li&gt;Field&lt;/li&gt;
&lt;li&gt;Method&lt;/li&gt;
&lt;li&gt;InvocationTargetException&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;math&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BigDecimal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;net&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HttpURLConnection&lt;/li&gt;
&lt;li&gt;URL&lt;/li&gt;
&lt;li&gt;URLConnection&lt;/li&gt;
&lt;li&gt;URLDecoder&lt;/li&gt;
&lt;li&gt;URLEncoder&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;nio&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;charset
&lt;ul&gt;
&lt;li&gt;Charset&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;security&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MessageDigest&lt;/li&gt;
&lt;li&gt;SecureRandom&lt;/li&gt;
&lt;li&gt;InvalidAlgorithmParameterException&lt;/li&gt;
&lt;li&gt;InvalidKeyException&lt;/li&gt;
&lt;li&gt;KeyManagementException&lt;/li&gt;
&lt;li&gt;NoSuchAlgorithmException&lt;/li&gt;
&lt;li&gt;NoSuchProviderException&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sql&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Date&lt;/li&gt;
&lt;li&gt;ResultSet&lt;/li&gt;
&lt;li&gt;ResultSetMetaData&lt;/li&gt;
&lt;li&gt;SQLException&lt;/li&gt;
&lt;li&gt;Timestamp&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;text&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DateFormat&lt;/li&gt;
&lt;li&gt;DecimalFormat&lt;/li&gt;
&lt;li&gt;MessageFormat&lt;/li&gt;
&lt;li&gt;Normalizer&lt;/li&gt;
&lt;li&gt;NumberFormat&lt;/li&gt;
&lt;li&gt;SimpleDateFormat&lt;/li&gt;
&lt;li&gt;ParseException&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;util&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ArrayList&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Arrays&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Base64.Decoder&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Base64.Encoder&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Calendar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collections&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Comparator&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Date&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enumeration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GregorianCalendar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HashMap&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HashSet&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HashMap&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Iterator&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LinkedHashMap&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LinkedHashSet&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LinkedList&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;List&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Locale&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;formatter.withLocale(Locale.CHINESE).format(apollo11launch);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Map.Entry&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Map&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Queue&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Random&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ResourceBundle&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Timer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TimerTask&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TimeZone&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;UUID&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;concurrent&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ConcurrentHashMap&lt;/li&gt;
&lt;li&gt;ConcurrentLinkedQueue&lt;/li&gt;
&lt;li&gt;Executors&lt;/li&gt;
&lt;li&gt;ScheduledExecutorService&lt;/li&gt;
&lt;li&gt;Semaphore&lt;/li&gt;
&lt;li&gt;TimeUnit&lt;/li&gt;
&lt;li&gt;ExecutionException&lt;/li&gt;
&lt;li&gt;TimeoutException&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;util.logging&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Logger&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.util.logging.Logger;
    
public class Main {
    
  private static final Logger logger =
Logger.getLogger(&amp;quot;com.mycompany.myapp&amp;quot;);
    
  public static void main(String[] args) {
    logger.info(&amp;quot;Logging an INFO-level message&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;regex&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Matcher&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pattern&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.io.*;
import java.net.*;
import java.nio.charset.*;
import java.util.regex.*;
    
try
{
    String urlString = &amp;quot;http://openjdk.java.net/&amp;quot;;
    
    // read contents of URL
    InputStream in = new URL(urlString).openStream();
    var input = new String(in.readAllBytes(), StandardCharsets.UTF_8);
    
    // search for all occurrences of pattern
    var patternString = &amp;quot;&amp;lt;a\\s+href\\s*=\\s*(\&amp;quot;[^\&amp;quot;]*\&amp;quot;|[^\\s&amp;gt;]*)\\s*&amp;gt;&amp;quot;;
    Pattern pattern = Pattern.compile(patternString, Pattern.CASE_INSENSITIVE);
    pattern.matcher(input)
    .results()
    .map(MatchResult::group)
    .forEach(System.out::println);
}
catch (IOException | PatternSyntaxException e)
{
    e.printStackTrace();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;stream&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collectors
&lt;ul&gt;
&lt;li&gt;toSet()&lt;/li&gt;
&lt;li&gt;toList()&lt;/li&gt;
&lt;li&gt;toMap()&lt;/li&gt;
&lt;li&gt;joining()&lt;/li&gt;
&lt;li&gt;toCollection()&lt;/li&gt;
&lt;li&gt;summarizingInt()&lt;/li&gt;
&lt;li&gt;groupingByConcurrent()&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;import java.util.List;
import java.util.Map;
import java.util.HashMap;&lt;/p&gt;
&lt;p&gt;import java.util.Date;
import java.io.Serializable;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.oracle.com/javafx/2/collections/jfxpub-collections.htm&#34;&gt;https://docs.oracle.com/javafx/2/collections/jfxpub-collections.htm&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;extension&#34;&gt;extension&lt;/h3&gt;
&lt;p&gt;javax&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;activation
&lt;ul&gt;
&lt;li&gt;DataHandler&lt;/li&gt;
&lt;li&gt;MimetypesFileTypeMap&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;crypto
&lt;ul&gt;
&lt;li&gt;BadPaddingException&lt;/li&gt;
&lt;li&gt;Cipher&lt;/li&gt;
&lt;li&gt;IllegalBlockSizeException&lt;/li&gt;
&lt;li&gt;NoSuchPaddingException&lt;/li&gt;
&lt;li&gt;spec
&lt;ul&gt;
&lt;li&gt;IvParameterSpec&lt;/li&gt;
&lt;li&gt;SecretKeySpec&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;net
&lt;ul&gt;
&lt;li&gt;ssl
&lt;ul&gt;
&lt;li&gt;HostnameVerifier&lt;/li&gt;
&lt;li&gt;HttpsURLConnection&lt;/li&gt;
&lt;li&gt;SSLSession&lt;/li&gt;
&lt;li&gt;SSLContext&lt;/li&gt;
&lt;li&gt;TrustManager&lt;/li&gt;
&lt;li&gt;X509TrustManager&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;script
&lt;ul&gt;
&lt;li&gt;ScriptException&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;security
&lt;ul&gt;
&lt;li&gt;auth
&lt;ul&gt;
&lt;li&gt;login
&lt;ul&gt;
&lt;li&gt;LoginException&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;xml
&lt;ul&gt;
&lt;li&gt;bind
&lt;ul&gt;
&lt;li&gt;Unmarshaller&lt;/li&gt;
&lt;li&gt;JAXBContext&lt;/li&gt;
&lt;li&gt;annotation
&lt;ul&gt;
&lt;li&gt;XmlAccessType&lt;/li&gt;
&lt;li&gt;XmlAccessorType&lt;/li&gt;
&lt;li&gt;XmlElement&lt;/li&gt;
&lt;li&gt;XmlElementWrapper&lt;/li&gt;
&lt;li&gt;XmlRootElement&lt;/li&gt;
&lt;li&gt;XmlType&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;namespace
&lt;ul&gt;
&lt;li&gt;QName&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;parsers
&lt;ul&gt;
&lt;li&gt;DocumentBuilder&lt;/li&gt;
&lt;li&gt;DocumentBuilderFactory&lt;/li&gt;
&lt;li&gt;SAXParser&lt;/li&gt;
&lt;li&gt;SAXParserFactory&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;soap
&lt;ul&gt;
&lt;li&gt;SOAPBody&lt;/li&gt;
&lt;li&gt;SOAPBodyElement&lt;/li&gt;
&lt;li&gt;SOAPEnvelope&lt;/li&gt;
&lt;li&gt;SOAPMessage&lt;/li&gt;
&lt;li&gt;SOAPPart&lt;/li&gt;
&lt;li&gt;SOAPException&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;enterprise-edition&#34;&gt;Enterprise Edition&lt;/h2&gt;
&lt;p&gt;javax&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;inject&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Inject&lt;/p&gt;
&lt;p&gt;Identifies injectable constructors, methods, and fields.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dzone.com/articles/cdi-di-p1&#34;&gt;https://dzone.com/articles/cdi-di-p1&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Car {
    // Injectable constructor
    @Inject public Car(Engine engine) { ... }
    
    // Injectable field
    @Inject private Provider&amp;lt;Seat&amp;gt; seatProvider;
    
    // Injectable package-private method
    @Inject void install(Windshield windshield, Trunk trunk) { ... }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Named&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;jms&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Message&lt;/li&gt;
&lt;li&gt;MessageListener&lt;/li&gt;
&lt;li&gt;TextMessage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;persistence&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transient&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;servlet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filter&lt;/li&gt;
&lt;li&gt;FilterChain&lt;/li&gt;
&lt;li&gt;FilterConfig&lt;/li&gt;
&lt;li&gt;ServletInputStream&lt;/li&gt;
&lt;li&gt;ServletOutputStream&lt;/li&gt;
&lt;li&gt;ServletRequest&lt;/li&gt;
&lt;li&gt;ServletResponse&lt;/li&gt;
&lt;li&gt;ServletException&lt;/li&gt;
&lt;li&gt;http
&lt;ul&gt;
&lt;li&gt;Cookie&lt;/li&gt;
&lt;li&gt;HttpServlet&lt;/li&gt;
&lt;li&gt;HttpServletRequest&lt;/li&gt;
&lt;li&gt;HttpServletResponse&lt;/li&gt;
&lt;li&gt;HttpServletRequestWrapper&lt;/li&gt;
&lt;li&gt;HttpServletResponseWrapper&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;transaction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transactional&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ws&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rs
&lt;ul&gt;
&lt;li&gt;DELETE&lt;/li&gt;
&lt;li&gt;GET&lt;/li&gt;
&lt;li&gt;POST&lt;/li&gt;
&lt;li&gt;PUT&lt;/li&gt;
&lt;li&gt;Path&lt;/li&gt;
&lt;li&gt;PathParam&lt;/li&gt;
&lt;li&gt;Produces&lt;/li&gt;
&lt;li&gt;QueryParam&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;core
&lt;ul&gt;
&lt;li&gt;Context&lt;/li&gt;
&lt;li&gt;MediaType&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;import javax.ws.rs.GET;
import javax.ws.rs.POST;
import javax.ws.rs.PUT;
import javax.ws.rs.DELETE;
import javax.ws.rs.Produces;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.QueryParam;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.MediaType;&lt;/p&gt;
&lt;p&gt;import javax.servlet.http.HttpServlet;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.oracle.com/cd/E19226-01/820-7627/6nisfjmk8/index.html&#34;&gt;https://docs.oracle.com/cd/E19226-01/820-7627/6nisfjmk8/index.html&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
