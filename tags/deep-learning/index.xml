<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deep learning on Ye Zheng&#39;s Blog</title>
    <link>http://www.yezheng.pro/tags/deep-learning/</link>
    <description>Recent content in deep learning on Ye Zheng&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 09 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="http://www.yezheng.pro/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tensorflow Docker</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/tensorflow-docker/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/tensorflow-docker/</guid>
      <description>TensorFlow Docker requirements Install Docker
sudo pacman -S docker systemctl enable docker.service systemctl start docker.service For GPU support on Linux,
yay -S nvidia-container-toolkit The official TensorFlow Docker images are located in the tensorflow/tensorflow Docker Hub repository.
Start a TensorFlow Docker container docker run [-it] [--rm] [-p hostPort:containerPort] tensorflow/tensorflow[:tag] [command] Examples using CPU-only images docker pull tensorflow/tensorflow docker run -it --rm tensorflow/tensorflow \ python -c &amp;quot;import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))&amp;quot; Start a bash shell session within a TensorFlow-configured container:</description>
    </item>
    
    <item>
      <title>evaluate the quality of the training phrases in intents</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/chatbot/evaluate-the-quality-of-the-training-phrases-in-intents/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/chatbot/evaluate-the-quality-of-the-training-phrases-in-intents/</guid>
      <description>This tutorial shows you how to analyze and evaluate the quality of the training phrases supplied to your Dialogflow agent&amp;rsquo;s intents. The purpose of this analysis is to avoid confusing the agent with phrases irrelevant to the intents supplied to, or more relevant to, other intents.
The approach you take is to generate semantic embeddings of the training phrases by using the TensorFlow Hub (tf.Hub) Universal Sentence Encoder module. You then compute cohesion and separation measurements based on the similarity between embeddings within the same intents and different intents.</description>
    </item>
    
    <item>
      <title>Machine Learning Models for Predictions in Cloud Dataflow Pipelines</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/ml-model-predictions-in-dataflow-pipelines/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/ml-model-predictions-in-dataflow-pipelines/</guid>
      <description>This solution describes and compares the different design approaches for calling a machine learning model during a Dataflow pipeline, and examines the tradeoffs involved in choosing one approach or another. We present the results of a series of experiments that we ran to explore different approaches and illustrate these tradeoffs, both in batch and stream processing pipelines. This solution is designed for people who integrate trained models into data processing pipelines, rather than for data scientists who want to build machine learning models.</description>
    </item>
    
    <item>
      <title>Deploying machine learning models in production</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/deploy/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/deploy/</guid>
      <description>Reference 训练好的深度学习模型是怎么部署的？ PyTorch模型的加速及部署 ahkarami/Deep-Learning-in-Production Accelerating Inference In TF-TRT User Guide tensorflow/tensorrt Tensorrt API Reference Containers: nvidia:tensorflow Model inference using TensorFlow and TensorRT Speed up TensorFlow Inference on GPUs with TensorRT TF20-TF-TRT-inference-from-Keras-saved-model.ipynb</description>
    </item>
    
    <item>
      <title>Bert</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/bert/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/bert/</guid>
      <description>For all translation problems, we suggest to try the Transformer model. https://tensorflow.google.cn/official_models/fine_tuning_bert the configuration, vocabulary, and a pre-trained checkpoint. you can find the download url for this in README.md page. BERT 可解释性-从&amp;quot;头&amp;quot;说起 一、背景介绍 搜索场景下用户搜索的 query 和</description>
    </item>
    
    <item>
      <title>Tensorflow</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/tensorflow/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/tensorflow/</guid>
      <description>TensorFlow Install TensorFlow 2    Version Python version Compiler Build tools     tensorflow-2.2.0 3.5-3.8 GCC 7.3.1 Bazel 2.0.0   tensorflow-2.1.0 2.7, 3.5-3.7 GCC 7.3.1 Bazel 0.27.1   tensorflow-2.0.0 2.7, 3.3-3.7 GCC 7.3.1 Bazel 0.26.1    sudo pacman -U cuda-10.1.243-2-x86_64.pkg.tar.xz sudo pacman -U cudnn-7.6.5.32-2-x86_64.pkg.tar.xz pip install tensorflow-gpu Data input pipelines Keras Sequential API When to use a Sequential model A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.</description>
    </item>
    
    <item>
      <title>notes of deep learning with python</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/notes-deep-learning-with-python/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/notes-deep-learning-with-python/</guid>
      <description>Deep Learning with Python PART 1 - FUNDAMENTALS OF DEEP LEARNING 1.What is deep learning? Artificial intelligence, machine learning, and deep learning Before deep learning: a brief history of machine learning Why deep learning? Why now? 2.Before we begin: the mathematical building blocks of neural networks A first look at a neural network Data representations for neural networks tensor: it’s a container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions (note that in the context of tensors, a dimension is often called an axis).</description>
    </item>
    
    <item>
      <title>kaggle</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/machine-learning/kaggle/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/machine-learning/kaggle/</guid>
      <description>https://www.kaggle.com/stackoverflow/statsquestions
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge
https://developer.ibm.com/exchanges/models/all/max-toxic-comment-classifier/
https://www.quora.com/Is-binary-relevance-same-as-one-vs-all
https://stackoverflow.com/questions/44674847/what-are-the-differences-between-all-these-cross-entropy-losses-in-keras-and-ten
https://vict0rs.ch/2018/06/17/multilabel-text-classification-tensorflow/
https://github.com/tensorflow/skflow/issues/113
https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff
https://www.reddit.com/r/MLQuestions/comments/5n82zb/loss_function_for_sparse_multilabel_classification/</description>
    </item>
    
    <item>
      <title>keras</title>
      <link>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/keras/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.yezheng.pro/post/specialization/artificial-intelligence/deep-learning/keras/</guid>
      <description>Keras import tensorflow as tf from tensorflow import keras </description>
    </item>
    
  </channel>
</rss>
